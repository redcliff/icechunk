{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Icechunk - Open-source, cloud-native transactional tensor storage engine","text":"<p>Home</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Home / contributing</p>"},{"location":"contributing/#contributing","title":"Contributing","text":"<p>\ud83d\udc4b Hi! Thanks for your interest in contributing to Icechunk!</p> <p>Icechunk is an open source (Apache 2.0) project and welcomes contributions in the form of:</p> <ul> <li>Usage questions - open a GitHub issue</li> <li>Bug reports - open a GitHub issue</li> <li>Feature requests - open a GitHub issue</li> <li>Documentation improvements - open a GitHub pull request</li> <li>Bug fixes and enhancements - open a GitHub pull request</li> </ul>"},{"location":"contributing/#development","title":"Development","text":""},{"location":"contributing/#python-development-workflow","title":"Python Development Workflow","text":"<p>Create / activate a virtual environment:</p> VenvConda / Mamba <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\n</code></pre> <pre><code>mamba create -n icechunk python=3.12 rust zarr\nmamba activate icechunk\n</code></pre> <p>Install <code>maturin</code>:</p> <pre><code>pip install maturin\n</code></pre> <p>Build the project in dev mode:</p> <pre><code>maturin develop\n</code></pre> <p>or build the project in editable mode:</p> <pre><code>pip install -e icechunk@.\n</code></pre>"},{"location":"contributing/#rust-development-workflow","title":"Rust Development Workflow","text":"<p>TODO</p>"},{"location":"contributing/#roadmap","title":"Roadmap","text":"<p>The initial release of Icechunk is just the beginning. We have a lot more planned for the format and the API.</p>"},{"location":"contributing/#roadmap-to-icechunk-10","title":"Roadmap to Icechunk 1.0","text":""},{"location":"contributing/#core-format","title":"Core format","text":"<p>The core format is where we\u2019ve put most of our effort to date and we plan to continue work in this area. Leading up to the 1.0 release, we will be focused on stabilizing data structures for snapshots, chunk manifests, attribute files and references. We\u2019ll also document and add more mechanisms for on-disk format evolution. The intention is to guarantee that any new version of Icechunk can always read repositories generated with any previous versions. We expect to evolve the spec and the Rust implementation as we stabilize things.</p>"},{"location":"contributing/#features","title":"Features","text":"<ul> <li>Commit conflict detection, resolution and rebase</li> <li>Current session status (git status)</li> <li>Support Google Cloud Storage</li> <li>Support Azure Blob Storage</li> <li>Distributed write support with dask.array</li> <li>Credential sets for virtual datasets</li> <li> <p>Complete Python API:</p> <ul> <li>list refs</li> <li>read hierarchy</li> <li>repo size</li> </ul> </li> <li> <p>Better documentation and examples</p> </li> </ul>"},{"location":"contributing/#performance","title":"Performance","text":"<ul> <li>Create scale benchmark of daily updated dataset (15M chunks, 30k commits)</li> <li>Create performance benchmark for read and write, compare to Zarr 3 + fsspec/s3</li> <li>Optimize if needed based on benchmarks: manifest splitting, history splitting, attribute files.</li> <li>Optimize virtual dataset prefixes</li> <li>Improve list_dir performance (which will improve other functions)</li> <li>Improve performance of get_size</li> </ul>"},{"location":"contributing/#refactoring","title":"Refactoring","text":"<ul> <li>Improve Python API<ul> <li>Separate Repo and Zarr Store</li> <li>Make it clear at the API level what methods require commit and which ones don't</li> <li>Transactions as context managers</li> <li>Better <code>repr</code></li> </ul> </li> </ul>"},{"location":"contributing/#correctness","title":"Correctness","text":"<ul> <li>Ingest native datasets: hrrr, gfs, sentinel data cube</li> <li>Ingest virtual datasets: arco-era5, lens, cmip6</li> <li>Add property and stateful tests from Zarr 3 and Arraylake</li> <li>Document and exercise on-disk versioning</li> </ul>"},{"location":"contributing/#roadmap-beyond-icechunk-10","title":"Roadmap beyond Icechunk 1.0","text":""},{"location":"contributing/#features_1","title":"Features","text":"<ul> <li>Persistent configuration</li> <li>More powerful conflict detection and resolution</li> <li>Better error messages</li> <li>Version expiration, garbage collection</li> <li>Efficient rename</li> </ul>"},{"location":"contributing/#performance_1","title":"Performance","text":"<p>While the initial performance benchmarks of Icechunk are very encouraging, we know that we have only scratched the surface of what is possible. We are looking forward to investing in a number of optimizations that will really make Icechunk fly!</p> <ul> <li>Request batching and splitting</li> <li>Manifest compression and serialization improvements</li> <li>Manifest split heuristics</li> <li>Bringing parts of the codec pipeline to the Rust side</li> <li>Better caching, in memory and optionally on local disk</li> </ul>"},{"location":"contributing/#other-utilities","title":"Other Utilities","text":"<p>On top of the foundation of the Icechunk format, we are looking to build a suite of other utilities that operate on data stored in Icechunk. Some examples:</p> <ul> <li>Garbage collection - version controlled data has the potential to accumulate data that is no longer needed but is still included in the store. A garbage collection process will allow users to safely cleanup data from old versions of an Icechunk dataset.</li> <li>Chunk compaction - data written by Zarr may result in many small chunks in object storage. A chunk compaction service will allow users to retroactively compact small chunks into larger objects (similar to Zarr\u2019s sharding format), resulting in potential performance improvements and fewer objects in storage.</li> <li>Manifest optimization - knowing how the data is queried would allow to optimize the shape and splits of the chunk manifests, in such a way as to minimize the amount of data needed to execute the most frequent queries.</li> </ul>"},{"location":"contributing/#zarr-related","title":"Zarr-related","text":"<p>We\u2019re very excited about a number of extensions to Zarr that would work great with Icechunk.</p> <ul> <li>Variable length chunks</li> <li>Chunk-level statistics</li> </ul>"},{"location":"contributing/#miscellaneous","title":"Miscellaneous","text":"<p>There\u2019s much more than what we\u2019ve written above on the roadmap. Some examples:</p> <ul> <li>Multi-language support (R, Julia, \u2026)</li> <li>Exposing high level API (groups and arrays) to Python users</li> <li>Make more details of the format accessible through configuration</li> <li>Improve Xarray backend to integrate more directly with Icechunk</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Home / faq</p>"},{"location":"faq/#faq","title":"FAQ","text":""},{"location":"faq/#why-was-icechunk-created","title":"Why was Icechunk created?","text":"<p>Icechunk was created by Earthmover as the open-source format for its cloud data platform Arraylake.</p> <p>Icechunk builds on the successful Zarr project. Zarr is a great foundation for storing and querying large multidimensional array data in a flexible, scalable way. But when people started using Zarr together with cloud object storage in a collaborative way, it became clear that Zarr alone could not offer the sort of consistency many users desired. Icechunk makes Zarr work a little bit more like a database, enabling different users / processes to safely read and write concurrently, while still only using object storage as a persistence layer.</p> <p>Another motivation for Icechunk was the success of Kerchunk. The Kerchunk project showed that it was possible to map many existing archival formats (e.g. HDF5, NetCDF, GRIB) to the Zarr data model without actually rewriting any bytes, by creating \"virtual\" Zarr datasets referencing binary chunks inside other files. Doing this at scale requires tracking millions of \"chunk references.\" Icechunk's storage model allows for these virtual chunks to be stored seamlessly alongside native Zarr chunks.</p> <p>Finally, Icechunk provides a universal I/O layer for cloud object storage, implementing numerous performance optimizations designed to accelerate data-intensive applications.</p> <p>Solving these problems in one go via a powerful, open-source, Rust-based library will bring massive benefits to the cloud-native scientific data community.</p>"},{"location":"faq/#where-does-the-name-icechunk-come-from","title":"Where does the name \"Icechunk\" come from?","text":"<p>Icechunk was inspired partly by Apache Iceberg, a popular cloud-native table format. However, instead of storing tabular data, Icechunk stores multidimensional arrays, for which the individual unit of storage is the chunk.</p>"},{"location":"faq/#when-should-i-use-icechunk","title":"When should I use Icechunk?","text":"<p>Here are some scenarios where it makes sense to use Icechunk:</p> <ul> <li>You want to store large, dynamically evolving multi-dimensional array (a.k.a. tensor) in cloud object storage.</li> <li>You want to allow multiple uncoordinated processes to access your data at the same time (like a database).</li> <li>You want to be able to safely roll back failed updates or revert Zarr data to an earlier state.</li> <li>You want to use concepts from data version control (e.g. tagging, branching, snapshots) with Zarr data.</li> <li>You want to achieve cloud-native performance on archival file formats (HDF5, NetCDF, GRIB) by exposing them as virtual Zarr datasets and need to store chunk references in a a robust, scalable, interoperable way.</li> <li>You want to get the best possible performance for reading / writing tensor data in AI / ML workflows.</li> </ul>"},{"location":"faq/#what-are-the-downsides-to-using-icechunk","title":"What are the downsides to using Icechunk?","text":"<p>As with all things in technology, the benefits of Icechunk come with some tradeoffs:</p> <ul> <li>There may be slightly higher cold-start latency to opening Icechunk datasets compared with regular Zarr.</li> <li>The on-disk format is less transparent than regular Zarr.</li> <li>The process for distributed writes is more complex to coordinate.</li> </ul> <p>Warning</p> <p>Another downside of Icechunk in its current state is its immaturity. The library is very new, likely contains bugs, and is not recommended for production usage at this point in time.</p>"},{"location":"faq/#what-is-icechunks-relationship-to-zarr","title":"What is Icechunk's relationship to Zarr?","text":"<p>The Zarr format and protocol is agnostic to the underlying storage system (\"store\" in Zarr terminology) and communicates with the store via a simple key / value interface. Zarr tells the store which keys and values it wants to get or set, and it's the store's job to figure out how to persist or retrieve the required bytes.</p> <p>Most existing Zarr stores have a simple 1:1 mapping between Zarr's keys and the underlying file / object names. For example, if Zarr asks for a key call <code>myarray/c/0/0</code>, the store may just look up a key of the same name in an underlying cloud object storage bucket.</p> <p>Icechunk is a storage engine which creates a layer of indirection between the Zarr keys and the actual files in storage. A Zarr library doesn't have to know explicitly how Icechunk works or how it's storing data on disk. It just gets / sets keys as it would with any store. Icechunk figures out how to materialize these keys based on its storage schema.</p> <ul> <li> <p>Standard Zarr + Fsspec</p> <p>In standard Zarr usage (without Icechunk), fsspec sits between the Zarr library and the object store, translating Zarr keys directly to object store keys.</p> <pre><code>flowchart TD\n    zarr-python[Zarr Library] &lt;-- key / value--&gt; icechunk[fsspec]\n    icechunk &lt;-- key / value --&gt; storage[(Object Storage)]\n</code></pre> </li> <li> <p>Zarr + Icechunk</p> <p>With Icechunk, the Icechunk library intercepts the Zarr keys and translates them to the Icechunk schema, storing data in object storage using its own format.</p> <pre><code>flowchart TD\n    zarr-python[Zarr Library] &lt;-- key / value--&gt; icechunk[Icechunk Library]\n    icechunk &lt;-- icechunk data / metadata files --&gt; storage[(Object Storage)]\n</code></pre> </li> </ul> <p>Implementing Icechunk this way allows Icechunk's specification to evolve independently from Zarr's, maintaining interoperability while enabling rapid iteration and promoting innovation on the I/O layer.</p>"},{"location":"faq/#is-icechunk-part-of-the-zarr-spec","title":"Is Icechunk part of the Zarr Spec?","text":"<p>No. At the moment, the Icechunk spec is completely independent of the Zarr spec.</p> <p>In the future, we may choose to propose Icechunk as a Zarr extension. However, because it sits below Zarr in the stack, it's not immediately clear how to do that.</p>"},{"location":"faq/#should-i-implement-icechunk-on-my-own-based-on-the-spec","title":"Should I implement Icechunk on my own based on the spec?","text":"<p>No, we do not recommend implementing Icechunk independently of the existing Rust library. There are two reasons for this:</p> <ol> <li>The spec has not yet been stabilized and is still evolving rapidly.</li> <li>It's probably much easier to bind to the Rust library from your language of choice,    rather than re-implement from scratch.</li> </ol> <p>We welcome contributions from folks interested in developing Icechunk bindings for other languages!</p>"},{"location":"faq/#is-icechunk-stable","title":"Is Icechunk stable?","text":"<p>The Icechunk library is reasonably well-tested and performant. The Rust-based core library provides a solid foundation of correctness, safety, and speed.</p> <p>However, the actual on disk format is still evolving and may change from one alpha release to the next. Until Icechunk reaches v1.0, we can't commit to long-term stability of the on-disk format. This means Icechunk can't yet be used for production uses which require long-term persistence of data.</p> <p>\ud83d\ude05 Don't worry! We are working as fast as we can and aim to release v1.0 soon!</p>"},{"location":"faq/#is-icechunk-fast","title":"Is Icechunk fast?","text":"<p>We have not yet begun the process of optimizing Icechunk for performance. Our focus so far has been on correctness and delivering the features needed for full interoperability with Zarr and Xarray.</p> <p>However, preliminary investigations indicate that Icechunk is at least as fast as the existing Zarr / Dask / fsspec stack and in many cases achieves significantly lower latency and higher throughput. Furthermore, Icechunk achieves this without using Dask, by implementing its own asynchronous multithreaded I/O pipeline.</p>"},{"location":"faq/#how-does-icechunk-compare-to-x","title":"How does Icechunk compare to X?","text":""},{"location":"faq/#array-formats","title":"Array Formats","text":"<p>Array formats are file formats for storing multi-dimensional array (tensor) data. Icechunk is an array format. Here is how Icechunk compares to other popular array formats.</p>"},{"location":"faq/#hdf5","title":"HDF5","text":"<p>HDF5 (Hierarchical Data Format version 5) is a popular format for storing scientific data. HDF is widely used in high-performance computing.</p> <ul> <li> <p>Similarities</p> <p>Icechunk and HDF5 share the same data model: multidimensional arrays and metadata organized into a hierarchical tree structure. This data model can accommodate a wide range of different use cases and workflows.</p> <p>Both Icechunk and HDF5 use the concept of \"chunking\" to split large arrays into smaller storage units.</p> </li> <li> <p>Differences</p> <p>HDF5 is a monolithic file format designed first and foremost for POSIX filesystems. All of the chunks in an HDF5 dataset live within a single file. The size of an HDF5 dataset is limited to the size of a single file. HDF5 relies on the filesystem for consistency and is not designed for multiple concurrent yet uncoordinated readers and writers.</p> <p>Icechunk spreads chunks over many files and is designed first and foremost for cloud object storage. Icechunk can accommodate datasets of arbitrary size. Icechunk's optimistic concurrency design allows for safe concurrent access for uncoordinated readers and writers.</p> </li> </ul>"},{"location":"faq/#netcdf","title":"NetCDF","text":"<p>NetCDF (Network Common Data Form) is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.</p> <p>NetCDF4 uses HDF5 as its underlying file format. Therefore, the similarities and differences with Icechunk are fundamentally the same.</p> <p>Icechunk can accommodate the NetCDF data model. It's possible to write NetCDF compliant data in Icechunk using Xarray.</p>"},{"location":"faq/#zarr","title":"Zarr","text":"<p>Icechunk works together with Zarr. (See What is Icechunk's relationship to Zarr? for more detail.)</p> <p>Compared to regular Zarr (without Icechunk), Icechunk offers many benefits, including</p> <ul> <li>Serializable isolation of updates via transactions</li> <li>Data version control (snapshots, branches, tags)</li> <li>Ability to store references to chunks in external datasets (HDF5, NetCDF, GRIB, etc.)</li> <li>A Rust-optimized I/O layer for communicating with object storage</li> </ul>"},{"location":"faq/#cloud-optimized-geotiff-cog","title":"Cloud Optimized GeoTiff (CoG)","text":"<p>A Cloud Optimized GeoTIFF (COG) is a regular GeoTIFF file, aimed at being hosted on a HTTP file server, with an internal organization that enables more efficient workflows on the cloud. It does this by leveraging the ability of clients issuing \u200bHTTP GET range requests to ask for just the parts of a file they need.</p> <p>CoG has become very popular in the geospatial community as a cloud-native format for raster data. A CoG file contains a single image (possibly with multiple bands), sharded into chunks of an appropriate size. A CoG also contains \"overviews,\" lower resolution versions of the same data. Finally, a CoG contains relevant geospatial metadata regarding projection, CRS, etc. which allow georeferencing of the data.</p> <p>Data identical to what is found in a CoG can be stored in the Zarr data model and therefore in an Icechunk repo. Furthermore, Zarr / Icechunk can accommodate rasters of arbitrarily large size and facilitate massive-scale concurrent writes (in addition to reads); A CoG, in contrast, is limited to a single file and thus has limitations on scale and write concurrency.</p> <p>However, Zarr and Icechunk currently do not offer the same level of broad geospatial interoperability that CoG does. The GeoZarr project aims to change that.</p>"},{"location":"faq/#tiledb-embedded","title":"TileDB Embedded","text":"<p>TileDB Embedded is an innovative array storage format that bears many similarities to both Zarr and Icechunk. Like TileDB Embedded, Icechunk aims to provide database-style features on top of the array data model. Both technologies use an embedded / serverless architecture, where client processes interact directly with data files in storage, rather than through a database server. However, there are a number of difference, enumerated below.</p> <p>The following table compares Zarr + Icechunk with TileDB Embedded in a few key areas</p> feature Zarr + Icechunk TileDB Embedded Comment atomicity atomic updates can span multiple arrays and groups array fragments limited to a single array Icechunk's model allows a writer to stage many updates across interrelated arrays into a single transaction. concurrency and isolation serializable isolation of transactions eventual consistency While both formats enable lock-free concurrent reading and writing, Icechunk can catch (and potentially reject) inconsistent, out-of order updates. versioning snapshots, branches, tags linear version history Icechunk's data versioning model is closer to Git's. unit of storage chunk tile (basically the same thing) minimum write chunk cell TileDB allows atomic updates to individual cells, while Zarr requires writing an entire chunk. sparse arrays Zarr + Icechunk do not currently support sparse arrays. virtual chunk references Icechunk enables references to chunks in other file formats (HDF5, NetCDF, GRIB, etc.), while TileDB does not. <p>Beyond this list, there are numerous differences in the design, file layout, and implementation of Icechunk and TileDB embedded which may lead to differences in suitability and performance for different workfloads.</p>"},{"location":"faq/#safetensors","title":"SafeTensors","text":"<p>SafeTensors is a format developed by HuggingFace for storing tensors (arrays) safely, in contrast to Python pickle objects.</p> <p>By the same criteria Icechunk and Zarr are also \"safe\", in that it is impossible to trigger arbitrary code execution when reading data.</p> <p>SafeTensors is a single-file format, like HDF5, SafeTensors optimizes for a simple on-disk layout that facilitates mem-map-based zero-copy reading in ML training pipelines, assuming that the data are being read from a local POSIX filesystem Zarr and Icechunk instead allow for flexible chunking and compression to optimize I/O against object storage.</p>"},{"location":"faq/#tabular-formats","title":"Tabular Formats","text":"<p>Tabular formats are for storing tabular data. Tabular formats are extremely prevalent in general-purpose data analytics but are less widely used in scientific domains. The tabular data model is different from Icechunk's multidimensional array data model, and so a direct comparison is not always apt. However, Icechunk is inspired by many tabular file formats, and there are some notable similarities.</p>"},{"location":"faq/#apache-parquet","title":"Apache Parquet","text":"<p>Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval. It provides high performance compression and encoding schemes to handle complex data in bulk and is supported in many programming language and analytics tools.</p> <p>Parquet employs many of the same core technological concepts used in Zarr + Icechunk such as chunking, compression, and efficient metadata access in a cloud context. Both formats support a range of different numerical data types. Both are \"columnar\" in the sense that different columns / variables / arrays can be queried efficiently without having to fetch unwanted data from other columns. Both also support attaching arbitrary key-value metadata to variables. Parquet supports \"nested\" types like variable-length lists, dicts, etc. that are currently unsupported in Zarr (but may be possible in the future).</p> <p>In general, Parquet and other tabular formats can't be substituted for Zarr / Icechunk, due to the lack of multidimensional array support. On the other hand, tabular data can be modeled in Zarr / Icechunk in a relatively straightforward way: each column as a 1D array, and a table / dataframe as a group of same-sized 1D arrays.</p>"},{"location":"faq/#apache-iceberg","title":"Apache Iceberg","text":"<p>Iceberg is a high-performance format for huge analytic tables. Iceberg brings the reliability and simplicity of SQL tables to big data, while making it possible for engines like Spark, Trino, Flink, Presto, Hive and Impala to safely work with the same tables, at the same time.</p> <p>Iceberg is commonly used to manage many Parquet files as a single table in object storage.</p> <p>Iceberg was influential in the design of Icechunk. Many of the spec core requirements are similar to Iceberg. Specifically, both formats share the following properties:</p> <ul> <li>Files written to object storage immutably</li> <li>All data and metadata files are tracked explicitly by manifests</li> <li>Similar mechanism for staging snapshots and committing transactions</li> <li>Support for branches and tags</li> </ul> <p>However, unlike Iceberg, Icechunk does not require an external catalog to commit transactions; it relies solely on the consistency of the object store.</p>"},{"location":"faq/#delta-lake","title":"Delta Lake","text":"<p>Delta is another popular table format based on a log of updates to the table state. Its functionality and design is quite similar to Iceberg, as is its comparison to Icechunk.</p>"},{"location":"faq/#lance","title":"Lance","text":"<p>Lance is a modern columnar data format that is optimized for ML workflows and datasets.</p> <p>Despite its focus on multimodal data, as a columnar format, Lance can't accommodate large arrays / tensors chunked over arbitrary dimensions, making it fundamentally different from Icechunk.</p> <p>However, the modern design of Lance was very influential on Icechunk. Icechunk's commit and conflict resolution mechanism is partly inspired by Lance.</p>"},{"location":"faq/#other-related-projects","title":"Other Related projects","text":""},{"location":"faq/#xarray","title":"Xarray","text":"<p>Xarray is an open source project and Python package that introduces labels in the form of dimensions, coordinates, and attributes on top of raw NumPy-like arrays, which allows for more intuitive, more concise, and less error-prone user experience.</p> <p>Xarray includes a large and growing library of domain-agnostic functions for advanced analytics and visualization with these data structures.</p> <p>Xarray and Zarr / Icechunk work great together! Xarray is the recommended way to read and write Icechunk data for Python users in geospatial, weather, climate, and similar domains.</p>"},{"location":"faq/#kerchunk","title":"Kerchunk","text":"<p>Kerchunk is a library that provides a unified way to represent a variety of chunked, compressed data formats (e.g. NetCDF/HDF5, GRIB2, TIFF, \u2026), allowing efficient access to the data from traditional file systems or cloud object storage. It also provides a flexible way to create virtual datasets from multiple files. It does this by extracting the byte ranges, compression information and other information about the data and storing this metadata in a new, separate object. This means that you can create a virtual aggregate dataset over potentially many source files, for efficient, parallel and cloud-friendly in-situ access without having to copy or translate the originals. It is a gateway to in-the-cloud massive data processing while the data providers still insist on using legacy formats for archival storage</p> <p>Kerchunk emerged from the Pangeo community as an experimental way of reading archival files, allowing those files to be accessed \"virtually\" using the Zarr protocol. Kerchunk pioneered the concept of a \"chunk manifest\", a file containing references to compressed binary chunks in other files in the form of the tuple <code>(uri, offset, size)</code>. Kerchunk has experimented with different ways of serializing chunk manifests, including JSON and Parquet.</p> <p>Icechunk provides a highly efficient and scalable mechanism for storing and tracking the references generated by Kerchunk. Kerchunk and Icechunk are highly complimentary.</p>"},{"location":"faq/#virtualizarr","title":"VirtualiZarr","text":"<p>VirtualiZarr creates virtual Zarr stores for cloud-friendly access to archival data, using familiar Xarray syntax.</p> <p>VirtualiZarr provides another way of generating and manipulating Kerchunk-style references. VirtualiZarr first uses Kerchunk to generate virtual references, but then provides a simple Xarray-based interface for manipulating those references. As VirtualiZarr can also write virtual references into an Icechunk Store directly, together they form a complete pipeline for generating and storing references to multiple pre-existing files.</p>"},{"location":"faq/#lakefs","title":"LakeFS","text":"<p>LakeFS is a solution git-style version control on top of cloud object storage. LakeFS enables git-style commits, tags, and branches representing the state of an entire object storage bucket.</p> <p>LakeFS is format agnostic and can accommodate any type of data, including Zarr. LakeFS can therefore be used to create a versioned Zarr store, similar to Icechunk.</p> <p>Icechunk, however, is designed specifically for array data, based on the Zarr data model. This specialization enables numerous optimizations and user-experience enhancements not possible with LakeFS.</p> <p>LakeFS also requires a server to operate. Icechunk, in contrast, works with just object storage.</p>"},{"location":"faq/#tensorstore","title":"TensorStore","text":"<p>TensorStore is a library for efficiently reading and writing large multi-dimensional arrays.</p> <p>TensorStore can read and write a variety of different array formats, including Zarr.</p> <p>While TensorStore is not yet compatible with Icechunk, it should be possible to implement Icechunk support in TensorStore.</p> <p>TensorStore implements an ocdbt:</p> <p>The ocdbt driver implements an Optionally-Cooperative Distributed B+Tree (OCDBT) on top of a base key-value store.</p> <p>Ocdbt implements a transactional, versioned key-value store suitable for storing Zarr data, thereby supporting some of the same features as Icechunk. Unlike Icechunk, the ocdbt key-value store is not specialized to Zarr, does not differentiate between chunk or metadata keys, and does not store any metadata about chunks.</p>"},{"location":"icechunk-rust/","title":"Rust","text":"<p>Home / icechunk-rust</p>"},{"location":"icechunk-rust/#icechunk-rust","title":"Icechunk Rust","text":"<p>The Icechunk rust library is used internally by Icechunk Python. It is currently not designed to be used in standalone form.</p> <ul> <li>Icechunk Rust Documentation at docs.rs</li> </ul> <p>We welcome contributors interested in implementing more Rust functionality! In particular, we would love to integrate Icechunk with zarrs, a new Zarr Rust library.</p>"},{"location":"overview/","title":"Overview","text":"<p>Home / overview</p>"},{"location":"overview/#icechunk","title":"Icechunk","text":"<p>Icechunk is an open-source (Apache 2.0), transactional storage engine for tensor / ND-array data designed for use on cloud object storage. Icechunk works together with Zarr, augmenting the Zarr core data model with features that enhance performance, collaboration, and safety in a cloud-computing context.</p>"},{"location":"overview/#docs-organization","title":"Docs Organization","text":"<p>This is the Icechunk documentation. It's organized into the following parts.</p> <ul> <li>This page: a general overview of the project's goals and components.</li> <li>Frequently Asked Questions</li> <li>Documentation for Icechunk Python, the main user-facing   library</li> <li>Documentation for the Icechunk Rust Crate</li> <li>The Icechunk Spec</li> </ul>"},{"location":"overview/#icechunk-overview","title":"Icechunk Overview","text":"<p>Let's break down what \"transactional storage engine for Zarr\" actually means:</p> <ul> <li>Zarr is an open source specification for the storage of multidimensional array (a.k.a. tensor) data.   Zarr defines the metadata for describing arrays (shape, dtype, etc.) and the way these arrays are chunked, compressed, and converted to raw bytes for storage. Zarr can store its data in any key-value store.   There are many different implementations of Zarr in different languages. Right now, Icechunk only supports   Zarr Python.   If you're interested in implementing Icehcunk support, please open an issue so we can help you.</li> <li>Storage engine - Icechunk exposes a key-value interface to Zarr and manages all of the actual I/O for getting, setting, and updating both metadata and chunk data in cloud object storage.   Zarr libraries don't have to know exactly how icechunk works under the hood in order to use it.</li> <li>Transactional - The key improvement that Icechunk brings on top of regular Zarr is to provide consistent serializable isolation between transactions.   This means that Icechunk data are safe to read and write in parallel from multiple uncoordinated processes.   This allows Zarr to be used more like a database.</li> </ul> <p>The core entity in Icechunk is a repository or repo. A repo is defined as a Zarr hierarchy containing one or more Arrays and Groups, and a repo functions as self-contained Zarr Store. The most common scenario is for an Icechunk repo to contain a single Zarr group with multiple arrays, each corresponding to different physical variables but sharing common spatiotemporal coordinates. However, formally a repo can be any valid Zarr hierarchy, from a single Array to a deeply nested structure of Groups and Arrays. Users of Icechunk should aim to scope their repos only to related arrays and groups that require consistent transactional updates.</p> <p>Icechunk supports the following core requirements:</p> <ol> <li>Object storage - the format is designed around the consistency features and performance characteristics available in modern cloud object storage. No external database or catalog is required to maintain a repo. (It also works with file storage.)</li> <li>Serializable isolation - Reads are isolated from concurrent writes and always use a committed snapshot of a repo. Writes are committed atomically and are never partially visible. No locks are required for reading.</li> <li>Time travel - Previous snapshots of a repo remain accessible after new ones have been written.</li> <li>Data version control - Repos support both tags (immutable references to snapshots) and branches (mutable references to snapshots).</li> <li>Chunk shardings - Chunk storage is decoupled from specific file names. Multiple chunks can be packed into a single object (sharding).</li> <li>Chunk references - Zarr-compatible chunks within other file formats (e.g. HDF5, NetCDF) can be referenced.</li> <li>Schema evolution - Arrays and Groups can be added, renamed, and removed from the hierarchy with minimal overhead.</li> </ol>"},{"location":"overview/#key-concepts","title":"Key Concepts","text":""},{"location":"overview/#groups-arrays-and-chunks","title":"Groups, Arrays, and Chunks","text":"<p>Icechunk is designed around the Zarr data model, widely used in scientific computing, data science, and AI / ML. (The Zarr high-level data model is effectively the same as HDF5.) The core data structure in this data model is the array. Arrays have two fundamental properties:</p> <ul> <li>shape - a tuple of integers which specify the dimensions of each axis of the array. A 10 x 10 square array would have shape (10, 10)</li> <li>data type - a specification of what type of data is found in each element, e.g. integer, float, etc. Different data types have different precision (e.g. 16-bit integer, 64-bit float, etc.)</li> </ul> <p>In Zarr / Icechunk, arrays are split into chunks, A chunk is the minimum unit of data that must be read / written from storage, and thus choices about chunking have strong implications for performance. Zarr leaves this completely up to the user. Chunk shape should be chosen based on the anticipated data access pattern for each array An Icechunk array is not bounded by an individual file and is effectively unlimited in size.</p> <p>For further organization of data, Icechunk supports groups within a single repo. Group are like folders which contain multiple arrays and or other groups. Groups enable data to be organized into hierarchical trees. A common usage pattern is to store multiple arrays in a group representing a NetCDF-style dataset.</p> <p>Arbitrary JSON-style key-value metadata can be attached to both arrays and groups.</p>"},{"location":"overview/#snapshots","title":"Snapshots","text":"<p>Every update to an Icechunk store creates a new snapshot with a unique ID. Icechunk users must organize their updates into groups of related operations called transactions. For example, appending a new time slice to multiple arrays should be done as a single transaction, comprising the following steps 1. Update the array metadata to resize the array to accommodate the new elements. 2. Write new chunks for each array in the group.</p> <p>While the transaction is in progress, none of these changes will be visible to other users of the store. Once the transaction is committed, a new snapshot is generated. Readers can only see and use committed snapshots.</p>"},{"location":"overview/#branches-and-tags","title":"Branches and Tags","text":"<p>Additionally, snapshots occur in a specific linear (i.e. serializable) order within  branch. A branch is a mutable reference to a snapshot--a pointer that maps the branch name to a snapshot ID. The default branch is <code>main</code>. Every commit to the main branch updates this reference. Icechunk's design protects against the race condition in which two uncoordinated sessions attempt to update the branch at the same time; only one can succeed.</p> <p>Icechunk also defines tags--immutable references to snapshot. Tags are appropriate for publishing specific releases of a repository or for any application which requires a persistent, immutable identifier to the store state.</p>"},{"location":"overview/#chunk-references","title":"Chunk References","text":"<p>Chunk references are \"pointers\" to chunks that exist in other files--HDF5, NetCDF, GRIB, etc. Icechunk can store these references alongside native Zarr chunks as \"virtual datasets\". You can then can update these virtual datasets incrementally (overwrite chunks, change metadata, etc.) without touching the underlying files.</p>"},{"location":"overview/#how-does-it-work","title":"How Does It Work?","text":"<p>Note</p> <p>For more detailed explanation, have a look at the Icechunk spec</p> <p>Zarr itself works by storing both metadata and chunk data into a abstract store according to a specified system of \"keys\". For example, a 2D Zarr array called <code>myarray</code>, within a group called <code>mygroup</code>, would generate the following keys:</p> <pre><code>mygroup/zarr.json\nmygroup/myarray/zarr.json\nmygroup/myarray/c/0/0\nmygroup/myarray/c/0/1\n</code></pre> <p>In standard regular Zarr stores, these key map directly to filenames in a filesystem or object keys in an object storage system. When writing data, a Zarr implementation will create these keys and populate them with data. When modifying existing arrays or groups, a Zarr implementation will potentially overwrite existing keys with new data.</p> <p>This is generally not a problem, as long there is only one person or process coordinating access to the data. However, when multiple uncoordinated readers and writers attempt to access the same Zarr data at the same time, various consistency problems problems emerge. These consistency problems can occur in both file storage and object storage; they are particularly severe in a cloud setting where Zarr is being used as an active store for data that are frequently changed while also being read.</p> <p>With Icechunk, we keep the same core Zarr data model, but add a layer of indirection between the Zarr keys and the on-disk storage. The Icechunk library translates between the Zarr keys and the actual on-disk data given the particular context of the user's state. Icechunk defines a series of interconnected metadata and data files that together enable efficient isolated reading and writing of metadata and chunks. Once written, these files are immutable. Icechunk keeps track of every single chunk explicitly in a \"chunk manifest\".</p> <pre><code>flowchart TD\n    zarr-python[Zarr Library] &lt;-- key / value--&gt; icechunk[Icechunk Library]\n    icechunk &lt;-- data / metadata files --&gt; storage[(Object Storage)]\n</code></pre>"},{"location":"sample-datasets/","title":"Sample Datasets","text":"<p>Home / sample-datasets</p>"},{"location":"sample-datasets/#sample-datasets","title":"Sample Datasets","text":""},{"location":"sample-datasets/#native-datasets","title":"Native Datasets","text":""},{"location":"sample-datasets/#virtual-datasets","title":"Virtual Datasets","text":""},{"location":"sample-datasets/#noaa-oisst-data","title":"NOAA OISST Data","text":"<p>The NOAA 1/4\u00b0 Daily Optimum Interpolation Sea Surface Temperature (OISST) is a long term Climate Data Record that incorporates observations from different platforms (satellites, ships, buoys and Argo floats) into a regular global grid</p> <p>Check out an example dataset built using all virtual references pointing to daily Sea Surface Temperature data from 2020 to 2024 on NOAA's S3 bucket using python:</p> <pre><code>import icechunk\n\nstorage = icechunk.StorageConfig.s3_anonymous(\n    bucket='earthmover-sample-data',\n    prefix='icechunk/oisst.2020-2024/',\n    region='us-east-1',\n)\n\nrepo = icechunk.Repository.open_existing(storage=storage, mode=\"r\", config=icechunk.RepositoryConfig(\n    virtual_ref_config=icechunk.VirtualRefConfig.s3_anonymous(region='us-east-1'),\n))\n</code></pre> <p></p>"},{"location":"spec/","title":"Specification","text":"<p>Home / spec</p>"},{"location":"spec/#icechunk-specification","title":"Icechunk Specification","text":"<p>!!! Note:     The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in RFC 2119.</p>"},{"location":"spec/#introduction","title":"Introduction","text":"<p>The Icechunk specification is a storage specification for Zarr data. Icechunk is inspired by Apache Iceberg and borrows many concepts and ideas from the Iceberg Spec.</p> <p>This specification describes a single Icechunk repository. A repository is defined as a Zarr store containing one or more Arrays and Groups. The most common scenario is for a repository to contain a single Zarr group with multiple arrays, each corresponding to different physical variables but sharing common spatiotemporal coordinates. However, formally a repository can be any valid Zarr hierarchy, from a single Array to a deeply nested structure of Groups and Arrays. Users of Icechunk should aim to scope their repository only to related arrays and groups that require consistent transactional updates.</p> <p>Icechunk defines a series of interconnected metadata and data files that together comprise the format. All the data and metadata for a repository are stored in a directory in object storage or file storage.</p>"},{"location":"spec/#goals","title":"Goals","text":"<p>The goals of the specification are as follows:</p> <ol> <li>Object storage - the format is designed around the consistency features and performance characteristics available in modern cloud object storage. No external database or catalog is required.</li> <li>Serializable isolation - Reads will be isolated from concurrent writes and always use a committed snapshot of a repository. Writes to repositories will be committed atomically and will not be partially visible. Readers will not acquire locks.</li> <li>Time travel - Previous snapshots of a repository remain accessible after new ones have been written.</li> <li>Chunk sharding and references - Chunk storage is decoupled from specific file names. Multiple chunks can be packed into a single object (sharding). Zarr-compatible chunks within other file formats (e.g. HDF5, NetCDF) can be referenced.</li> <li>Schema Evolution - Arrays and Groups can be added, renamed, and removed from the hierarchy with minimal overhead.</li> </ol>"},{"location":"spec/#non-goals","title":"Non Goals","text":"<ol> <li>Low Latency - Icechunk is designed to support analytical workloads for large repositories. We accept that the extra layers of metadata files and indirection will introduce additional cold-start latency compared to regular Zarr.</li> <li>No Catalog - The spec does not extend beyond a single repository or provide a way to organize multiple repositories into a hierarchy.</li> <li>Access Controls - Access control is the responsibility of the storage medium. The spec is not designed to enable fine-grained access restrictions (e.g. only read specific arrays) within a single repository.</li> </ol>"},{"location":"spec/#storage-operations","title":"Storage Operations","text":"<p>Icechunk requires that the storage system support the following operations:</p> <ul> <li>In-place write - Strong read-after-write and list-after-write consistency is expected. Files are not moved or altered once they are written.</li> <li>Conditional write if-not-exists - For the commit process to be safe and consistent, the storage system must guard against two files of the same name being created at the same time.</li> <li>Seekable reads - Chunk file formats may require seek support (e.g. shards).</li> <li>Deletes - Delete files that are no longer used (via a garbage-collection operation).</li> <li>Sorted List - The storage system must allow the listing of directories / prefixes in a consistent sorted order.</li> </ul> <p>These requirements are compatible with object stores, like S3, as well as with filesystems.</p> <p>The storage system is not required to support random-access writes. Once written, chunk and metadata files are immutable until they are deleted.</p>"},{"location":"spec/#specification","title":"Specification","text":""},{"location":"spec/#overview","title":"Overview","text":"<p>Icechunk uses a series of linked metadata files to describe the state of the repository.</p> <ul> <li>The Snapshot file records all of the different arrays and groups in the repository, plus their metadata. Every new commit creates a new snapshot file. The snapshot file contains pointers to one or more chunk manifest files and [optionally] attribute files.</li> <li>Chunk manifests store references to individual chunks. A single manifest may store references for multiple arrays or a subset of all the references for a single array.</li> <li>Attributes files provide a way to store additional user-defined attributes for arrays and groups outside of the structure file. This is important if attributes are very large, otherwise, they will be stored inline in the snapshot file.</li> <li>Chunk files store the actual compressed chunk data, potentially containing data for multiple chunks in a single file.</li> <li>Reference files track the state of branches and tags, containing a lightweight pointer to a snapshot file. Transactions on a branch are committed by creating the next branch file in a sequence.</li> </ul> <p>When reading from object store, the client opens the latest branch or tag file to obtain a pointer to the relevant snapshot file. The client then reads the snapshot file to determine the structure and hierarchy of the repository. When fetching data from an array, the client first examines the chunk manifest file[s] for that array and finally fetches the chunks referenced therein.</p> <p>When writing a new repository snapshot, the client first writes a new set of chunks and chunk manifests, and then generates a new snapshot file. Finally, in an atomic put-if-not-exists operation, to commit the transaction, it creates the next branch file in the sequence. This operation may fail if a different client has already committed the next snapshot. In this case, the client may attempt to resolve the conflicts and retry the commit.</p> <pre><code>flowchart TD\n    subgraph metadata[Metadata]\n    subgraph reference_files[Reference Files]\n    old_branch[Main Branch File 001]\n    branch[Main Branch File 002]\n    end\n    subgraph snapshots[Snapshots]\n    snapshot1[Snapshot File 1]\n    snapshot2[Snapshot File 2]\n    end\n    subgraph attributes[Attributes]\n    attrs[Attribute File]\n    end\n    subgraph manifests[Manifests]\n    manifestA[Chunk Manifest A]\n    manifestB[Chunk Manifest B]\n    end\n    end\n    subgraph data\n    chunk1[Chunk File 1]\n    chunk2[Chunk File 2]\n    chunk3[Chunk File 3]\n    chunk4[Chunk File 4]\n    end\n\n    branch -- snapshot ID --&gt; snapshot2\n    snapshot1 --&gt; attrs\n    snapshot1 --&gt; manifestA\n    snapshot2 --&gt; attrs\n    snapshot2 --&gt;manifestA\n    snapshot2 --&gt;manifestB\n    manifestA --&gt; chunk1\n    manifestA --&gt; chunk2\n    manifestB --&gt; chunk3\n    manifestB --&gt; chunk4\n\n</code></pre>"},{"location":"spec/#file-layout","title":"File Layout","text":"<p>All data and metadata files are stored within a root directory (typically a prefix within an object store) using the following directory structure.</p> <ul> <li><code>$ROOT</code> base URI (s3, gcs, local directory, etc.)</li> <li><code>$ROOT/refs/</code> reference files</li> <li><code>$ROOT/snapshots/</code> snapshot files</li> <li><code>$ROOT/attributes/</code> attribute files</li> <li><code>$ROOT/manifests/</code> chunk manifests</li> <li><code>$ROOT/chunks/</code> chunks</li> </ul>"},{"location":"spec/#file-formats","title":"File Formats","text":"<p>Warning</p> <p>The actual file formats used for each type of metadata file are in flux. The spec currently describes the data structures encoded in these files, rather than a specific file format.</p>"},{"location":"spec/#reference-files","title":"Reference Files","text":"<p>Similar to Git, Icechunk supports the concept of branches and tags. These references point to a specific snapshot of the repository.</p> <ul> <li>Branches are mutable references to a snapshot.   Repositories may have one or more branches.   The default branch name is <code>main</code>.   Repositories must always have a <code>main</code> branch, which is used to detect the existence of a valid repository in a given path.   After creation, branches may be updated to point to a different snapshot.</li> <li>Tags are immutable references to a snapshot.   A repository may contain zero or more tags.   After creation, tags may never be updated, unlike in Git.</li> </ul> <p>References are very important in the Icechunk design. Creating or updating references is the point at which consistency and atomicity of Icechunk transactions is enforced. Different client sessions may simultaneously create two inconsistent snapshots; however, only one session may successfully update a reference to point it to its snapshot.</p> <p>References (both branches and tags) are stored as JSON files, the content is a JSON object with:</p> <ul> <li>keys: a single key <code>\"snapshot\"</code>,</li> <li>value: a string representation of the snapshot id, using Base 32 Crockford encoding. The snapshot id is 12 byte random binary, so the encoded string has 20 characters.</li> </ul> <p>Here is an example of a JSON file corresponding to a tag or branch:</p> <pre><code>{\"snapshot\":\"VY76P925PRY57WFEK410\"}\n</code></pre>"},{"location":"spec/#creating-and-updating-branches","title":"Creating and Updating Branches","text":"<p>The process of creating and updating branches is designed to use the limited consistency guarantees offered by object storage to ensure transactional consistency. When a client checks out a branch, it obtains a specific snapshot ID and uses this snapshot as the basis for any changes it creates during its session. The client creates a new snapshot and then updates the branch reference to point to the new snapshot (a \"commit\"). However, when updating the branch reference, the client must detect whether a different session has updated the branch reference in the interim, possibly retrying or failing the commit if so. This is an \"optimistic concurrency\" strategy; the resolution mechanism can be expensive, but conflicts are expected to be infrequent.</p> <p>All popular object stores support a \"create if not exists\" operation. In other words, object stores can guard against the race condition which occurs when two sessions attempt to create the same file at the same time. This motivates the design of Icechunk's branch file naming convention.</p> <p>Each commit to an Icechunk branch augments a counter called the sequence number. The first commit creates sequence number 0. The next commit creates sequence number 1. Etc. This sequence number is encoded into the branch reference file name.</p> <p>When a client checks out a branch, it keeps track of its current sequence number N. When it tries to commit, it attempts to create the file corresponding to sequence number N + 1 in an atomic \"create if not exists\" operation. If this succeeds, the commit is successful. If this fails (because another client created that file already), the commit fails. At this point, the client may choose to retry its commit (possibly re-reading the updated data) and then create sequence number N + 2.</p> <p>Branch references are stored in the <code>refs/</code> directory within a subdirectory corresponding to the branch name prepended by the string <code>branch.</code>: <code>refs/branch.$BRANCH_NAME/</code>. Branch names may not contain the <code>/</code> character.</p> <p>To facilitate easy lookups of the latest branch reference, we use the following encoding for the sequence number: - subtract the sequence number from the integer <code>1099511627775</code> - encode the resulting integer as a string using Base 32 Crockford - left-padding the string with 0s to a length of 8 characters This produces a deterministic sequence of branch file names in which the latest sequence always appears first when sorted lexicographically, facilitating easy lookup by listing the object store.</p> <p>The full branch file name is then given by <code>refs/branch.$BRANCH_NAME/$ENCODED_SEQUENCE.json</code>.</p> <p>For example, the first main branch file is in a store, corresponding with sequence number 0, is always named <code>refs/branch.main/ZZZZZZZZ.json</code>. The branch file for sequence number 100 is <code>refs/branch.main/ZZZZZZWV.json</code>. The maximum number of commits allowed in an Icechunk repository is consequently <code>1099511627775</code>, corresponding to the state file <code>refs/branch.main/00000000.json</code>.</p>"},{"location":"spec/#tags","title":"Tags","text":"<p>Since tags are immutable, they are simpler than branches.</p> <p>Tag files follow the pattern <code>refs/tag.$TAG_NAME/ref.json</code>.</p> <p>Tag names may not contain the <code>/</code> character.</p> <p>When creating a new tag, the client attempts to create the tag file using a \"create if not exists\" operation. If successful, the tag is created successful. If not, that means another client has already created that tag.</p> <p>Tags cannot be deleted once created.</p>"},{"location":"spec/#snapshot-files","title":"Snapshot Files","text":"<p>The snapshot file fully describes the schema of the repository, including all arrays and groups.</p> <p>The snapshot file is currently encoded using MessagePack, but this may change before Icechunk version 1.0. Given the alpha status of this spec, the best way to understand the information stored in the snapshot file is through the data structure used internally by the Icechunk library for serialization. This data structure will most certainly change before the spec stabilization:</p> <pre><code>pub struct Snapshot {\n    pub icechunk_snapshot_format_version: IcechunkFormatVersion,\n    pub icechunk_snapshot_format_flags: BTreeMap&lt;String, rmpv::Value&gt;,\n\n    pub manifest_files: Vec&lt;ManifestFileInfo&gt;,\n    pub attribute_files: Vec&lt;AttributeFileInfo&gt;,\n\n    pub total_parents: u32,\n    pub short_term_parents: u16,\n    pub short_term_history: VecDeque&lt;SnapshotMetadata&gt;,\n\n    pub metadata: SnapshotMetadata,\n    pub started_at: DateTime&lt;Utc&gt;,\n    pub properties: SnapshotProperties,\n    nodes: BTreeMap&lt;Path, NodeSnapshot&gt;,\n}\n</code></pre> <p>To get full details on what each field contains, please refer to the Icechunk library code.</p>"},{"location":"spec/#attributes-files","title":"Attributes Files","text":"<p>Attribute files hold user-defined attributes separately from the snapshot file.</p> <p>Warning</p> <p>Attribute files have not been implemented.</p> <p>The on-disk format for attribute files has not been defined yet, but it will probably be a MessagePack serialization of the attributes map.</p>"},{"location":"spec/#chunk-manifest-files","title":"Chunk Manifest Files","text":"<p>A chunk manifest file stores chunk references. Chunk references from multiple arrays can be stored in the same chunk manifest. The chunks from a single array can also be spread across multiple manifests.</p> <p>Manifest files are currently encoded using MessagePack, but this may change before Icechunk version 1.0. Given the alpha status of this spec, the best way to understand the information stored in the snapshot file is through the data structure used internally by the Icechunk library. This data structure will most certainly change before the spec stabilization:</p> <pre><code>pub struct Manifest {\n    pub icechunk_manifest_format_version: IcechunkFormatVersion,\n    pub icechunk_manifest_format_flags: BTreeMap&lt;String, rmpv::Value&gt;,\n    chunks: BTreeMap&lt;(NodeId, ChunkIndices), ChunkPayload&gt;,\n}\n\npub enum ChunkPayload {\n    Inline(Bytes),\n    Virtual(VirtualChunkRef),\n    Ref(ChunkRef),\n}\n</code></pre> <p>The most important part to understand from the data structure is the fact that manifests can hold three types of references:</p> <ul> <li>Native (<code>Ref</code>), pointing to the id of a chunk within the Icechunk repository.</li> <li>Inline (<code>Inline</code>), an optimization for very small chunks that can be embedded directly in the manifest. Mostly used for coordinate arrays.</li> <li>Virtual (<code>Virtual</code>), pointing to a region of a file outside of the Icechunk repository, for example,   a chunk that is inside a NetCDF file in object store</li> </ul> <p>To get full details on what each field contains, please refer to the Icechunk library code.</p>"},{"location":"spec/#chunk-files","title":"Chunk Files","text":"<p>Chunk files contain the compressed binary chunks of a Zarr array. Icechunk permits quite a bit of flexibility about how chunks are stored. Chunk files can be:</p> <ul> <li>One chunk per chunk file (i.e. standard Zarr)</li> <li>Multiple contiguous chunks from the same array in a single chunk file (similar to Zarr V3 shards)</li> <li>Chunks from multiple different arrays in the same file</li> <li>Other file types (e.g. NetCDF, HDF5) which contain Zarr-compatible chunks</li> </ul> <p>Applications may choose to arrange chunks within files in different ways to optimize I/O patterns.</p>"},{"location":"spec/#algorithms","title":"Algorithms","text":""},{"location":"spec/#initialize-new-repository","title":"Initialize New Repository","text":"<p>A new repository is initialized by creating a new [possibly empty] snapshot file and then creating the first file in the main branch sequence.</p> <p>If another client attempts to initialize a repository in the same location, only one can succeed.</p>"},{"location":"spec/#read-from-repository","title":"Read from Repository","text":""},{"location":"spec/#from-snapshot-id","title":"From Snapshot ID","text":"<p>If the specific snapshot ID is known, a client can open it directly in read only mode.</p> <ol> <li>Use the specified snapshot ID to fetch the snapshot file.</li> <li>Fetch desired attributes and values from arrays.</li> </ol>"},{"location":"spec/#from-branch","title":"From Branch","text":"<p>Usually, a client will want to read from the latest branch (e.g. <code>main</code>).</p> <ol> <li>List the object store prefix <code>refs/branch.$BRANCH_NAME/</code> to obtain the latest branch file in the sequence. Due to the encoding of the sequence number, this should be the first file in lexicographical order.</li> <li>Read the branch file JSON contents to obtain the snapshot ID.</li> <li>Use the snapshot ID to fetch the snapshot file.</li> <li>Fetch desired attributes and values from arrays.</li> </ol>"},{"location":"spec/#from-tag","title":"From Tag","text":"<ol> <li>Read the tag file found at <code>refs/tag.$TAG_NAME/ref.json</code> to obtain the snapshot ID.</li> <li>Use the snapshot ID to fetch the snapshot file.</li> <li>Fetch desired attributes and values from arrays.</li> </ol>"},{"location":"spec/#write-new-snapshot","title":"Write New Snapshot","text":"<ol> <li>Open a repository at a specific branch as described above, keeping track of the sequence number and branch name in the session context.</li> <li>[optional] Write new chunk files.</li> <li>[optional] Write new chunk manifests.</li> <li>Write a new snapshot file.</li> <li>Attempt to write the next branch file in the sequence<ol> <li>If successful, the commit succeeded and the branch is updated.</li> <li>If unsuccessful, attempt to reconcile and retry the commit.</li> </ol> </li> </ol>"},{"location":"spec/#create-new-tag","title":"Create New Tag","text":"<p>A tag can be created from any snapshot.</p> <ol> <li>Open the repository at a specific snapshot.</li> <li>Attempt to create the tag file.    a. If successful, the tag was created.    b. If unsuccessful, the tag already exists.</li> </ol>"},{"location":"icechunk-python/","title":"Index","text":"<p>Home / icechunk-python</p>"},{"location":"icechunk-python/#index-of-icechunk-python","title":"Index of icechunk-python","text":"<ul> <li>developing</li> <li>examples</li> <li>notebooks</li> <li>quickstart</li> <li>distributed</li> <li>reference</li> </ul>"},{"location":"icechunk-python/concurrency/","title":"Concurrency","text":"<p>Home / icechunk-python / concurrency</p>"},{"location":"icechunk-python/concurrency/#concurrency","title":"Concurrency","text":"<p>TODO: describe the general approach to concurrency in Icechunk</p>"},{"location":"icechunk-python/concurrency/#built-in-concurrency","title":"Built-in concurrency","text":"<p>Describe the multi-threading and async concurrency in Icechunk / Zarr</p>"},{"location":"icechunk-python/concurrency/#distributed-concurrency-within-a-single-transaction","title":"Distributed concurrency within a single transaction","text":"<p>\"Cooperative\" concurrency</p>"},{"location":"icechunk-python/concurrency/#concurrency-across-uncoordinated-sessions","title":"Concurrency across uncoordinated sessions","text":""},{"location":"icechunk-python/concurrency/#conflict-detection","title":"Conflict detection","text":""},{"location":"icechunk-python/configuration/","title":"Configuration","text":"<p>Home / icechunk-python / configuration</p>"},{"location":"icechunk-python/configuration/#configuration","title":"Configuration","text":"<p>When creating and opening Icechunk stores, there are a two different sets of configuration to be aware of:</p> <ul> <li><code>StorageConfig</code> - for configuring access to the object store or filesystem</li> <li><code>RepositoryConfig</code> - for configuring the behavior of the Icechunk Repository itself</li> </ul>"},{"location":"icechunk-python/configuration/#storage-config","title":"Storage Config","text":"<p>Icechunk can be confirgured to work with both object storage and filesystem backends. The storage configuration defines the location of an Icechunk store, along with any options or information needed to access data from a given storage type.</p>"},{"location":"icechunk-python/configuration/#s3-storage","title":"S3 Storage","text":"<p>When using Icechunk with s3 compatible storage systems, credentials must be provided to allow access to the data on the given endpoint. Icechunk allows for creating the storage config for s3 in three ways:</p> From environmentProvide credentialsAnonymous <p>With this option, the credentials for connecting to S3 are detected automatically from your environment. This is usually the best choice if you are connecting from within an AWS environment (e.g. from EC2). See the API</p> <pre><code>icechunk.StorageConfig.s3_from_env(\n    bucket=\"icechunk-test\",\n    prefix=\"quickstart-demo-1\"\n)\n</code></pre> <p>With this option, you provide your credentials and other details explicitly. See the API</p> <pre><code>icechunk.StorageConfig.s3_from_config(\n    bucket=\"icechunk-test\",\n    prefix=\"quickstart-demo-1\",\n    region='us-east-1',\n    credentials=S3Credentials(\n        access_key_id='my-access-key',\n        secret_access_key='my-secret-key',\n        # session token is optional\n        session_token='my-token',\n    ),\n    endpoint_url=None,\n    allow_http=False,\n)\n</code></pre> <p>With this option, you connect to S3 anonymously (without credentials). This is suitable for public data. See the API</p> <pre><code>icechunk.StorageConfig.s3_anonymous(\n    bucket=\"icechunk-test\",\n    prefix=\"quickstart-demo-1\",\n    region='us-east-1,\n)\n</code></pre>"},{"location":"icechunk-python/configuration/#filesystem-storage","title":"Filesystem Storage","text":"<p>Icechunk can also be used on a local filesystem by providing a path to the location of the store</p> Local filesystem <pre><code>icechunk.StorageConfig.filesystem(\"/path/to/my/dataset\")\n</code></pre>"},{"location":"icechunk-python/configuration/#repository-config","title":"Repository Config","text":"<p>Separate from the storage config, the Repository can also be configured with options which control its runtime behavior.</p>"},{"location":"icechunk-python/configuration/#writing-chunks-inline","title":"Writing chunks inline","text":"<p>Chunks can be written inline alongside the store metadata if the size of a given chunk falls within the configured threshold. Inlining allows these small chunks (often used to store small coordinate variables) to be accessed more quickly. This is the default behavior for chunks smaller than 512 bytes, but it can be overridden using the <code>inline_chunk_threshold_bytes</code> option:</p> Never write chunks inlineWrite bigger chunks inline <pre><code>RepositoryConfig(\n    inline_chunk_threshold_bytes=0,\n    ...\n)\n</code></pre> <pre><code>RepositoryConfig(\n    inline_chunk_threshold_bytes=1024,\n    ...\n)\n</code></pre>"},{"location":"icechunk-python/configuration/#virtual-reference-storage-config","title":"Virtual Reference Storage Config","text":"<p>Icechunk allows for reading \"Virtual\" data from existing archival datasets. This requires creating a distinct <code>VirtualRefConfig</code> (similar to <code>StorageConfig</code>) giving Icechunk the necessary permissions to access the archival data. This can be configured using the <code>virtual_ref_config</code> option:</p> S3 from environmentS3 with credentialsS3 Anonymous <pre><code>RepositoryConfig(\n    virtual_ref_config=VirtualRefConfig.s3_from_env(),\n    ...\n)\n</code></pre> <pre><code>RepositoryConfig(\n    virtual_ref_config=VirtualRefConfig.s3_from_config(\n        credential=S3Credentials(\n            access_key_id='my-access-key',\n            secret_access_key='my-secret-key',\n        ),\n        region='us-east-1'\n    ),\n    ...\n)\n</code></pre> <pre><code>RepositoryConfig(\n    virtual_ref_config=VirtualRefConfig.s3_anonymous(region='us-east-1'),\n    ...\n)\n</code></pre>"},{"location":"icechunk-python/configuration/#creating-and-opening-repos","title":"Creating and Opening Repos","text":"<p>Now we can now create or open an Icechunk store using our config.</p>"},{"location":"icechunk-python/configuration/#creating-a-new-repo","title":"Creating a new repo","text":"<p>Note</p> <p>Icechunk repos cannot be created in the same location where another store already exists.</p> Creating with S3 storageCreating with local filesystem <pre><code>storage = icechunk.StorageConfig.s3_from_env(\n    bucket='earthmover-sample-data',\n    prefix='icechunk/oisst.2020-2024/',\n    region='us-east-1',\n)\n\nrepo = icechunk.Repository.create(\n    storage=storage,\n)\n</code></pre> <pre><code>storage = icechunk.StorageConfig.filesystem(\"/path/to/my/dataset\")\nconfig = icechunk.RepositoryConfig(\n    inline_chunk_threshold_bytes=1024,\n)\n\nrepo = icechunk.Repository.create(\n    storage=storage,\n)\n</code></pre> <p>If you are not sure if the repo exists yet, an <code>icechunk Repository</code> can created or opened if it already exists:</p> Open or creating with S3 storageOpen or creating with local filesystem <pre><code>storage = icechunk.StorageConfig.s3_from_env(\n    bucket='earthmover-sample-data',\n    prefix='icechunk/oisst.2020-2024/',\n    region='us-east-1',\n)\n\nrepo = icechunk.Repository.open_or_create(\n    storage=storage,\n)\n</code></pre> <pre><code>storage = icechunk.StorageConfig.filesystem(\"/path/to/my/dataset\")\nconfig = icechunk.RepositoryConfig(\n    inline_chunk_threshold_bytes=1024,\n)\n\nrepo = icechunk.Repository.open_or_create(\n    storage=storage,\n)\n</code></pre>"},{"location":"icechunk-python/configuration/#opening-an-existing-repo","title":"Opening an existing repo","text":"Opening from S3 StorageOpening from local filesystem <pre><code>storage = icechunk.StorageConfig.s3_anonymous(\n    bucket='earthmover-sample-data',\n    prefix='icechunk/oisst.2020-2024/',\n    region='us-east-1',\n)\n\nconfig = icechunk.RepositoryConfig(\n    virtual_ref_config=icechunk.VirtualRefConfig.s3_anonymous(region='us-east-1'),\n)\n\nrepo = icechunk.Repository.open_existing(\n    storage=storage,\n    config=config,\n)\n</code></pre> <pre><code>storage = icechunk.StorageConfig.filesystem(\"/path/to/my/dataset\")\nconfig = icechunk.RepositoryConfig(\n    inline_chunk_threshold_bytes=1024,\n)\n\nstore = icechunk.IcechunkStore.open_existing(\n    storage=storage,\n    config=config,\n)\n</code></pre>"},{"location":"icechunk-python/dask/","title":"Dask","text":"<p>Home / icechunk-python / dask</p>"},{"location":"icechunk-python/dask/#distributed-writes-with-dask","title":"Distributed Writes with dask","text":"<p>You can use Icechunk in conjunction with Xarray and Dask to perform large-scale distributed writes from a multi-node cluster. However, because of how Icechunk works, it's not possible to use the existing <code>Dask.Array.to_zarr</code> or <code>Xarray.Dataset.to_zarr</code> functions with either the Dask multiprocessing or distributed schedulers. (It is fine with the multithreaded scheduler.)</p> <p>Instead, Icechunk provides its own specialized functions to make distributed writes with Dask and Xarray. This page explains how to use these specialized functions.</p> <p>Note</p> <p>Using Xarray, Dask, and Icechunk requires <code>icechunk&gt;=0.1.0a5</code>, <code>dask&gt;=2024.11.0</code>, and <code>xarray&gt;=2024.11.0</code>.</p> <p>First let's start a distributed Client and create an IcechunkStore.</p> <pre><code># initialize a distributed Client\nfrom distributed import Client\n\nclient = Client()\n\n# initialize the icechunk store\nfrom icechunk import Repository, StorageConfig\n\nstorage_config = StorageConfig.filesystem(\"./icechunk-xarray\")\nicechunk_repo = Repository.create(storage_config)\nicechunk_session = icechunk_repo.writable_session(\"main\")\n</code></pre>"},{"location":"icechunk-python/dask/#icechunk-dask","title":"Icechunk + Dask","text":"<p>Use <code>icechunk.dask.store_dask</code> to write a Dask array to an Icechunk store. The API follows that of <code>dask.array.store</code> without support for the <code>compute</code> kwarg.</p> <p>First create a dask array to write: <pre><code>shape = (100, 100)\ndask_chunks = (20, 20)\ndask_array = dask.array.random.random(shape, chunks=dask_chunks)\n</code></pre></p> <p>Now create the Zarr array you will write to. <pre><code>zarr_chunks = (10, 10)\ngroup = zarr.group(store=icechunk_sesion.store(), overwrite=True)\n\nzarray = group.create_array(\n    \"array\",\n    shape=shape,\n    chunks=zarr_chunks,\n    dtype=\"f8\",\n    fill_value=float(\"nan\"),\n)\n</code></pre> Note that the chunks in the store are a divisor of the dask chunks. This means each individual write task is independent, and will not conflict. It is your responsibility to ensure that such conflicts are avoided.</p> <p>Now write <pre><code>import icechunk.dask\n\nicechunk.dask.store_dask(icechunk_session, sources=[dask_array], targets=[zarray])\n</code></pre></p> <p>Finally commit your changes! <pre><code>icechunk_session.commit(\"wrote a dask array!\")\n</code></pre></p>"},{"location":"icechunk-python/dask/#icechunk-dask-xarray","title":"Icechunk + Dask + Xarray","text":""},{"location":"icechunk-python/dask/#simple","title":"Simple","text":"<p>The <code>icechunk.xarray.to_icechunk</code> is functionally identical to Xarray's <code>Dataset.to_zarr</code>, including many of the same keyword arguments. Notably the <code>compute</code> kwarg is not supported.</p> <p>Now roundtrip an xarray dataset <pre><code>import icechunk.xarray\nimport xarray as xr\n\n# Assuming you have a valid writable Session named icechunk_session\nstore = icechunk_session.store()\n\ndataset = xr.tutorial.open_dataset(\"rasm\", chunks={\"time\": 1}).isel(time=slice(24))\n\nicechunk.xarray.to_icechunk(dataset, store=store))\n\nroundtripped = xr.open_zarr(store, consolidated=False)\ndataset.identical(roundtripped)\n</code></pre></p> <p>Finally commit your changes! <pre><code>icechunk_session.commit(\"wrote an Xarray dataset!\")\n</code></pre></p>"},{"location":"icechunk-python/quickstart/","title":"Quickstart","text":"<p>Home / icechunk-python / quickstart</p>"},{"location":"icechunk-python/quickstart/#quickstart","title":"Quickstart","text":"<p>Icechunk is designed to be mostly in the background. As a Python user, you'll mostly be interacting with Zarr. If you're not familiar with Zarr, you may want to start with the Zarr Tutorial</p>"},{"location":"icechunk-python/quickstart/#installation","title":"Installation","text":"<p>Install Icechunk with pip</p> <pre><code>pip install icechunk\n</code></pre> <p>Note</p> <p>Icechunk is currently designed to support the Zarr V3 Specification. Using it today requires installing the latest pre-release of Zarr Python 3.</p>"},{"location":"icechunk-python/quickstart/#create-a-new-icechunk-repository","title":"Create a new Icechunk repository","text":"<p>To get started, let's create a new Icechunk repository. We recommend creating your repo on S3 to get the most out of Icechunk's cloud-native design. However, you can also create a repo on your local filesystem.</p> S3 StorageLocal Storage <pre><code>storage_config = icechunk.StorageConfig.s3_from_env(\n    bucket=\"icechunk-test\",\n    prefix=\"quickstart-demo-1\"\n)\nrepo = icechunk.Repository.create(storage_config)\n</code></pre> <pre><code>storage_config = icechunk.StorageConfig.filesystem(\"./icechunk-local\")\nrepo = icechunk.Repository.create(storage_config)\n</code></pre>"},{"location":"icechunk-python/quickstart/#accessing-the-icechunk-store","title":"Accessing the Icechunk store","text":"<p>Once the repository is created, we can use <code>Session</code>s to read and write data. Since there is no data in the repository yet, let's create a writable session on the default <code>main</code> branch.</p> <pre><code>session = repo.writable_session(\"main\")\n</code></pre> <p>Now that we have a session, we can access the <code>IcechunkStore</code> from it to interact with the underlying data using <code>zarr</code>:</p> <pre><code>store = session.store()\n</code></pre>"},{"location":"icechunk-python/quickstart/#write-some-data-and-commit","title":"Write some data and commit","text":"<p>We can now use our Icechunk <code>store</code> with Zarr. Let's first create a group and an array within it.</p> <pre><code>group = zarr.group(store)\narray = group.create(\"my_array\", shape=10, dtype=int)\n</code></pre> <p>Now let's write some data</p> <pre><code>array[:] = 1\n</code></pre> <p>Now let's commit our update using the session</p> <pre><code>session.commit(\"first commit\")\n</code></pre> <p>\ud83c\udf89 Congratulations! You just made your first Icechunk snapshot.</p> <p>Note</p> <p>Once a writable <code>Session</code> has been successfully committed to, it becomes read only to ensure that all writing is done explicitly.</p>"},{"location":"icechunk-python/quickstart/#make-a-second-commit","title":"Make a second commit","text":"<p>At this point, we have already committed using our session, so we need to get a new session and store to make more changes.</p> <pre><code>session_2 = repo.writable_session(\"main\")\nstore_2 = session_2.store()\ngroup = zarr.open_group(store_2)\narray = group[\"my_array\"]\n</code></pre> <p>Let's now put some new data into our array, overwriting the first five elements.</p> <pre><code>array[:5] = 2\n</code></pre> <p>...and commit the changes</p> <pre><code>snapshot_id_2 = session_2.commit(\"overwrite some values\")\n</code></pre>"},{"location":"icechunk-python/quickstart/#explore-version-history","title":"Explore version history","text":"<p>We can see the full version history of our repo:</p> <pre><code>hist = repo.ancestry(snapshot_id_2)\nfor anc in hist:\n    print(anc.id, anc.message, anc.written_at)\n\n# Output:\n# AHC3TSP5ERXKTM4FCB5G overwrite some values 2024-10-14 14:07:27.328429+00:00\n# Q492CAPV7SF3T1BC0AA0 first commit 2024-10-14 14:07:26.152193+00:00\n# T7SMDT9C5DZ8MP83DNM0 Repository initialized 2024-10-14 14:07:22.338529+00:00\n</code></pre> <p>...and we can go back in time to the earlier version.</p> <pre><code># latest version\nassert array[0] == 2\n# check out earlier snapshot\nearlier_session = repo.readonly_session(snapshot_id=hist[1].id)\nstore = earlier_session.store()\n\n# get the array\ngroup = zarr.open_group(store)\narray = group[\"my_array]\n\n# verify data matches first version\nassert array[0] == 1\n</code></pre> <p>That's it! You now know how to use Icechunk! For your next step, dig deeper into configuration, explore the version control system, or learn how to use Icechunk with Xarray.</p>"},{"location":"icechunk-python/reference/","title":"API Reference","text":"<p>Home / icechunk-python / reference </p>"},{"location":"icechunk-python/reference/#icechunk.BasicConflictSolver","title":"<code>BasicConflictSolver</code>","text":"<p>               Bases: <code>ConflictSolver</code></p> <p>A basic conflict solver that allows for simple configuration of resolution behavior</p> <p>This conflict solver allows for simple configuration of resolution behavior for conflicts that may occur during a rebase operation. It will attempt to resolve a limited set of conflicts based on the configuration options provided.</p> <ul> <li>When a user attribute conflict is encountered, the behavior is determined by the <code>on_user_attributes_conflict</code> option</li> <li>When a chunk conflict is encountered, the behavior is determined by the <code>on_chunk_conflict</code> option</li> <li>When an array is deleted that has been updated, <code>fail_on_delete_of_updated_array</code> will determine whether to fail the rebase operation</li> <li>When a group is deleted that has been updated, <code>fail_on_delete_of_updated_group</code> will determine whether to fail the rebase operation</li> </ul> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class BasicConflictSolver(ConflictSolver):\n    \"\"\"A basic conflict solver that allows for simple configuration of resolution behavior\n\n    This conflict solver allows for simple configuration of resolution behavior for conflicts that may occur during a rebase operation.\n    It will attempt to resolve a limited set of conflicts based on the configuration options provided.\n\n    - When a user attribute conflict is encountered, the behavior is determined by the `on_user_attributes_conflict` option\n    - When a chunk conflict is encountered, the behavior is determined by the `on_chunk_conflict` option\n    - When an array is deleted that has been updated, `fail_on_delete_of_updated_array` will determine whether to fail the rebase operation\n    - When a group is deleted that has been updated, `fail_on_delete_of_updated_group` will determine whether to fail the rebase operation\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        on_user_attributes_conflict: VersionSelection = VersionSelection.UseOurs,\n        on_chunk_conflict: VersionSelection = VersionSelection.UseOurs,\n        fail_on_delete_of_updated_array: bool = False,\n        fail_on_delete_of_updated_group: bool = False,\n    ) -&gt; None:\n        \"\"\"Create a BasicConflictSolver object with the given configuration options\n        Parameters:\n        on_user_attributes_conflict: VersionSelection\n            The behavior to use when a user attribute conflict is encountered, by default VersionSelection.use_ours()\n        on_chunk_conflict: VersionSelection\n            The behavior to use when a chunk conflict is encountered, by default VersionSelection.use_theirs()\n        fail_on_delete_of_updated_array: bool\n            Whether to fail when a chunk is deleted that has been updated, by default False\n        fail_on_delete_of_updated_group: bool\n            Whether to fail when a group is deleted that has been updated, by default False\n        \"\"\"\n        ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.BasicConflictSolver.__init__","title":"<code>__init__(*, on_user_attributes_conflict=VersionSelection.UseOurs, on_chunk_conflict=VersionSelection.UseOurs, fail_on_delete_of_updated_array=False, fail_on_delete_of_updated_group=False)</code>","text":"<p>Create a BasicConflictSolver object with the given configuration options Parameters: on_user_attributes_conflict: VersionSelection     The behavior to use when a user attribute conflict is encountered, by default VersionSelection.use_ours() on_chunk_conflict: VersionSelection     The behavior to use when a chunk conflict is encountered, by default VersionSelection.use_theirs() fail_on_delete_of_updated_array: bool     Whether to fail when a chunk is deleted that has been updated, by default False fail_on_delete_of_updated_group: bool     Whether to fail when a group is deleted that has been updated, by default False</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>def __init__(\n    self,\n    *,\n    on_user_attributes_conflict: VersionSelection = VersionSelection.UseOurs,\n    on_chunk_conflict: VersionSelection = VersionSelection.UseOurs,\n    fail_on_delete_of_updated_array: bool = False,\n    fail_on_delete_of_updated_group: bool = False,\n) -&gt; None:\n    \"\"\"Create a BasicConflictSolver object with the given configuration options\n    Parameters:\n    on_user_attributes_conflict: VersionSelection\n        The behavior to use when a user attribute conflict is encountered, by default VersionSelection.use_ours()\n    on_chunk_conflict: VersionSelection\n        The behavior to use when a chunk conflict is encountered, by default VersionSelection.use_theirs()\n    fail_on_delete_of_updated_array: bool\n        Whether to fail when a chunk is deleted that has been updated, by default False\n    fail_on_delete_of_updated_group: bool\n        Whether to fail when a group is deleted that has been updated, by default False\n    \"\"\"\n    ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.CachingConfig","title":"<code>CachingConfig</code>","text":"<p>Configuration for how Icechunk caches its metadata files</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class CachingConfig:\n    \"\"\"Configuration for how Icechunk caches its metadata files\"\"\"\n    @property\n    def snapshots_cache_size(self) -&gt; int: ...\n    @snapshots_cache_size.setter\n    def snapshots_cache_size(self, value: int) -&gt; None: ...\n    @property\n    def manifests_cache_size(self) -&gt; int: ...\n    @manifests_cache_size.setter\n    def manifests_cache_size(self, value: int) -&gt; None: ...\n    @property\n    def transactions_cache_size(self) -&gt; int: ...\n    @transactions_cache_size.setter\n    def transactions_cache_size(self, value: int) -&gt; None: ...\n    @property\n    def attributes_cache_size(self) -&gt; int: ...\n    @attributes_cache_size.setter\n    def attributes_cache_size(self, value: int) -&gt; None: ...\n    @property\n    def chunks_cache_size(self) -&gt; int: ...\n    @chunks_cache_size.setter\n    def chunks_cache_size(self, value: int) -&gt; None: ...\n    @staticmethod\n    def default() -&gt; CachingConfig: ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.CompressionAlgorithm","title":"<code>CompressionAlgorithm</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for selecting the compression algorithm used by Icechunk to write its metadata files</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class CompressionAlgorithm(Enum):\n    \"\"\"Enum for selecting the compression algorithm used by Icechunk to write its metadata files\"\"\"\n\n    Zstd = 0\n\n    @staticmethod\n    def default() -&gt; CompressionAlgorithm: ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.CompressionConfig","title":"<code>CompressionConfig</code>","text":"<p>Configuration for how Icechunk compresses its metadata files</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class CompressionConfig:\n    \"\"\"Configuration for how Icechunk compresses its metadata files\"\"\"\n    @property\n    def algorithm(self) -&gt; CompressionAlgorithm: ...\n    @algorithm.setter\n    def algorithm(self, value: CompressionAlgorithm) -&gt; None: ...\n    @property\n    def level(self) -&gt; int: ...\n    @level.setter\n    def level(self, value: int) -&gt; None: ...\n    @staticmethod\n    def default() -&gt; CompressionConfig: ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Conflict","title":"<code>Conflict</code>","text":"<p>A conflict detected between snapshots</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class Conflict:\n    \"\"\"A conflict detected between snapshots\"\"\"\n\n    @property\n    def conflict_type(self) -&gt; ConflictType:\n        \"\"\"The type of conflict detected\"\"\"\n        ...\n\n    @property\n    def path(self) -&gt; str:\n        \"\"\"The path of the node that caused the conflict\"\"\"\n        ...\n\n    @property\n    def conflicted_chunks(self) -&gt; list[list[int]] | None:\n        \"\"\"If the conflict is a chunk conflict, this will return the list of chunk indices that are in conflict\"\"\"\n        ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Conflict.conflict_type","title":"<code>conflict_type: ConflictType</code>  <code>property</code>","text":"<p>The type of conflict detected</p>"},{"location":"icechunk-python/reference/#icechunk.Conflict.conflicted_chunks","title":"<code>conflicted_chunks: list[list[int]] | None</code>  <code>property</code>","text":"<p>If the conflict is a chunk conflict, this will return the list of chunk indices that are in conflict</p>"},{"location":"icechunk-python/reference/#icechunk.Conflict.path","title":"<code>path: str</code>  <code>property</code>","text":"<p>The path of the node that caused the conflict</p>"},{"location":"icechunk-python/reference/#icechunk.ConflictDetector","title":"<code>ConflictDetector</code>","text":"<p>               Bases: <code>ConflictSolver</code></p> <p>A conflict solver that can be used to detect conflicts between two stores, but does not resolve them</p> <p>Where the <code>BasicConflictSolver</code> will attempt to resolve conflicts, the <code>ConflictDetector</code> will only detect them. This means that during a rebase operation the <code>ConflictDetector</code> will raise a <code>RebaseFailed</code> error if any conflicts are detected, and allow the rebase operation to be retried with a different conflict resolution strategy. Otherwise, if no conflicts are detected the rebase operation will succeed.</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class ConflictDetector(ConflictSolver):\n    \"\"\"A conflict solver that can be used to detect conflicts between two stores, but does not resolve them\n\n    Where the `BasicConflictSolver` will attempt to resolve conflicts, the `ConflictDetector` will only detect them. This means\n    that during a rebase operation the `ConflictDetector` will raise a `RebaseFailed` error if any conflicts are detected, and\n    allow the rebase operation to be retried with a different conflict resolution strategy. Otherwise, if no conflicts are detected\n    the rebase operation will succeed.\n    \"\"\"\n\n    def __init__(self) -&gt; None: ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.ConflictError","title":"<code>ConflictError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when a commit operation fails due to a conflict.</p> Source code in <code>icechunk/session.py</code> <pre><code>class ConflictError(Exception):\n    \"\"\"Error raised when a commit operation fails due to a conflict.\"\"\"\n\n    _error: ConflictErrorData\n\n    def __init__(self, error: PyConflictError) -&gt; None:\n        self._error = error.args[0]\n\n    def __str__(self) -&gt; str:\n        return str(self._error)\n\n    @property\n    def expected_parent(self) -&gt; str:\n        \"\"\"\n        The expected parent snapshot ID.\n\n        This is the snapshot ID that the session was based on when the\n        commit operation was called.\n        \"\"\"\n        return self._error.expected_parent\n\n    @property\n    def actual_parent(self) -&gt; str:\n        \"\"\"\n        The actual parent snapshot ID of the branch that the session attempted to commit to.\n\n        When the session is based on a branch, this is the snapshot ID of the branch tip. If this\n        error is raised, it means the branch was modified and committed by another session after\n        the session was created.\n        \"\"\"\n        return self._error.actual_parent\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.ConflictError.actual_parent","title":"<code>actual_parent: str</code>  <code>property</code>","text":"<p>The actual parent snapshot ID of the branch that the session attempted to commit to.</p> <p>When the session is based on a branch, this is the snapshot ID of the branch tip. If this error is raised, it means the branch was modified and committed by another session after the session was created.</p>"},{"location":"icechunk-python/reference/#icechunk.ConflictError.expected_parent","title":"<code>expected_parent: str</code>  <code>property</code>","text":"<p>The expected parent snapshot ID.</p> <p>This is the snapshot ID that the session was based on when the commit operation was called.</p>"},{"location":"icechunk-python/reference/#icechunk.ConflictErrorData","title":"<code>ConflictErrorData</code>","text":"<p>Data class for conflict errors. This describes the snapshot conflict detected when committing a session</p> <p>If this error is raised, it means the branch was modified and committed by another session after the session was created.</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class ConflictErrorData:\n    \"\"\"Data class for conflict errors. This describes the snapshot conflict detected when committing a session\n\n    If this error is raised, it means the branch was modified and committed by another session after the session was created.\n    \"\"\"\n    @property\n    def expected_parent(self) -&gt; str:\n        \"\"\"The expected parent snapshot ID.\n\n        This is the snapshot ID that the session was based on when the\n        commit operation was called.\n        \"\"\"\n        ...\n    @property\n    def actual_parent(self) -&gt; str:\n        \"\"\"\n        The actual parent snapshot ID of the branch that the session attempted to commit to.\n\n        When the session is based on a branch, this is the snapshot ID of the branch tip. If this\n        error is raised, it means the branch was modified and committed by another session after\n        the session was created.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.ConflictErrorData.actual_parent","title":"<code>actual_parent: str</code>  <code>property</code>","text":"<p>The actual parent snapshot ID of the branch that the session attempted to commit to.</p> <p>When the session is based on a branch, this is the snapshot ID of the branch tip. If this error is raised, it means the branch was modified and committed by another session after the session was created.</p>"},{"location":"icechunk-python/reference/#icechunk.ConflictErrorData.expected_parent","title":"<code>expected_parent: str</code>  <code>property</code>","text":"<p>The expected parent snapshot ID.</p> <p>This is the snapshot ID that the session was based on when the commit operation was called.</p>"},{"location":"icechunk-python/reference/#icechunk.ConflictSolver","title":"<code>ConflictSolver</code>","text":"<p>An abstract conflict solver that can be used to detect or resolve conflicts between two stores</p> <p>This should never be used directly, but should be subclassed to provide specific conflict resolution behavior</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class ConflictSolver:\n    \"\"\"An abstract conflict solver that can be used to detect or resolve conflicts between two stores\n\n    This should never be used directly, but should be subclassed to provide specific conflict resolution behavior\n    \"\"\"\n\n    ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.ConflictType","title":"<code>ConflictType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Type of conflict detected</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class ConflictType(Enum):\n    \"\"\"Type of conflict detected\"\"\"\n\n    NewNodeConflictsWithExistingNode = 1\n    NewNodeInInvalidGroup = 2\n    ZarrMetadataDoubleUpdate = 3\n    ZarrMetadataUpdateOfDeletedArray = 4\n    UserAttributesDoubleUpdate = 5\n    UserAttributesUpdateOfDeletedNode = 6\n    ChunkDoubleUpdate = 7\n    ChunksUpdatedInDeletedArray = 8\n    ChunksUpdatedInUpdatedArray = 9\n    DeleteOfUpdatedArray = 10\n    DeleteOfUpdatedGroup = 11\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkError","title":"<code>IcechunkError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for all Icechunk errors</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class IcechunkError(Exception):\n    \"\"\"Base class for all Icechunk errors\"\"\"\n\n    ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore","title":"<code>IcechunkStore</code>","text":"<p>               Bases: <code>Store</code>, <code>SyncMixin</code></p> Source code in <code>icechunk/store.py</code> <pre><code>class IcechunkStore(Store, SyncMixin):\n    _store: PyStore\n\n    def __init__(\n        self,\n        store: PyStore,\n        *args: Any,\n        **kwargs: Any,\n    ):\n        \"\"\"Create a new IcechunkStore.\n\n        This should not be called directly, instead use the `create`, `open_existing` or `open_or_create` class methods.\n        \"\"\"\n        super().__init__(read_only=store.read_only)\n        if store is None:\n            raise ValueError(\n                \"An IcechunkStore should not be created with the default constructor, instead use either the create or open_existing class methods.\"\n            )\n        self._store = store\n        self._is_open = True\n\n    def __eq__(self, value: object) -&gt; bool:\n        if not isinstance(value, IcechunkStore):\n            return False\n        return self._store == value._store\n\n    def __getstate__(self) -&gt; object:\n        # we serialize the Rust store as bytes\n        d = self.__dict__.copy()\n        d[\"_store\"] = self._store.as_bytes()\n        return d\n\n    def __setstate__(self, state: Any) -&gt; None:\n        # we have to deserialize the bytes of the Rust store\n        store_repr = state[\"_store\"]\n        state[\"_store\"] = PyStore.from_bytes(store_repr)\n        state[\"_read_only\"] = state[\"_store\"].read_only\n        self.__dict__ = state\n\n    @property\n    def session(self) -&gt; \"Session\":\n        from icechunk import Session\n\n        return Session(self._store.session)\n\n    async def clear(self) -&gt; None:\n        \"\"\"Clear the store.\n\n        This will remove all contents from the current session,\n        including all groups and all arrays. But it will not modify the repository history.\n        \"\"\"\n        return await self._store.clear()\n\n    def sync_clear(self) -&gt; None:\n        \"\"\"Clear the store.\n\n        This will remove all contents from the current session,\n        including all groups and all arrays. But it will not modify the repository history.\n        \"\"\"\n        return self._store.sync_clear()\n\n    async def is_empty(self, prefix: str) -&gt; bool:\n        \"\"\"\n        Check if the directory is empty.\n\n        Parameters\n        ----------\n        prefix : str\n            Prefix of keys to check.\n\n        Returns\n        -------\n        bool\n            True if the store is empty, False otherwise.\n        \"\"\"\n        return await self._store.is_empty(prefix)\n\n    async def get(\n        self,\n        key: str,\n        prototype: BufferPrototype,\n        byte_range: ByteRequest | None = None,\n    ) -&gt; Buffer | None:\n        \"\"\"Retrieve the value associated with a given key.\n\n        Parameters\n        ----------\n        key : str\n        byte_range : ByteRequest, optional\n\n            ByteRequest may be one of the following. If not provided, all data associated with the key is retrieved.\n\n            - RangeByteRequest(int, int): Request a specific range of bytes in the form (start, end). The end is exclusive. If the given range is zero-length or starts after the end of the object, an error will be returned. Additionally, if the range ends after the end of the object, the entire remainder of the object will be returned. Otherwise, the exact requested range will be returned.\n            - OffsetByteRequest(int): Request all bytes starting from a given byte offset. This is equivalent to bytes={int}- as an HTTP header.\n            - SuffixByteRequest(int): Request the last int bytes. Note that here, int is the size of the request, not the byte offset. This is equivalent to bytes=-{int} as an HTTP header.\n\n        Returns\n        -------\n        Buffer\n        \"\"\"\n\n        try:\n            result = await self._store.get(key, _byte_request_to_tuple(byte_range))\n        except KeyError as _e:\n            # Zarr python expects None to be returned if the key does not exist\n            # but an IcechunkStore returns an error if the key does not exist\n            return None\n\n        return prototype.buffer.from_bytes(result)\n\n    async def get_partial_values(\n        self,\n        prototype: BufferPrototype,\n        key_ranges: Iterable[tuple[str, ByteRequest | None]],\n    ) -&gt; list[Buffer | None]:\n        \"\"\"Retrieve possibly partial values from given key_ranges.\n\n        Parameters\n        ----------\n        key_ranges : Iterable[tuple[str, tuple[int | None, int | None]]]\n            Ordered set of key, range pairs, a key may occur multiple times with different ranges\n\n        Returns\n        -------\n        list of values, in the order of the key_ranges, may contain null/none for missing keys\n        \"\"\"\n        # NOTE: pyo3 has not implicit conversion from an Iterable to a rust iterable. So we convert it\n        # to a list here first. Possible opportunity for optimization.\n        ranges = [(k[0], _byte_request_to_tuple(k[1])) for k in key_ranges]\n        result = await self._store.get_partial_values(list(ranges))\n        return [prototype.buffer.from_bytes(r) for r in result]\n\n    async def exists(self, key: str) -&gt; bool:\n        \"\"\"Check if a key exists in the store.\n\n        Parameters\n        ----------\n        key : str\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return await self._store.exists(key)\n\n    @property\n    def supports_writes(self) -&gt; bool:\n        \"\"\"Does the store support writes?\"\"\"\n        return self._store.supports_writes\n\n    async def set(self, key: str, value: Buffer) -&gt; None:\n        \"\"\"Store a (key, value) pair.\n\n        Parameters\n        ----------\n        key : str\n        value : Buffer\n        \"\"\"\n        return await self._store.set(key, value.to_bytes())\n\n    async def set_if_not_exists(self, key: str, value: Buffer) -&gt; None:\n        \"\"\"\n        Store a key to ``value`` if the key is not already present.\n\n        Parameters\n        -----------\n        key : str\n        value : Buffer\n        \"\"\"\n        return await self._store.set_if_not_exists(key, value.to_bytes())\n\n    def set_virtual_ref(\n        self,\n        key: str,\n        location: str,\n        *,\n        offset: int,\n        length: int,\n        checksum: str | datetime | None = None,\n        validate_container: bool = False,\n    ) -&gt; None:\n        \"\"\"Store a virtual reference to a chunk.\n\n        Parameters\n        ----------\n        key : str\n            The chunk to store the reference under. This is the fully qualified zarr key eg: 'array/c/0/0/0'\n        location : str\n            The location of the chunk in storage. This is absolute path to the chunk in storage eg: 's3://bucket/path/to/file.nc'\n        offset : int\n            The offset in bytes from the start of the file location in storage the chunk starts at\n        length : int\n            The length of the chunk in bytes, measured from the given offset\n        checksum : str | datetime | None\n            The etag or last_medified_at field of the object\n        validate_container: bool\n            If set to true, fail for locations that don't match any existing virtual chunk container\n        \"\"\"\n        return self._store.set_virtual_ref(\n            key, location, offset, length, checksum, validate_container\n        )\n\n    async def delete(self, key: str) -&gt; None:\n        \"\"\"Remove a key from the store\n\n        Parameters\n        ----------\n        key : str\n        \"\"\"\n        return await self._store.delete(key)\n\n    async def delete_dir(self, prefix: str) -&gt; None:\n        \"\"\"Delete a prefix\n\n        Parameters\n        ----------\n        key : str\n        \"\"\"\n        return await self._store.delete_dir(prefix)\n\n    @property\n    def supports_partial_writes(self) -&gt; bool:\n        \"\"\"Does the store support partial writes?\"\"\"\n        return self._store.supports_partial_writes\n\n    async def set_partial_values(\n        self, key_start_values: Iterable[tuple[str, int, BytesLike]]\n    ) -&gt; None:\n        \"\"\"Store values at a given key, starting at byte range_start.\n\n        Parameters\n        ----------\n        key_start_values : list[tuple[str, int, BytesLike]]\n            set of key, range_start, values triples, a key may occur multiple times with different\n            range_starts, range_starts (considering the length of the respective values) must not\n            specify overlapping ranges for the same key\n        \"\"\"\n        # NOTE: pyo3 does not implicit conversion from an Iterable to a rust iterable. So we convert it\n        # to a list here first. Possible opportunity for optimization.\n        return await self._store.set_partial_values(list(key_start_values))\n\n    @property\n    def supports_listing(self) -&gt; bool:\n        \"\"\"Does the store support listing?\"\"\"\n        return self._store.supports_listing\n\n    @property\n    def supports_deletes(self) -&gt; bool:\n        return self._store.supports_deletes\n\n    def list(self) -&gt; AsyncIterator[str]:\n        \"\"\"Retrieve all keys in the store.\n\n        Returns\n        -------\n        AsyncIterator[str, None]\n        \"\"\"\n        # This method should be async, like overridden methods in child classes.\n        # However, that's not straightforward:\n        # https://stackoverflow.com/questions/68905848\n\n        # The zarr spec specefies that that this and other\n        # listing methods should not be async, so we need to\n        # wrap the async method in a sync method.\n        return self._store.list()\n\n    def list_prefix(self, prefix: str) -&gt; AsyncIterator[str]:\n        \"\"\"Retrieve all keys in the store that begin with a given prefix. Keys are returned relative\n        to the root of the store.\n\n        Parameters\n        ----------\n        prefix : str\n\n        Returns\n        -------\n        AsyncIterator[str, None]\n        \"\"\"\n        # The zarr spec specefies that that this and other\n        # listing methods should not be async, so we need to\n        # wrap the async method in a sync method.\n        return self._store.list_prefix(prefix)\n\n    def list_dir(self, prefix: str) -&gt; AsyncIterator[str]:\n        \"\"\"\n        Retrieve all keys and prefixes with a given prefix and which do not contain the character\n        \u201c/\u201d after the given prefix.\n\n        Parameters\n        ----------\n        prefix : str\n\n        Returns\n        -------\n        AsyncIterator[str, None]\n        \"\"\"\n        # The zarr spec specefies that that this and other\n        # listing methods should not be async, so we need to\n        # wrap the async method in a sync method.\n        return self._store.list_dir(prefix)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.supports_listing","title":"<code>supports_listing: bool</code>  <code>property</code>","text":"<p>Does the store support listing?</p>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.supports_partial_writes","title":"<code>supports_partial_writes: bool</code>  <code>property</code>","text":"<p>Does the store support partial writes?</p>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.supports_writes","title":"<code>supports_writes: bool</code>  <code>property</code>","text":"<p>Does the store support writes?</p>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.__init__","title":"<code>__init__(store, *args, **kwargs)</code>","text":"<p>Create a new IcechunkStore.</p> <p>This should not be called directly, instead use the <code>create</code>, <code>open_existing</code> or <code>open_or_create</code> class methods.</p> Source code in <code>icechunk/store.py</code> <pre><code>def __init__(\n    self,\n    store: PyStore,\n    *args: Any,\n    **kwargs: Any,\n):\n    \"\"\"Create a new IcechunkStore.\n\n    This should not be called directly, instead use the `create`, `open_existing` or `open_or_create` class methods.\n    \"\"\"\n    super().__init__(read_only=store.read_only)\n    if store is None:\n        raise ValueError(\n            \"An IcechunkStore should not be created with the default constructor, instead use either the create or open_existing class methods.\"\n        )\n    self._store = store\n    self._is_open = True\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.clear","title":"<code>clear()</code>  <code>async</code>","text":"<p>Clear the store.</p> <p>This will remove all contents from the current session, including all groups and all arrays. But it will not modify the repository history.</p> Source code in <code>icechunk/store.py</code> <pre><code>async def clear(self) -&gt; None:\n    \"\"\"Clear the store.\n\n    This will remove all contents from the current session,\n    including all groups and all arrays. But it will not modify the repository history.\n    \"\"\"\n    return await self._store.clear()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.delete","title":"<code>delete(key)</code>  <code>async</code>","text":"<p>Remove a key from the store</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> required Source code in <code>icechunk/store.py</code> <pre><code>async def delete(self, key: str) -&gt; None:\n    \"\"\"Remove a key from the store\n\n    Parameters\n    ----------\n    key : str\n    \"\"\"\n    return await self._store.delete(key)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.delete_dir","title":"<code>delete_dir(prefix)</code>  <code>async</code>","text":"<p>Delete a prefix</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> required Source code in <code>icechunk/store.py</code> <pre><code>async def delete_dir(self, prefix: str) -&gt; None:\n    \"\"\"Delete a prefix\n\n    Parameters\n    ----------\n    key : str\n    \"\"\"\n    return await self._store.delete_dir(prefix)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.exists","title":"<code>exists(key)</code>  <code>async</code>","text":"<p>Check if a key exists in the store.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> required <p>Returns:</p> Type Description <code>bool</code> Source code in <code>icechunk/store.py</code> <pre><code>async def exists(self, key: str) -&gt; bool:\n    \"\"\"Check if a key exists in the store.\n\n    Parameters\n    ----------\n    key : str\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return await self._store.exists(key)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.get","title":"<code>get(key, prototype, byte_range=None)</code>  <code>async</code>","text":"<p>Retrieve the value associated with a given key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> required <code>byte_range</code> <code>ByteRequest</code> <p>ByteRequest may be one of the following. If not provided, all data associated with the key is retrieved.</p> <ul> <li>RangeByteRequest(int, int): Request a specific range of bytes in the form (start, end). The end is exclusive. If the given range is zero-length or starts after the end of the object, an error will be returned. Additionally, if the range ends after the end of the object, the entire remainder of the object will be returned. Otherwise, the exact requested range will be returned.</li> <li>OffsetByteRequest(int): Request all bytes starting from a given byte offset. This is equivalent to bytes={int}- as an HTTP header.</li> <li>SuffixByteRequest(int): Request the last int bytes. Note that here, int is the size of the request, not the byte offset. This is equivalent to bytes=-{int} as an HTTP header.</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>Buffer</code> Source code in <code>icechunk/store.py</code> <pre><code>async def get(\n    self,\n    key: str,\n    prototype: BufferPrototype,\n    byte_range: ByteRequest | None = None,\n) -&gt; Buffer | None:\n    \"\"\"Retrieve the value associated with a given key.\n\n    Parameters\n    ----------\n    key : str\n    byte_range : ByteRequest, optional\n\n        ByteRequest may be one of the following. If not provided, all data associated with the key is retrieved.\n\n        - RangeByteRequest(int, int): Request a specific range of bytes in the form (start, end). The end is exclusive. If the given range is zero-length or starts after the end of the object, an error will be returned. Additionally, if the range ends after the end of the object, the entire remainder of the object will be returned. Otherwise, the exact requested range will be returned.\n        - OffsetByteRequest(int): Request all bytes starting from a given byte offset. This is equivalent to bytes={int}- as an HTTP header.\n        - SuffixByteRequest(int): Request the last int bytes. Note that here, int is the size of the request, not the byte offset. This is equivalent to bytes=-{int} as an HTTP header.\n\n    Returns\n    -------\n    Buffer\n    \"\"\"\n\n    try:\n        result = await self._store.get(key, _byte_request_to_tuple(byte_range))\n    except KeyError as _e:\n        # Zarr python expects None to be returned if the key does not exist\n        # but an IcechunkStore returns an error if the key does not exist\n        return None\n\n    return prototype.buffer.from_bytes(result)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.get_partial_values","title":"<code>get_partial_values(prototype, key_ranges)</code>  <code>async</code>","text":"<p>Retrieve possibly partial values from given key_ranges.</p> <p>Parameters:</p> Name Type Description Default <code>key_ranges</code> <code>Iterable[tuple[str, tuple[int | None, int | None]]]</code> <p>Ordered set of key, range pairs, a key may occur multiple times with different ranges</p> required <p>Returns:</p> Type Description <code>list of values, in the order of the key_ranges, may contain null/none for missing keys</code> Source code in <code>icechunk/store.py</code> <pre><code>async def get_partial_values(\n    self,\n    prototype: BufferPrototype,\n    key_ranges: Iterable[tuple[str, ByteRequest | None]],\n) -&gt; list[Buffer | None]:\n    \"\"\"Retrieve possibly partial values from given key_ranges.\n\n    Parameters\n    ----------\n    key_ranges : Iterable[tuple[str, tuple[int | None, int | None]]]\n        Ordered set of key, range pairs, a key may occur multiple times with different ranges\n\n    Returns\n    -------\n    list of values, in the order of the key_ranges, may contain null/none for missing keys\n    \"\"\"\n    # NOTE: pyo3 has not implicit conversion from an Iterable to a rust iterable. So we convert it\n    # to a list here first. Possible opportunity for optimization.\n    ranges = [(k[0], _byte_request_to_tuple(k[1])) for k in key_ranges]\n    result = await self._store.get_partial_values(list(ranges))\n    return [prototype.buffer.from_bytes(r) for r in result]\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.is_empty","title":"<code>is_empty(prefix)</code>  <code>async</code>","text":"<p>Check if the directory is empty.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix of keys to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the store is empty, False otherwise.</p> Source code in <code>icechunk/store.py</code> <pre><code>async def is_empty(self, prefix: str) -&gt; bool:\n    \"\"\"\n    Check if the directory is empty.\n\n    Parameters\n    ----------\n    prefix : str\n        Prefix of keys to check.\n\n    Returns\n    -------\n    bool\n        True if the store is empty, False otherwise.\n    \"\"\"\n    return await self._store.is_empty(prefix)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.list","title":"<code>list()</code>","text":"<p>Retrieve all keys in the store.</p> <p>Returns:</p> Type Description <code>AsyncIterator[str, None]</code> Source code in <code>icechunk/store.py</code> <pre><code>def list(self) -&gt; AsyncIterator[str]:\n    \"\"\"Retrieve all keys in the store.\n\n    Returns\n    -------\n    AsyncIterator[str, None]\n    \"\"\"\n    # This method should be async, like overridden methods in child classes.\n    # However, that's not straightforward:\n    # https://stackoverflow.com/questions/68905848\n\n    # The zarr spec specefies that that this and other\n    # listing methods should not be async, so we need to\n    # wrap the async method in a sync method.\n    return self._store.list()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.list_dir","title":"<code>list_dir(prefix)</code>","text":"<p>Retrieve all keys and prefixes with a given prefix and which do not contain the character \u201c/\u201d after the given prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> required <p>Returns:</p> Type Description <code>AsyncIterator[str, None]</code> Source code in <code>icechunk/store.py</code> <pre><code>def list_dir(self, prefix: str) -&gt; AsyncIterator[str]:\n    \"\"\"\n    Retrieve all keys and prefixes with a given prefix and which do not contain the character\n    \u201c/\u201d after the given prefix.\n\n    Parameters\n    ----------\n    prefix : str\n\n    Returns\n    -------\n    AsyncIterator[str, None]\n    \"\"\"\n    # The zarr spec specefies that that this and other\n    # listing methods should not be async, so we need to\n    # wrap the async method in a sync method.\n    return self._store.list_dir(prefix)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.list_prefix","title":"<code>list_prefix(prefix)</code>","text":"<p>Retrieve all keys in the store that begin with a given prefix. Keys are returned relative to the root of the store.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> required <p>Returns:</p> Type Description <code>AsyncIterator[str, None]</code> Source code in <code>icechunk/store.py</code> <pre><code>def list_prefix(self, prefix: str) -&gt; AsyncIterator[str]:\n    \"\"\"Retrieve all keys in the store that begin with a given prefix. Keys are returned relative\n    to the root of the store.\n\n    Parameters\n    ----------\n    prefix : str\n\n    Returns\n    -------\n    AsyncIterator[str, None]\n    \"\"\"\n    # The zarr spec specefies that that this and other\n    # listing methods should not be async, so we need to\n    # wrap the async method in a sync method.\n    return self._store.list_prefix(prefix)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.set","title":"<code>set(key, value)</code>  <code>async</code>","text":"<p>Store a (key, value) pair.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> required <code>value</code> <code>Buffer</code> required Source code in <code>icechunk/store.py</code> <pre><code>async def set(self, key: str, value: Buffer) -&gt; None:\n    \"\"\"Store a (key, value) pair.\n\n    Parameters\n    ----------\n    key : str\n    value : Buffer\n    \"\"\"\n    return await self._store.set(key, value.to_bytes())\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.set_if_not_exists","title":"<code>set_if_not_exists(key, value)</code>  <code>async</code>","text":"<p>Store a key to <code>value</code> if the key is not already present.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> required <code>value</code> <code>Buffer</code> required Source code in <code>icechunk/store.py</code> <pre><code>async def set_if_not_exists(self, key: str, value: Buffer) -&gt; None:\n    \"\"\"\n    Store a key to ``value`` if the key is not already present.\n\n    Parameters\n    -----------\n    key : str\n    value : Buffer\n    \"\"\"\n    return await self._store.set_if_not_exists(key, value.to_bytes())\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.set_partial_values","title":"<code>set_partial_values(key_start_values)</code>  <code>async</code>","text":"<p>Store values at a given key, starting at byte range_start.</p> <p>Parameters:</p> Name Type Description Default <code>key_start_values</code> <code>list[tuple[str, int, BytesLike]]</code> <p>set of key, range_start, values triples, a key may occur multiple times with different range_starts, range_starts (considering the length of the respective values) must not specify overlapping ranges for the same key</p> required Source code in <code>icechunk/store.py</code> <pre><code>async def set_partial_values(\n    self, key_start_values: Iterable[tuple[str, int, BytesLike]]\n) -&gt; None:\n    \"\"\"Store values at a given key, starting at byte range_start.\n\n    Parameters\n    ----------\n    key_start_values : list[tuple[str, int, BytesLike]]\n        set of key, range_start, values triples, a key may occur multiple times with different\n        range_starts, range_starts (considering the length of the respective values) must not\n        specify overlapping ranges for the same key\n    \"\"\"\n    # NOTE: pyo3 does not implicit conversion from an Iterable to a rust iterable. So we convert it\n    # to a list here first. Possible opportunity for optimization.\n    return await self._store.set_partial_values(list(key_start_values))\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.set_virtual_ref","title":"<code>set_virtual_ref(key, location, *, offset, length, checksum=None, validate_container=False)</code>","text":"<p>Store a virtual reference to a chunk.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The chunk to store the reference under. This is the fully qualified zarr key eg: 'array/c/0/0/0'</p> required <code>location</code> <code>str</code> <p>The location of the chunk in storage. This is absolute path to the chunk in storage eg: 's3://bucket/path/to/file.nc'</p> required <code>offset</code> <code>int</code> <p>The offset in bytes from the start of the file location in storage the chunk starts at</p> required <code>length</code> <code>int</code> <p>The length of the chunk in bytes, measured from the given offset</p> required <code>checksum</code> <code>str | datetime | None</code> <p>The etag or last_medified_at field of the object</p> <code>None</code> <code>validate_container</code> <code>bool</code> <p>If set to true, fail for locations that don't match any existing virtual chunk container</p> <code>False</code> Source code in <code>icechunk/store.py</code> <pre><code>def set_virtual_ref(\n    self,\n    key: str,\n    location: str,\n    *,\n    offset: int,\n    length: int,\n    checksum: str | datetime | None = None,\n    validate_container: bool = False,\n) -&gt; None:\n    \"\"\"Store a virtual reference to a chunk.\n\n    Parameters\n    ----------\n    key : str\n        The chunk to store the reference under. This is the fully qualified zarr key eg: 'array/c/0/0/0'\n    location : str\n        The location of the chunk in storage. This is absolute path to the chunk in storage eg: 's3://bucket/path/to/file.nc'\n    offset : int\n        The offset in bytes from the start of the file location in storage the chunk starts at\n    length : int\n        The length of the chunk in bytes, measured from the given offset\n    checksum : str | datetime | None\n        The etag or last_medified_at field of the object\n    validate_container: bool\n        If set to true, fail for locations that don't match any existing virtual chunk container\n    \"\"\"\n    return self._store.set_virtual_ref(\n        key, location, offset, length, checksum, validate_container\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.IcechunkStore.sync_clear","title":"<code>sync_clear()</code>","text":"<p>Clear the store.</p> <p>This will remove all contents from the current session, including all groups and all arrays. But it will not modify the repository history.</p> Source code in <code>icechunk/store.py</code> <pre><code>def sync_clear(self) -&gt; None:\n    \"\"\"Clear the store.\n\n    This will remove all contents from the current session,\n    including all groups and all arrays. But it will not modify the repository history.\n    \"\"\"\n    return self._store.sync_clear()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.RebaseFailedData","title":"<code>RebaseFailedData</code>","text":"<p>Data class for rebase failed errors. This describes the error that occurred when rebasing a session</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class RebaseFailedData:\n    \"\"\"Data class for rebase failed errors. This describes the error that occurred when rebasing a session\"\"\"\n\n    @property\n    def snapshot(self) -&gt; str:\n        \"\"\"The snapshot ID that the session was rebased to\"\"\"\n        ...\n\n    @property\n    def conflicts(self) -&gt; list[Conflict]:\n        \"\"\"The conflicts that occurred during the rebase operation\"\"\"\n        ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.RebaseFailedData.conflicts","title":"<code>conflicts: list[Conflict]</code>  <code>property</code>","text":"<p>The conflicts that occurred during the rebase operation</p>"},{"location":"icechunk-python/reference/#icechunk.RebaseFailedData.snapshot","title":"<code>snapshot: str</code>  <code>property</code>","text":"<p>The snapshot ID that the session was rebased to</p>"},{"location":"icechunk-python/reference/#icechunk.RebaseFailedError","title":"<code>RebaseFailedError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when a rebase operation fails.</p> Source code in <code>icechunk/session.py</code> <pre><code>class RebaseFailedError(Exception):\n    \"\"\"Error raised when a rebase operation fails.\"\"\"\n\n    _error: RebaseFailedData\n\n    def __init__(self, error: PyRebaseFailedError) -&gt; None:\n        self._error = error.args[0]\n\n    def __str__(self) -&gt; str:\n        return str(self._error)\n\n    @property\n    def snapshot_id(self) -&gt; str:\n        \"\"\"\n        The snapshot ID that the rebase operation failed on.\n        \"\"\"\n        return self._error.snapshot\n\n    @property\n    def conflicts(self) -&gt; list[Conflict]:\n        \"\"\"\n        List of conflicts that occurred during the rebase operation.\n        \"\"\"\n        return self._error.conflicts\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.RebaseFailedError.conflicts","title":"<code>conflicts: list[Conflict]</code>  <code>property</code>","text":"<p>List of conflicts that occurred during the rebase operation.</p>"},{"location":"icechunk-python/reference/#icechunk.RebaseFailedError.snapshot_id","title":"<code>snapshot_id: str</code>  <code>property</code>","text":"<p>The snapshot ID that the rebase operation failed on.</p>"},{"location":"icechunk-python/reference/#icechunk.Repository","title":"<code>Repository</code>","text":"<p>An Icechunk repository.</p> Source code in <code>icechunk/repository.py</code> <pre><code>class Repository:\n    \"\"\"An Icechunk repository.\"\"\"\n\n    _repository: PyRepository\n\n    def __init__(self, repository: PyRepository):\n        self._repository = repository\n\n    @classmethod\n    def create(\n        cls,\n        storage: Storage,\n        config: RepositoryConfig | None = None,\n        virtual_chunk_credentials: dict[str, AnyCredential] | None = None,\n    ) -&gt; Self:\n        \"\"\"Create a new Icechunk repository.\n\n        If one already exists at the given store location, an error will be raised.\n\n        Args:\n            storage: The storage configuration for the repository.\n            config: The repository configuration. If not provided, a default configuration will be used.\n        \"\"\"\n        return cls(\n            PyRepository.create(\n                storage,\n                config=config,\n                virtual_chunk_credentials=virtual_chunk_credentials,\n            )\n        )\n\n    @classmethod\n    def open(\n        cls,\n        storage: Storage,\n        config: RepositoryConfig | None = None,\n        virtual_chunk_credentials: dict[str, AnyCredential] | None = None,\n    ) -&gt; Self:\n        \"\"\"Open an existing Icechunk repository.\n\n        If no repository exists at the given storage location, an error will be raised.\n\n        Args:\n            storage: The storage configuration for the repository.\n            config: The repository settings. If not provided, a default configuration will be\n            loaded from the repository\n        \"\"\"\n        return cls(\n            PyRepository.open(\n                storage,\n                config=config,\n                virtual_chunk_credentials=virtual_chunk_credentials,\n            )\n        )\n\n    @classmethod\n    def open_or_create(\n        cls,\n        storage: Storage,\n        config: RepositoryConfig | None = None,\n        virtual_chunk_credentials: dict[str, AnyCredential] | None = None,\n    ) -&gt; Self:\n        \"\"\"Open an existing Icechunk repository or create a new one if it does not exist.\n\n        Args:\n            storage: The storage configuration for the repository.\n            config: The repository settings. If not provided, a default configuration will be\n            loaded from the repository\n        \"\"\"\n        return cls(\n            PyRepository.open_or_create(\n                storage,\n                config=config,\n                virtual_chunk_credentials=virtual_chunk_credentials,\n            )\n        )\n\n    @staticmethod\n    def exists(storage: Storage) -&gt; bool:\n        \"\"\"Check if a repository exists at the given storage location.\n\n        Args:\n            storage: The storage configuration for the repository.\n        \"\"\"\n        return PyRepository.exists(storage)\n\n    @staticmethod\n    def fetch_config(storage: Storage) -&gt; RepositoryConfig | None:\n        \"\"\"Fetch the configuration for the repository saved in storage\"\"\"\n        return PyRepository.fetch_config(storage)\n\n    def save_config(self) -&gt; None:\n        \"\"\"Save the repository configuration to storage, this configuration will be used in future calls to Repository.open.\"\"\"\n        return self._repository.save_config()\n\n    def ancestry(\n        self,\n        *,\n        branch: str | None = None,\n        tag: str | None = None,\n        snapshot: str | None = None,\n    ) -&gt; list[SnapshotMetadata]:\n        \"\"\"Get the ancestry of a snapshot.\n\n        Args:\n            branch: The branch to get the ancestry of.\n            tag: The tag to get the ancestry of.\n            snapshot: The snapshot ID to get the ancestry of.\n\n        Returns:\n            list[SnapshotMetadata]: The ancestry of the snapshot, listing out the snapshots and their metadata\n\n        Only one of the arguments can be specified.\n        \"\"\"\n        return self._repository.ancestry(branch=branch, tag=tag, snapshot=snapshot)\n\n    def create_branch(self, branch: str, snapshot_id: str) -&gt; None:\n        \"\"\"Create a new branch at the given snapshot.\n\n        Args:\n            branch: The name of the branch to create.\n            snapshot_id: The snapshot ID to create the branch at.\n        \"\"\"\n        self._repository.create_branch(branch, snapshot_id)\n\n    def list_branches(self) -&gt; set[str]:\n        \"\"\"List the branches in the repository.\"\"\"\n        return self._repository.list_branches()\n\n    def lookup_branch(self, branch: str) -&gt; str:\n        \"\"\"Get the tip snapshot ID of a branch.\n\n        Args:\n            branch: The branch to get the tip of.\n\n        Returns:\n            str: The snapshot ID of the tip of the branch\n        \"\"\"\n        return self._repository.lookup_branch(branch)\n\n    def reset_branch(self, branch: str, snapshot_id: str) -&gt; None:\n        \"\"\"Reset a branch to a specific snapshot.\n\n        This will permanently alter the history of the branch such that the tip of\n        the branch is the specified snapshot.\n\n        Args:\n            branch: The branch to reset.\n            snapshot_id: The snapshot ID to reset the branch to.\n        \"\"\"\n        self._repository.reset_branch(branch, snapshot_id)\n\n    def delete_branch(self, branch: str) -&gt; None:\n        \"\"\"Delete a branch.\n\n        Args:\n            branch: The branch to delete.\n        \"\"\"\n        self._repository.delete_branch(branch)\n\n    def create_tag(self, tag: str, snapshot_id: str) -&gt; None:\n        \"\"\"Create a new tag at the given snapshot.\n\n        Args:\n            tag: The name of the tag to create.\n            snapshot_id: The snapshot ID to create the tag at.\n        \"\"\"\n        self._repository.create_tag(tag, snapshot_id)\n\n    def list_tags(self) -&gt; set[str]:\n        \"\"\"List the tags in the repository.\"\"\"\n        return self._repository.list_tags()\n\n    def lookup_tag(self, tag: str) -&gt; str:\n        \"\"\"Get the snapshot ID of a tag.\n\n        Args:\n            tag: The tag to get the snapshot ID of.\n\n        Returns:\n            str: The snapshot ID of the tag.\n        \"\"\"\n        return self._repository.lookup_tag(tag)\n\n    def readonly_session(\n        self,\n        *,\n        branch: str | None = None,\n        tag: str | None = None,\n        snapshot: str | None = None,\n    ) -&gt; Session:\n        \"\"\"Create a read-only session.\n\n        This can be thought of as a read-only checkout of the repository at a given snapshot.\n        When branch or tag are provided, the session will be based on the tip of the branch or\n        the snapshot ID of the tag.\n\n        Args:\n            branch: If provided, the branch to create the session on.\n            tag: If provided, the tag to create the session on.\n            snapshot: If provided, the snapshot ID to create the session on.\n\n        Returns:\n            Session: The read-only session, pointing to the specified snapshot, tag, or branch.\n\n        Only one of the arguments can be specified.\n        \"\"\"\n        return Session(\n            self._repository.readonly_session(branch=branch, tag=tag, snapshot=snapshot)\n        )\n\n    def writable_session(self, branch: str) -&gt; Session:\n        \"\"\"Create a writable session on a branch\n\n        Like the read-only session, this can be thought of as a checkout of the repository at the\n        tip of the branch. However, this session is writable and can be used to make changes to the\n        repository. When ready, the changes can be committed to the branch, after which the session will\n        become a read-only session on the new snapshot.\n\n        Args:\n            branch: The branch to create the session on.\n\n        Returns:\n            Session: The writable session on the branch.\n\n        \"\"\"\n        return Session(self._repository.writable_session(branch))\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.ancestry","title":"<code>ancestry(*, branch=None, tag=None, snapshot=None)</code>","text":"<p>Get the ancestry of a snapshot.</p> <p>Args:     branch: The branch to get the ancestry of.     tag: The tag to get the ancestry of.     snapshot: The snapshot ID to get the ancestry of.</p> <p>Returns:     list[SnapshotMetadata]: The ancestry of the snapshot, listing out the snapshots and their metadata</p> <p>Only one of the arguments can be specified.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def ancestry(\n    self,\n    *,\n    branch: str | None = None,\n    tag: str | None = None,\n    snapshot: str | None = None,\n) -&gt; list[SnapshotMetadata]:\n    \"\"\"Get the ancestry of a snapshot.\n\n    Args:\n        branch: The branch to get the ancestry of.\n        tag: The tag to get the ancestry of.\n        snapshot: The snapshot ID to get the ancestry of.\n\n    Returns:\n        list[SnapshotMetadata]: The ancestry of the snapshot, listing out the snapshots and their metadata\n\n    Only one of the arguments can be specified.\n    \"\"\"\n    return self._repository.ancestry(branch=branch, tag=tag, snapshot=snapshot)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.create","title":"<code>create(storage, config=None, virtual_chunk_credentials=None)</code>  <code>classmethod</code>","text":"<p>Create a new Icechunk repository.</p> <p>If one already exists at the given store location, an error will be raised.</p> <p>Args:     storage: The storage configuration for the repository.     config: The repository configuration. If not provided, a default configuration will be used.</p> Source code in <code>icechunk/repository.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    storage: Storage,\n    config: RepositoryConfig | None = None,\n    virtual_chunk_credentials: dict[str, AnyCredential] | None = None,\n) -&gt; Self:\n    \"\"\"Create a new Icechunk repository.\n\n    If one already exists at the given store location, an error will be raised.\n\n    Args:\n        storage: The storage configuration for the repository.\n        config: The repository configuration. If not provided, a default configuration will be used.\n    \"\"\"\n    return cls(\n        PyRepository.create(\n            storage,\n            config=config,\n            virtual_chunk_credentials=virtual_chunk_credentials,\n        )\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.create_branch","title":"<code>create_branch(branch, snapshot_id)</code>","text":"<p>Create a new branch at the given snapshot.</p> <p>Args:     branch: The name of the branch to create.     snapshot_id: The snapshot ID to create the branch at.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def create_branch(self, branch: str, snapshot_id: str) -&gt; None:\n    \"\"\"Create a new branch at the given snapshot.\n\n    Args:\n        branch: The name of the branch to create.\n        snapshot_id: The snapshot ID to create the branch at.\n    \"\"\"\n    self._repository.create_branch(branch, snapshot_id)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.create_tag","title":"<code>create_tag(tag, snapshot_id)</code>","text":"<p>Create a new tag at the given snapshot.</p> <p>Args:     tag: The name of the tag to create.     snapshot_id: The snapshot ID to create the tag at.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def create_tag(self, tag: str, snapshot_id: str) -&gt; None:\n    \"\"\"Create a new tag at the given snapshot.\n\n    Args:\n        tag: The name of the tag to create.\n        snapshot_id: The snapshot ID to create the tag at.\n    \"\"\"\n    self._repository.create_tag(tag, snapshot_id)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.delete_branch","title":"<code>delete_branch(branch)</code>","text":"<p>Delete a branch.</p> <p>Args:     branch: The branch to delete.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def delete_branch(self, branch: str) -&gt; None:\n    \"\"\"Delete a branch.\n\n    Args:\n        branch: The branch to delete.\n    \"\"\"\n    self._repository.delete_branch(branch)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.exists","title":"<code>exists(storage)</code>  <code>staticmethod</code>","text":"<p>Check if a repository exists at the given storage location.</p> <p>Args:     storage: The storage configuration for the repository.</p> Source code in <code>icechunk/repository.py</code> <pre><code>@staticmethod\ndef exists(storage: Storage) -&gt; bool:\n    \"\"\"Check if a repository exists at the given storage location.\n\n    Args:\n        storage: The storage configuration for the repository.\n    \"\"\"\n    return PyRepository.exists(storage)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.fetch_config","title":"<code>fetch_config(storage)</code>  <code>staticmethod</code>","text":"<p>Fetch the configuration for the repository saved in storage</p> Source code in <code>icechunk/repository.py</code> <pre><code>@staticmethod\ndef fetch_config(storage: Storage) -&gt; RepositoryConfig | None:\n    \"\"\"Fetch the configuration for the repository saved in storage\"\"\"\n    return PyRepository.fetch_config(storage)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.list_branches","title":"<code>list_branches()</code>","text":"<p>List the branches in the repository.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def list_branches(self) -&gt; set[str]:\n    \"\"\"List the branches in the repository.\"\"\"\n    return self._repository.list_branches()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.list_tags","title":"<code>list_tags()</code>","text":"<p>List the tags in the repository.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def list_tags(self) -&gt; set[str]:\n    \"\"\"List the tags in the repository.\"\"\"\n    return self._repository.list_tags()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.lookup_branch","title":"<code>lookup_branch(branch)</code>","text":"<p>Get the tip snapshot ID of a branch.</p> <p>Args:     branch: The branch to get the tip of.</p> <p>Returns:     str: The snapshot ID of the tip of the branch</p> Source code in <code>icechunk/repository.py</code> <pre><code>def lookup_branch(self, branch: str) -&gt; str:\n    \"\"\"Get the tip snapshot ID of a branch.\n\n    Args:\n        branch: The branch to get the tip of.\n\n    Returns:\n        str: The snapshot ID of the tip of the branch\n    \"\"\"\n    return self._repository.lookup_branch(branch)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.lookup_tag","title":"<code>lookup_tag(tag)</code>","text":"<p>Get the snapshot ID of a tag.</p> <p>Args:     tag: The tag to get the snapshot ID of.</p> <p>Returns:     str: The snapshot ID of the tag.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def lookup_tag(self, tag: str) -&gt; str:\n    \"\"\"Get the snapshot ID of a tag.\n\n    Args:\n        tag: The tag to get the snapshot ID of.\n\n    Returns:\n        str: The snapshot ID of the tag.\n    \"\"\"\n    return self._repository.lookup_tag(tag)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.open","title":"<code>open(storage, config=None, virtual_chunk_credentials=None)</code>  <code>classmethod</code>","text":"<p>Open an existing Icechunk repository.</p> <p>If no repository exists at the given storage location, an error will be raised.</p> <p>Args:     storage: The storage configuration for the repository.     config: The repository settings. If not provided, a default configuration will be     loaded from the repository</p> Source code in <code>icechunk/repository.py</code> <pre><code>@classmethod\ndef open(\n    cls,\n    storage: Storage,\n    config: RepositoryConfig | None = None,\n    virtual_chunk_credentials: dict[str, AnyCredential] | None = None,\n) -&gt; Self:\n    \"\"\"Open an existing Icechunk repository.\n\n    If no repository exists at the given storage location, an error will be raised.\n\n    Args:\n        storage: The storage configuration for the repository.\n        config: The repository settings. If not provided, a default configuration will be\n        loaded from the repository\n    \"\"\"\n    return cls(\n        PyRepository.open(\n            storage,\n            config=config,\n            virtual_chunk_credentials=virtual_chunk_credentials,\n        )\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.open_or_create","title":"<code>open_or_create(storage, config=None, virtual_chunk_credentials=None)</code>  <code>classmethod</code>","text":"<p>Open an existing Icechunk repository or create a new one if it does not exist.</p> <p>Args:     storage: The storage configuration for the repository.     config: The repository settings. If not provided, a default configuration will be     loaded from the repository</p> Source code in <code>icechunk/repository.py</code> <pre><code>@classmethod\ndef open_or_create(\n    cls,\n    storage: Storage,\n    config: RepositoryConfig | None = None,\n    virtual_chunk_credentials: dict[str, AnyCredential] | None = None,\n) -&gt; Self:\n    \"\"\"Open an existing Icechunk repository or create a new one if it does not exist.\n\n    Args:\n        storage: The storage configuration for the repository.\n        config: The repository settings. If not provided, a default configuration will be\n        loaded from the repository\n    \"\"\"\n    return cls(\n        PyRepository.open_or_create(\n            storage,\n            config=config,\n            virtual_chunk_credentials=virtual_chunk_credentials,\n        )\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.readonly_session","title":"<code>readonly_session(*, branch=None, tag=None, snapshot=None)</code>","text":"<p>Create a read-only session.</p> <p>This can be thought of as a read-only checkout of the repository at a given snapshot. When branch or tag are provided, the session will be based on the tip of the branch or the snapshot ID of the tag.</p> <p>Args:     branch: If provided, the branch to create the session on.     tag: If provided, the tag to create the session on.     snapshot: If provided, the snapshot ID to create the session on.</p> <p>Returns:     Session: The read-only session, pointing to the specified snapshot, tag, or branch.</p> <p>Only one of the arguments can be specified.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def readonly_session(\n    self,\n    *,\n    branch: str | None = None,\n    tag: str | None = None,\n    snapshot: str | None = None,\n) -&gt; Session:\n    \"\"\"Create a read-only session.\n\n    This can be thought of as a read-only checkout of the repository at a given snapshot.\n    When branch or tag are provided, the session will be based on the tip of the branch or\n    the snapshot ID of the tag.\n\n    Args:\n        branch: If provided, the branch to create the session on.\n        tag: If provided, the tag to create the session on.\n        snapshot: If provided, the snapshot ID to create the session on.\n\n    Returns:\n        Session: The read-only session, pointing to the specified snapshot, tag, or branch.\n\n    Only one of the arguments can be specified.\n    \"\"\"\n    return Session(\n        self._repository.readonly_session(branch=branch, tag=tag, snapshot=snapshot)\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.reset_branch","title":"<code>reset_branch(branch, snapshot_id)</code>","text":"<p>Reset a branch to a specific snapshot.</p> <p>This will permanently alter the history of the branch such that the tip of the branch is the specified snapshot.</p> <p>Args:     branch: The branch to reset.     snapshot_id: The snapshot ID to reset the branch to.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def reset_branch(self, branch: str, snapshot_id: str) -&gt; None:\n    \"\"\"Reset a branch to a specific snapshot.\n\n    This will permanently alter the history of the branch such that the tip of\n    the branch is the specified snapshot.\n\n    Args:\n        branch: The branch to reset.\n        snapshot_id: The snapshot ID to reset the branch to.\n    \"\"\"\n    self._repository.reset_branch(branch, snapshot_id)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.save_config","title":"<code>save_config()</code>","text":"<p>Save the repository configuration to storage, this configuration will be used in future calls to Repository.open.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def save_config(self) -&gt; None:\n    \"\"\"Save the repository configuration to storage, this configuration will be used in future calls to Repository.open.\"\"\"\n    return self._repository.save_config()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Repository.writable_session","title":"<code>writable_session(branch)</code>","text":"<p>Create a writable session on a branch</p> <p>Like the read-only session, this can be thought of as a checkout of the repository at the tip of the branch. However, this session is writable and can be used to make changes to the repository. When ready, the changes can be committed to the branch, after which the session will become a read-only session on the new snapshot.</p> <p>Args:     branch: The branch to create the session on.</p> <p>Returns:     Session: The writable session on the branch.</p> Source code in <code>icechunk/repository.py</code> <pre><code>def writable_session(self, branch: str) -&gt; Session:\n    \"\"\"Create a writable session on a branch\n\n    Like the read-only session, this can be thought of as a checkout of the repository at the\n    tip of the branch. However, this session is writable and can be used to make changes to the\n    repository. When ready, the changes can be committed to the branch, after which the session will\n    become a read-only session on the new snapshot.\n\n    Args:\n        branch: The branch to create the session on.\n\n    Returns:\n        Session: The writable session on the branch.\n\n    \"\"\"\n    return Session(self._repository.writable_session(branch))\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.RepositoryConfig","title":"<code>RepositoryConfig</code>","text":"<p>Configuration for an Icechunk repository</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class RepositoryConfig:\n    \"\"\"Configuration for an Icechunk repository\"\"\"\n\n    @staticmethod\n    def default() -&gt; RepositoryConfig: ...\n    @property\n    def inline_chunk_threshold_bytes(self) -&gt; int: ...\n    @inline_chunk_threshold_bytes.setter\n    def inline_chunk_threshold_bytes(self, value: int) -&gt; None: ...\n    @property\n    def unsafe_overwrite_refs(self) -&gt; bool: ...\n    @unsafe_overwrite_refs.setter\n    def unsafe_overwrite_refs(self, value: bool) -&gt; None: ...\n    @property\n    def get_partial_values_concurrency(self) -&gt; int: ...\n    @get_partial_values_concurrency.setter\n    def get_partial_values_concurrency(self, value: int) -&gt; None: ...\n    @property\n    def compression(self) -&gt; CompressionConfig: ...\n    @compression.setter\n    def compression(self, value: CompressionConfig) -&gt; None: ...\n    @property\n    def caching(self) -&gt; CachingConfig: ...\n    @caching.setter\n    def caching(self, value: CachingConfig) -&gt; None: ...\n    @property\n    def storage(self) -&gt; Storage: ...\n    @storage.setter\n    def storage(self, value: Storage) -&gt; None: ...\n    @property\n    def virtual_chunk_containers(self) -&gt; dict[str, VirtualChunkContainer]: ...\n    @virtual_chunk_containers.setter\n    def virtual_chunk_containers(\n        self, value: dict[str, VirtualChunkContainer]\n    ) -&gt; None: ...\n    def set_virtual_chunk_container(self, cont: VirtualChunkContainer) -&gt; None: ...\n    def clear_virtual_chunk_containers(self) -&gt; None: ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Session","title":"<code>Session</code>","text":"<p>A session object that allows for reading and writing data from an Icechunk repository.</p> Source code in <code>icechunk/session.py</code> <pre><code>class Session:\n    \"\"\"A session object that allows for reading and writing data from an Icechunk repository.\"\"\"\n\n    _session: PySession\n\n    def __init__(self, session: PySession):\n        self._session = session\n        self._allow_distributed_write = False\n\n    def __eq__(self, value: object) -&gt; bool:\n        if not isinstance(value, Session):\n            return False\n        return self._session == value._session\n\n    def __getstate__(self) -&gt; object:\n        state = {\n            \"_session\": self._session.as_bytes(),\n        }\n        return state\n\n    def __setstate__(self, state: object) -&gt; None:\n        if not isinstance(state, dict):\n            raise ValueError(\"Invalid state\")\n        self._session = PySession.from_bytes(state[\"_session\"])\n\n    @property\n    def read_only(self) -&gt; bool:\n        \"\"\"Whether the session is read-only.\"\"\"\n        return self._session.read_only\n\n    @property\n    def snapshot_id(self) -&gt; str:\n        \"\"\"The base snapshot ID of the session\"\"\"\n        return self._session.snapshot_id\n\n    @property\n    def branch(self) -&gt; str | None:\n        \"\"\"The branch that the session is based on. This is only set if the\n        session is writable\"\"\"\n        return self._session.branch\n\n    @property\n    def has_uncommitted_changes(self) -&gt; bool:\n        \"\"\"Whether the session has uncommitted changes. This is only possibly\n        true if the session is writable\"\"\"\n        return self._session.has_uncommitted_changes\n\n    def discard_changes(self) -&gt; None:\n        \"\"\"When the session is writable, discard any uncommitted changes\"\"\"\n        self._session.discard_changes()\n\n    @property\n    def store(self) -&gt; IcechunkStore:\n        \"\"\"Get a zarr Store object for reading and writing data from the repository using zarr python\"\"\"\n        return IcechunkStore(self._session.store)\n\n    def all_virtual_chunk_locations(self) -&gt; list[str]:\n        \"\"\"Return the location URLs of all virtual chunks\"\"\"\n        return self._session.all_virtual_chunk_locations()\n\n    def merge(self, other: Self) -&gt; None:\n        \"\"\"Merge the changes for this session with the changes from another session\"\"\"\n        self._session.merge(other._session)\n\n    def commit(self, message: str) -&gt; str:\n        \"\"\"Commit the changes in the session to the repository\n\n        When successful, the writable session is completed and the session is now read-only\n        and based on the new commit. The snapshot ID of the new commit is returned.\n\n        If the session is out of date, this will raise a ConflictError exception depicting\n        the conflict that occurred. The session will need to be rebased before committing.\n\n        Args:\n            message (str): The message to write with the commit\n\n        Returns:\n            str: The snapshot ID of the new commit\n        \"\"\"\n        try:\n            return self._session.commit(message)\n        except PyConflictError as e:\n            raise ConflictError(e) from None\n\n    def rebase(self, solver: ConflictSolver) -&gt; None:\n        \"\"\"Rebase the session to the latest ancestry of the branch.\n\n        This method will iteratively crawl the ancestry of the branch and apply the changes\n        from the branch to the session. If a conflict is detected, the conflict solver will\n        be used to optionally resolve the conflict. When complete, the session will be based\n        on the latest commit of the branch and the session will be ready to attempt another\n        commit.\n\n        When a conflict is detected and a resolution is not possible with the proivided\n        solver, a RebaseFailed exception will be raised. This exception will contain the\n        snapshot ID that the rebase failed on and a list of conflicts that occurred.\n\n        Args:\n            solver (ConflictSolver): The conflict solver to use when a conflict is detected\n\n        Raises:\n            RebaseFailed: When a conflict is detected and the solver fails to resolve it\n\n        \"\"\"\n        try:\n            self._session.rebase(solver)\n        except PyRebaseFailedError as e:\n            raise RebaseFailedError(e) from None\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Session.branch","title":"<code>branch: str | None</code>  <code>property</code>","text":"<p>The branch that the session is based on. This is only set if the session is writable</p>"},{"location":"icechunk-python/reference/#icechunk.Session.has_uncommitted_changes","title":"<code>has_uncommitted_changes: bool</code>  <code>property</code>","text":"<p>Whether the session has uncommitted changes. This is only possibly true if the session is writable</p>"},{"location":"icechunk-python/reference/#icechunk.Session.read_only","title":"<code>read_only: bool</code>  <code>property</code>","text":"<p>Whether the session is read-only.</p>"},{"location":"icechunk-python/reference/#icechunk.Session.snapshot_id","title":"<code>snapshot_id: str</code>  <code>property</code>","text":"<p>The base snapshot ID of the session</p>"},{"location":"icechunk-python/reference/#icechunk.Session.store","title":"<code>store: IcechunkStore</code>  <code>property</code>","text":"<p>Get a zarr Store object for reading and writing data from the repository using zarr python</p>"},{"location":"icechunk-python/reference/#icechunk.Session.all_virtual_chunk_locations","title":"<code>all_virtual_chunk_locations()</code>","text":"<p>Return the location URLs of all virtual chunks</p> Source code in <code>icechunk/session.py</code> <pre><code>def all_virtual_chunk_locations(self) -&gt; list[str]:\n    \"\"\"Return the location URLs of all virtual chunks\"\"\"\n    return self._session.all_virtual_chunk_locations()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Session.commit","title":"<code>commit(message)</code>","text":"<p>Commit the changes in the session to the repository</p> <p>When successful, the writable session is completed and the session is now read-only and based on the new commit. The snapshot ID of the new commit is returned.</p> <p>If the session is out of date, this will raise a ConflictError exception depicting the conflict that occurred. The session will need to be rebased before committing.</p> <p>Args:     message (str): The message to write with the commit</p> <p>Returns:     str: The snapshot ID of the new commit</p> Source code in <code>icechunk/session.py</code> <pre><code>def commit(self, message: str) -&gt; str:\n    \"\"\"Commit the changes in the session to the repository\n\n    When successful, the writable session is completed and the session is now read-only\n    and based on the new commit. The snapshot ID of the new commit is returned.\n\n    If the session is out of date, this will raise a ConflictError exception depicting\n    the conflict that occurred. The session will need to be rebased before committing.\n\n    Args:\n        message (str): The message to write with the commit\n\n    Returns:\n        str: The snapshot ID of the new commit\n    \"\"\"\n    try:\n        return self._session.commit(message)\n    except PyConflictError as e:\n        raise ConflictError(e) from None\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Session.discard_changes","title":"<code>discard_changes()</code>","text":"<p>When the session is writable, discard any uncommitted changes</p> Source code in <code>icechunk/session.py</code> <pre><code>def discard_changes(self) -&gt; None:\n    \"\"\"When the session is writable, discard any uncommitted changes\"\"\"\n    self._session.discard_changes()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Session.merge","title":"<code>merge(other)</code>","text":"<p>Merge the changes for this session with the changes from another session</p> Source code in <code>icechunk/session.py</code> <pre><code>def merge(self, other: Self) -&gt; None:\n    \"\"\"Merge the changes for this session with the changes from another session\"\"\"\n    self._session.merge(other._session)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.Session.rebase","title":"<code>rebase(solver)</code>","text":"<p>Rebase the session to the latest ancestry of the branch.</p> <p>This method will iteratively crawl the ancestry of the branch and apply the changes from the branch to the session. If a conflict is detected, the conflict solver will be used to optionally resolve the conflict. When complete, the session will be based on the latest commit of the branch and the session will be ready to attempt another commit.</p> <p>When a conflict is detected and a resolution is not possible with the proivided solver, a RebaseFailed exception will be raised. This exception will contain the snapshot ID that the rebase failed on and a list of conflicts that occurred.</p> <p>Args:     solver (ConflictSolver): The conflict solver to use when a conflict is detected</p> <p>Raises:     RebaseFailed: When a conflict is detected and the solver fails to resolve it</p> Source code in <code>icechunk/session.py</code> <pre><code>def rebase(self, solver: ConflictSolver) -&gt; None:\n    \"\"\"Rebase the session to the latest ancestry of the branch.\n\n    This method will iteratively crawl the ancestry of the branch and apply the changes\n    from the branch to the session. If a conflict is detected, the conflict solver will\n    be used to optionally resolve the conflict. When complete, the session will be based\n    on the latest commit of the branch and the session will be ready to attempt another\n    commit.\n\n    When a conflict is detected and a resolution is not possible with the proivided\n    solver, a RebaseFailed exception will be raised. This exception will contain the\n    snapshot ID that the rebase failed on and a list of conflicts that occurred.\n\n    Args:\n        solver (ConflictSolver): The conflict solver to use when a conflict is detected\n\n    Raises:\n        RebaseFailed: When a conflict is detected and the solver fails to resolve it\n\n    \"\"\"\n    try:\n        self._session.rebase(solver)\n    except PyRebaseFailedError as e:\n        raise RebaseFailedError(e) from None\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.SnapshotMetadata","title":"<code>SnapshotMetadata</code>","text":"<p>Metadata for a snapshot</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class SnapshotMetadata:\n    \"\"\"Metadata for a snapshot\"\"\"\n    @property\n    def id(self) -&gt; str:\n        \"\"\"The snapshot ID\"\"\"\n        ...\n    @property\n    def written_at(self) -&gt; datetime.datetime:\n        \"\"\"\n        The timestamp when the snapshot was written\n        \"\"\"\n        ...\n    @property\n    def message(self) -&gt; str:\n        \"\"\"\n        The commit message of the snapshot\n        \"\"\"\n        ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.SnapshotMetadata.id","title":"<code>id: str</code>  <code>property</code>","text":"<p>The snapshot ID</p>"},{"location":"icechunk-python/reference/#icechunk.SnapshotMetadata.message","title":"<code>message: str</code>  <code>property</code>","text":"<p>The commit message of the snapshot</p>"},{"location":"icechunk-python/reference/#icechunk.SnapshotMetadata.written_at","title":"<code>written_at: datetime.datetime</code>  <code>property</code>","text":"<p>The timestamp when the snapshot was written</p>"},{"location":"icechunk-python/reference/#icechunk.Storage","title":"<code>Storage</code>","text":"<p>Storage configuration for an IcechunkStore</p> <p>Currently supports memory, filesystem, and S3 storage backends. Use the class methods to create a StorageConfig object with the desired backend.</p> <p>Ex: <pre><code>storage_config = StorageConfig.memory(\"prefix\")\nstorage_config = StorageConfig.filesystem(\"/path/to/root\")\nstorage_config = StorageConfig.object_store(\"s3://bucket/prefix\", vec![\"my\", \"options\"])\nstorage_config = StorageConfig.s3_from_env(\"bucket\", \"prefix\")\nstorage_config = StorageConfig.s3_from_config(\"bucket\", \"prefix\", ...)\n</code></pre></p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class Storage:\n    \"\"\"Storage configuration for an IcechunkStore\n\n    Currently supports memory, filesystem, and S3 storage backends.\n    Use the class methods to create a StorageConfig object with the desired backend.\n\n    Ex:\n    ```\n    storage_config = StorageConfig.memory(\"prefix\")\n    storage_config = StorageConfig.filesystem(\"/path/to/root\")\n    storage_config = StorageConfig.object_store(\"s3://bucket/prefix\", vec![\"my\", \"options\"])\n    storage_config = StorageConfig.s3_from_env(\"bucket\", \"prefix\")\n    storage_config = StorageConfig.s3_from_config(\"bucket\", \"prefix\", ...)\n    ```\n    \"\"\"\n\n    @classmethod\n    def new_s3(\n        cls,\n        config: S3Options,\n        bucket: str,\n        prefix: str | None,\n        credentials: AnyS3Credential | None = None,\n    ) -&gt; Storage: ...\n    @classmethod\n    def new_in_memory(cls) -&gt; Storage: ...\n    @classmethod\n    def new_local_filesystem(cls, path: str) -&gt; Storage: ...\n    @classmethod\n    def new_gcs(\n        cls,\n        bucket: str,\n        prefix: str | None,\n        credentials: AnyGcsCredential | None = None,\n        *,\n        config: dict[str, str] | None = None,\n    ) -&gt; Storage: ...\n    @classmethod\n    def new_azure_blob(\n        cls,\n        container: str,\n        prefix: str,\n        credentials: AnyAzureCredential | None = None,\n        *,\n        config: dict[str, str] | None = None,\n    ) -&gt; Storage: ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.StorageConcurrencySettings","title":"<code>StorageConcurrencySettings</code>","text":"<p>Configuration for how Icechunk uses its Storage instance</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class StorageConcurrencySettings:\n    \"\"\"Configuration for how Icechunk uses its Storage instance\"\"\"\n\n    @property\n    def max_concurrent_requests_for_object(self) -&gt; int: ...\n    @max_concurrent_requests_for_object.setter\n    def max_concurrent_requests_for_object(self, value: int) -&gt; None: ...\n    @property\n    def ideal_concurrent_request_size(self) -&gt; int: ...\n    @ideal_concurrent_request_size.setter\n    def ideal_concurrent_request_size(self, value: int) -&gt; None: ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.StorageSettings","title":"<code>StorageSettings</code>","text":"<p>Configuration for how Icechunk uses its Storage instance</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class StorageSettings:\n    \"\"\"Configuration for how Icechunk uses its Storage instance\"\"\"\n\n    @property\n    def concurrency(self) -&gt; StorageConcurrencySettings: ...\n    @concurrency.setter\n    def concurrency(self, value: StorageConcurrencySettings) -&gt; None: ...\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.VersionSelection","title":"<code>VersionSelection</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for selecting the which version of a conflict</p> Source code in <code>icechunk/_icechunk_python.pyi</code> <pre><code>class VersionSelection(Enum):\n    \"\"\"Enum for selecting the which version of a conflict\"\"\"\n\n    Fail = 0\n    UseOurs = 1\n    UseTheirs = 2\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.azure_credentials","title":"<code>azure_credentials(*, access_key=None, sas_token=None, bearer_token=None, from_env=None)</code>","text":"<p>Create credentials Azure Blob Storage object store.</p> <p>If all arguments are None, credentials are fetched from the operative system environment.</p> Source code in <code>icechunk/credentials.py</code> <pre><code>def azure_credentials(\n    *,\n    access_key: str | None = None,\n    sas_token: str | None = None,\n    bearer_token: str | None = None,\n    from_env: bool | None = None,\n) -&gt; AnyAzureCredential:\n    \"\"\"Create credentials Azure Blob Storage object store.\n\n    If all arguments are None, credentials are fetched from the operative system environment.\n    \"\"\"\n    if (from_env is None or from_env) and (\n        access_key is None and sas_token is None and bearer_token is None\n    ):\n        return azure_from_env_credentials()\n\n    if (access_key is not None or sas_token is not None or bearer_token is not None) and (\n        from_env is None or not from_env\n    ):\n        return AzureCredentials.Static(\n            azure_static_credentials(\n                access_key=access_key,\n                sas_token=sas_token,\n                bearer_token=bearer_token,\n            )\n        )\n\n    raise ValueError(\"Conflicting arguments to azure_credentials function\")\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.azure_from_env_credentials","title":"<code>azure_from_env_credentials()</code>","text":"<p>Instruct Azure Blob Storage object store to fetch credentials from the operative system environment.</p> Source code in <code>icechunk/credentials.py</code> <pre><code>def azure_from_env_credentials() -&gt; AzureCredentials.FromEnv:\n    \"\"\"Instruct Azure Blob Storage object store to fetch credentials from the operative system environment.\"\"\"\n    return AzureCredentials.FromEnv()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.azure_static_credentials","title":"<code>azure_static_credentials(*, access_key=None, sas_token=None, bearer_token=None)</code>","text":"<p>Create static credentials Azure Blob Storage object store.</p> Source code in <code>icechunk/credentials.py</code> <pre><code>def azure_static_credentials(\n    *,\n    access_key: str | None = None,\n    sas_token: str | None = None,\n    bearer_token: str | None = None,\n) -&gt; AnyAzureStaticCredential:\n    \"\"\"Create static credentials Azure Blob Storage object store.\"\"\"\n    if [access_key, sas_token, bearer_token].count(None) != 2:\n        raise ValueError(\"Conflicting arguments to azure_static_credentials function\")\n    if access_key is not None:\n        return AzureStaticCredentials.AccessKey(access_key)\n    if sas_token is not None:\n        return AzureStaticCredentials.SasToken(sas_token)\n    if bearer_token is not None:\n        return AzureStaticCredentials.BearerToken(bearer_token)\n    raise ValueError(\n        \"No valid static credential provided for Azure Blob Storage object store\"\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.azure_storage","title":"<code>azure_storage(*, container, prefix, access_key=None, sas_token=None, bearer_token=None, from_env=None, config=None)</code>","text":"<p>Create a Storage instance that saves data in Azure Blob Storage object store.</p> <p>Parameters:</p> Name Type Description Default <code>container</code> <code>str</code> <p>The container where the repository will store its data</p> required <code>prefix</code> <code>str</code> <p>The prefix within the container that is the root directory of the repository</p> required <code>access_key</code> <code>str | None</code> <p>Azure Blob Storage credential access key</p> <code>None</code> <code>sas_token</code> <code>str | None</code> <p>Azure Blob Storage credential SAS token</p> <code>None</code> <code>bearer_token</code> <code>str | None</code> <p>Azure Blob Storage credential bearer token</p> <code>None</code> <code>from_env</code> <code>bool | None</code> <p>Fetch credentials from the operative system environment</p> <code>None</code> Source code in <code>icechunk/storage.py</code> <pre><code>def azure_storage(\n    *,\n    container: str,\n    prefix: str,\n    access_key: str | None = None,\n    sas_token: str | None = None,\n    bearer_token: str | None = None,\n    from_env: bool | None = None,\n    config: dict[str, str] | None = None,\n) -&gt; Storage:\n    \"\"\"Create a Storage instance that saves data in Azure Blob Storage object store.\n\n    Parameters\n    ----------\n    container: str\n        The container where the repository will store its data\n    prefix: str\n        The prefix within the container that is the root directory of the repository\n    access_key: str | None\n        Azure Blob Storage credential access key\n    sas_token: str | None\n        Azure Blob Storage credential SAS token\n    bearer_token: str | None\n        Azure Blob Storage credential bearer token\n    from_env: bool | None\n        Fetch credentials from the operative system environment\n    \"\"\"\n    credentials = azure_credentials(\n        access_key=access_key,\n        sas_token=sas_token,\n        bearer_token=bearer_token,\n        from_env=from_env,\n    )\n    return Storage.new_azure_blob(\n        container=container,\n        prefix=prefix,\n        credentials=credentials,\n        config=config,\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.containers_credentials","title":"<code>containers_credentials(m={}, **kwargs)</code>","text":"<p>Build a map of credentials for virtual chunk containers.</p> <p>Example usage: <pre><code>import icechunk as ic\n\nconfig = ic.RepositoryConfig.default()\nconfig.inline_chunk_threshold_bytes = 512\n\nvirtual_store_config = ic.s3_store(\n    region=\"us-east-1\",\n    endpoint_url=\"http://localhost:9000\",\n    allow_http=True,\n    s3_compatible=True,\n)\ncontainer = ic.VirtualChunkContainer(\"s3\", \"s3://\", virtual_store_config)\nconfig.set_virtual_chunk_container(container)\ncredentials = ic.containers_credentials(\n    s3=ic.s3_credentials(access_key_id=\"ACCESS_KEY\", secret_access_key=\"SECRET\")\n)\n\nrepo = ic.Repository.create(\n    storage=ic.local_filesystem_storage(store_path),\n    config=config,\n    virtual_chunk_credentials=credentials,\n)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>Mapping[str, AnyS3Credential]</code> <p>A mapping from container name to credentials.</p> <code>{}</code> Source code in <code>icechunk/credentials.py</code> <pre><code>def containers_credentials(\n    m: Mapping[str, AnyS3Credential] = {}, **kwargs: AnyS3Credential\n) -&gt; dict[str, Credentials.S3]:\n    \"\"\"Build a map of credentials for virtual chunk containers.\n\n    Example usage:\n    ```\n    import icechunk as ic\n\n    config = ic.RepositoryConfig.default()\n    config.inline_chunk_threshold_bytes = 512\n\n    virtual_store_config = ic.s3_store(\n        region=\"us-east-1\",\n        endpoint_url=\"http://localhost:9000\",\n        allow_http=True,\n        s3_compatible=True,\n    )\n    container = ic.VirtualChunkContainer(\"s3\", \"s3://\", virtual_store_config)\n    config.set_virtual_chunk_container(container)\n    credentials = ic.containers_credentials(\n        s3=ic.s3_credentials(access_key_id=\"ACCESS_KEY\", secret_access_key=\"SECRET\")\n    )\n\n    repo = ic.Repository.create(\n        storage=ic.local_filesystem_storage(store_path),\n        config=config,\n        virtual_chunk_credentials=credentials,\n    )\n    ```\n\n    Parameters\n    ----------\n    m: Mapping[str, AnyS3Credential]\n        A mapping from container name to credentials.\n    \"\"\"\n    res = {}\n    for name, cred in {**m, **kwargs}.items():\n        if isinstance(cred, AnyS3Credential):\n            res[name] = Credentials.S3(cred)\n        else:\n            raise ValueError(f\"Unknown credential type {type(cred)}\")\n    return res\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.gcs_credentials","title":"<code>gcs_credentials(*, service_account_file=None, service_account_key=None, application_credentials=None, from_env=None)</code>","text":"<p>Create credentials Google Cloud Storage object store.</p> <p>If all arguments are None, credentials are fetched from the operative system environment.</p> Source code in <code>icechunk/credentials.py</code> <pre><code>def gcs_credentials(\n    *,\n    service_account_file: str | None = None,\n    service_account_key: str | None = None,\n    application_credentials: str | None = None,\n    from_env: bool | None = None,\n) -&gt; AnyGcsCredential:\n    \"\"\"Create credentials Google Cloud Storage object store.\n\n    If all arguments are None, credentials are fetched from the operative system environment.\n    \"\"\"\n    if (from_env is None or from_env) and (\n        service_account_file is None\n        and service_account_key is None\n        and application_credentials is None\n    ):\n        return gcs_from_env_credentials()\n\n    if (\n        service_account_file is not None\n        or service_account_key is not None\n        or application_credentials is not None\n    ) and (from_env is None or not from_env):\n        return GcsCredentials.Static(\n            gcs_static_credentials(\n                service_account_file=service_account_file,\n                service_account_key=service_account_key,\n                application_credentials=application_credentials,\n            )\n        )\n\n    raise ValueError(\"Conflicting arguments to gcs_credentials function\")\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.gcs_from_env_credentials","title":"<code>gcs_from_env_credentials()</code>","text":"<p>Instruct Google Cloud Storage object store to fetch credentials from the operative system environment.</p> Source code in <code>icechunk/credentials.py</code> <pre><code>def gcs_from_env_credentials() -&gt; GcsCredentials.FromEnv:\n    \"\"\"Instruct Google Cloud Storage object store to fetch credentials from the operative system environment.\"\"\"\n    return GcsCredentials.FromEnv()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.gcs_static_credentials","title":"<code>gcs_static_credentials(*, service_account_file=None, service_account_key=None, application_credentials=None)</code>","text":"<p>Create static credentials Google Cloud Storage object store.</p> Source code in <code>icechunk/credentials.py</code> <pre><code>def gcs_static_credentials(\n    *,\n    service_account_file: str | None = None,\n    service_account_key: str | None = None,\n    application_credentials: str | None = None,\n) -&gt; AnyGcsStaticCredential:\n    \"\"\"Create static credentials Google Cloud Storage object store.\"\"\"\n    if service_account_file is not None:\n        return GcsStaticCredentials.ServiceAccount(service_account_file)\n    if service_account_key is not None:\n        return GcsStaticCredentials.ServiceAccountKey(service_account_key)\n    if application_credentials is not None:\n        return GcsStaticCredentials.ApplicationCredentials(application_credentials)\n    raise ValueError(\"Conflicting arguments to gcs_static_credentials function\")\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.gcs_storage","title":"<code>gcs_storage(*, bucket, prefix, service_account_file=None, service_account_key=None, application_credentials=None, from_env=None, config=None)</code>","text":"<p>Create a Storage instance that saves data in Google Cloud Storage object store.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>The bucket where the repository will store its data</p> required <code>prefix</code> <code>str | None</code> <p>The prefix within the bucket that is the root directory of the repository</p> required <code>from_env</code> <code>bool | None</code> <p>Fetch credentials from the operative system environment</p> <code>None</code> Source code in <code>icechunk/storage.py</code> <pre><code>def gcs_storage(\n    *,\n    bucket: str,\n    prefix: str | None,\n    service_account_file: str | None = None,\n    service_account_key: str | None = None,\n    application_credentials: str | None = None,\n    from_env: bool | None = None,\n    config: dict[str, str] | None = None,\n) -&gt; Storage:\n    \"\"\"Create a Storage instance that saves data in Google Cloud Storage object store.\n\n    Parameters\n    ----------\n    bucket: str\n        The bucket where the repository will store its data\n    prefix: str | None\n        The prefix within the bucket that is the root directory of the repository\n    from_env: bool | None\n        Fetch credentials from the operative system environment\n    \"\"\"\n    credentials = gcs_credentials(\n        service_account_file=service_account_file,\n        service_account_key=service_account_key,\n        application_credentials=application_credentials,\n        from_env=from_env,\n    )\n    return Storage.new_gcs(\n        bucket=bucket,\n        prefix=prefix,\n        credentials=credentials,\n        config=config,\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.in_memory_storage","title":"<code>in_memory_storage()</code>","text":"<p>Create a Storage instance that saves data in memory.</p> <p>This Storage implementation is used for tests. Data will be lost after the process finishes, and can only be accesses through the Storage instance returned. Different instances don't share data.</p> Source code in <code>icechunk/storage.py</code> <pre><code>def in_memory_storage() -&gt; Storage:\n    \"\"\"Create a Storage instance that saves data in memory.\n\n    This Storage implementation is used for tests. Data will be lost after the process finishes, and can only be accesses through the Storage instance returned. Different instances don't share data.\"\"\"\n    return Storage.new_in_memory()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.local_filesystem_storage","title":"<code>local_filesystem_storage(path)</code>","text":"<p>Create a Storage instance that saves data in the local file system.</p> <p>This Storage instance is not recommended for production data</p> Source code in <code>icechunk/storage.py</code> <pre><code>def local_filesystem_storage(path: str) -&gt; Storage:\n    \"\"\"Create a Storage instance that saves data in the local file system.\n\n    This Storage instance is not recommended for production data\n    \"\"\"\n    return Storage.new_local_filesystem(path)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.s3_anonymous_credentials","title":"<code>s3_anonymous_credentials()</code>","text":"<p>Create no-signature credentials for S3 and S3 compatible object stores.</p> Source code in <code>icechunk/credentials.py</code> <pre><code>def s3_anonymous_credentials() -&gt; S3Credentials.Anonymous:\n    \"\"\"Create no-signature credentials for S3 and S3 compatible object stores.\"\"\"\n    return S3Credentials.Anonymous()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.s3_credentials","title":"<code>s3_credentials(*, access_key_id=None, secret_access_key=None, session_token=None, expires_after=None, anonymous=None, from_env=None, get_credentials=None)</code>","text":"<p>Create credentials for S3 and S3 compatible object stores.</p> <p>If all arguments are None, credentials are fetched from the environment.</p> <p>Parameters:</p> Name Type Description Default <code>access_key_id</code> <code>str | None</code> <p>S3 credential access key</p> <code>None</code> <code>secret_access_key</code> <code>str | None</code> <p>S3 credential secret access key</p> <code>None</code> <code>session_token</code> <code>str | None</code> <p>Optional S3 credential session token</p> <code>None</code> <code>expires_after</code> <code>datetime | None</code> <p>Optional expiration for the object store credentials</p> <code>None</code> <code>anonymous</code> <code>bool | None</code> <p>If set to True requests to the object store will not be signed</p> <code>None</code> <code>from_env</code> <code>bool | None</code> <p>Fetch credentials from the operative system environment</p> <code>None</code> <code>get_credentials</code> <code>Callable[[], S3StaticCredentials] | None</code> <p>Use this function to get and refresh object store credentials</p> <code>None</code> Source code in <code>icechunk/credentials.py</code> <pre><code>def s3_credentials(\n    *,\n    access_key_id: str | None = None,\n    secret_access_key: str | None = None,\n    session_token: str | None = None,\n    expires_after: datetime | None = None,\n    anonymous: bool | None = None,\n    from_env: bool | None = None,\n    get_credentials: Callable[[], S3StaticCredentials] | None = None,\n) -&gt; AnyS3Credential:\n    \"\"\"Create credentials for S3 and S3 compatible object stores.\n\n    If all arguments are None, credentials are fetched from the environment.\n\n    Parameters\n    ----------\n    access_key_id: str | None\n        S3 credential access key\n    secret_access_key: str | None\n        S3 credential secret access key\n    session_token: str | None\n        Optional S3 credential session token\n    expires_after: datetime | None\n        Optional expiration for the object store credentials\n    anonymous: bool | None\n        If set to True requests to the object store will not be signed\n    from_env: bool | None\n        Fetch credentials from the operative system environment\n    get_credentials: Callable[[], S3StaticCredentials] | None\n        Use this function to get and refresh object store credentials\n    \"\"\"\n    if (\n        (from_env is None or from_env)\n        and access_key_id is None\n        and secret_access_key is None\n        and session_token is None\n        and expires_after is None\n        and not anonymous\n        and get_credentials is None\n    ):\n        return s3_from_env_credentials()\n\n    if (\n        anonymous\n        and access_key_id is None\n        and secret_access_key is None\n        and session_token is None\n        and expires_after is None\n        and not from_env\n        and get_credentials is None\n    ):\n        return s3_anonymous_credentials()\n\n    if (\n        get_credentials is not None\n        and access_key_id is None\n        and secret_access_key is None\n        and session_token is None\n        and expires_after is None\n        and not from_env\n        and not anonymous\n    ):\n        return s3_refreshable_credentials(get_credentials)\n\n    if (\n        access_key_id\n        and secret_access_key\n        and not from_env\n        and not anonymous\n        and get_credentials is None\n    ):\n        return s3_static_credentials(\n            access_key_id=access_key_id,\n            secret_access_key=secret_access_key,\n            session_token=session_token,\n            expires_after=expires_after,\n        )\n\n    raise ValueError(\"Conflicting arguments to s3_credentials function\")\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.s3_from_env_credentials","title":"<code>s3_from_env_credentials()</code>","text":"<p>Instruct S3 and S3 compatible object stores to gather credentials from the operative system environment.</p> Source code in <code>icechunk/credentials.py</code> <pre><code>def s3_from_env_credentials() -&gt; S3Credentials.FromEnv:\n    \"\"\"Instruct S3 and S3 compatible object stores to gather credentials from the operative system environment.\"\"\"\n    return S3Credentials.FromEnv()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.s3_refreshable_credentials","title":"<code>s3_refreshable_credentials(get_credentials)</code>","text":"<p>Create refreshable credentials for S3 and S3 compatible object stores.</p> <p>Parameters:</p> Name Type Description Default <code>get_credentials</code> <code>Callable[[], S3StaticCredentials]</code> <p>Use this function to get and refresh the credentials. The function must be pickable.</p> required Source code in <code>icechunk/credentials.py</code> <pre><code>def s3_refreshable_credentials(\n    get_credentials: Callable[[], S3StaticCredentials],\n) -&gt; S3Credentials.Refreshable:\n    \"\"\"Create refreshable credentials for S3 and S3 compatible object stores.\n\n\n    Parameters\n    ----------\n    get_credentials: Callable[[], S3StaticCredentials]\n        Use this function to get and refresh the credentials. The function must be pickable.\n    \"\"\"\n    return S3Credentials.Refreshable(pickle.dumps(get_credentials))\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.s3_static_credentials","title":"<code>s3_static_credentials(*, access_key_id, secret_access_key, session_token=None, expires_after=None)</code>","text":"<p>Create static credentials for S3 and S3 compatible object stores.</p> <p>Parameters:</p> Name Type Description Default <code>access_key_id</code> <code>str</code> <p>S3 credential access key</p> required <code>secret_access_key</code> <code>str</code> <p>S3 credential secret access key</p> required <code>session_token</code> <code>str | None</code> <p>Optional S3 credential session token</p> <code>None</code> <code>expires_after</code> <code>datetime | None</code> <p>Optional expiration for the object store credentials</p> <code>None</code> Source code in <code>icechunk/credentials.py</code> <pre><code>def s3_static_credentials(\n    *,\n    access_key_id: str,\n    secret_access_key: str,\n    session_token: str | None = None,\n    expires_after: datetime | None = None,\n) -&gt; S3Credentials.Static:\n    \"\"\"Create static credentials for S3 and S3 compatible object stores.\n\n    Parameters\n    ----------\n    access_key_id: str | None\n        S3 credential access key\n    secret_access_key: str | None\n        S3 credential secret access key\n    session_token: str | None\n        Optional S3 credential session token\n    expires_after: datetime | None\n        Optional expiration for the object store credentials\n    \"\"\"\n    return S3Credentials.Static(\n        S3StaticCredentials(\n            access_key_id=access_key_id,\n            secret_access_key=secret_access_key,\n            session_token=session_token,\n            expires_after=expires_after,\n        )\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.s3_storage","title":"<code>s3_storage(*, bucket, prefix, region=None, endpoint_url=None, allow_http=False, access_key_id=None, secret_access_key=None, session_token=None, expires_after=None, anonymous=None, from_env=None, get_credentials=None)</code>","text":"<p>Create a Storage instance that saves data in S3 or S3 compatible object stores.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>The bucket where the repository will store its data</p> required <code>prefix</code> <code>str | None</code> <p>The prefix within the bucket that is the root directory of the repository</p> required <code>region</code> <code>str | None</code> <p>The region to use in the object store, if <code>None</code> a default region will be used</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>Optional endpoint where the object store serves data, example: http://localhost:9000</p> <code>None</code> <code>allow_http</code> <code>bool</code> <p>If the object store can be accessed using http protocol instead of https</p> <code>False</code> <code>access_key_id</code> <code>str | None</code> <p>S3 credential access key</p> <code>None</code> <code>secret_access_key</code> <code>str | None</code> <p>S3 credential secret access key</p> <code>None</code> <code>session_token</code> <code>str | None</code> <p>Optional S3 credential session token</p> <code>None</code> <code>expires_after</code> <code>datetime | None</code> <p>Optional expiration for the object store credentials</p> <code>None</code> <code>anonymous</code> <code>bool | None</code> <p>If set to True requests to the object store will not be signed</p> <code>None</code> <code>from_env</code> <code>bool | None</code> <p>Fetch credentials from the operative system environment</p> <code>None</code> <code>get_credentials</code> <code>Callable[[], S3StaticCredentials] | None</code> <p>Use this function to get and refresh object store credentials</p> <code>None</code> Source code in <code>icechunk/storage.py</code> <pre><code>def s3_storage(\n    *,\n    bucket: str,\n    prefix: str | None,\n    region: str | None = None,\n    endpoint_url: str | None = None,\n    allow_http: bool = False,\n    access_key_id: str | None = None,\n    secret_access_key: str | None = None,\n    session_token: str | None = None,\n    expires_after: datetime | None = None,\n    anonymous: bool | None = None,\n    from_env: bool | None = None,\n    get_credentials: Callable[[], S3StaticCredentials] | None = None,\n) -&gt; Storage:\n    \"\"\"Create a Storage instance that saves data in S3 or S3 compatible object stores.\n\n    Parameters\n    ----------\n    bucket: str\n        The bucket where the repository will store its data\n    prefix: str | None\n        The prefix within the bucket that is the root directory of the repository\n    region: str | None\n        The region to use in the object store, if `None` a default region will be used\n    endpoint_url: str | None\n        Optional endpoint where the object store serves data, example: http://localhost:9000\n    allow_http: bool\n        If the object store can be accessed using http protocol instead of https\n    access_key_id: str | None\n        S3 credential access key\n    secret_access_key: str | None\n        S3 credential secret access key\n    session_token: str | None\n        Optional S3 credential session token\n    expires_after: datetime | None\n        Optional expiration for the object store credentials\n    anonymous: bool | None\n        If set to True requests to the object store will not be signed\n    from_env: bool | None\n        Fetch credentials from the operative system environment\n    get_credentials: Callable[[], S3StaticCredentials] | None\n        Use this function to get and refresh object store credentials\n    \"\"\"\n    credentials = s3_credentials(\n        access_key_id=access_key_id,\n        secret_access_key=secret_access_key,\n        session_token=session_token,\n        expires_after=expires_after,\n        anonymous=anonymous,\n        from_env=from_env,\n        get_credentials=get_credentials,\n    )\n    options = S3Options(region=region, endpoint_url=endpoint_url, allow_http=allow_http)\n    return Storage.new_s3(\n        config=options,\n        bucket=bucket,\n        prefix=prefix,\n        credentials=credentials,\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.s3_store","title":"<code>s3_store(region=None, endpoint_url=None, allow_http=False, anonymous=False, s3_compatible=False)</code>","text":"<p>Build an ObjectStoreConfig instance for S3 or S3 compatible object stores.</p> Source code in <code>icechunk/storage.py</code> <pre><code>def s3_store(\n    region: str | None = None,\n    endpoint_url: str | None = None,\n    allow_http: bool = False,\n    anonymous: bool = False,\n    s3_compatible: bool = False,\n) -&gt; ObjectStoreConfig.S3Compatible | ObjectStoreConfig.S3:\n    \"\"\"Build an ObjectStoreConfig instance for S3 or S3 compatible object stores.\"\"\"\n    options = S3Options(region=region, endpoint_url=endpoint_url, allow_http=allow_http)\n    return (\n        ObjectStoreConfig.S3Compatible(options)\n        if s3_compatible\n        else ObjectStoreConfig.S3(options)\n    )\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.xarray.XarrayDatasetWriter","title":"<code>XarrayDatasetWriter</code>  <code>dataclass</code>","text":"<p>Write Xarray Datasets to a group in an Icechunk store.</p> <p>This class is private API. Please do not use it.</p> Source code in <code>icechunk/xarray.py</code> <pre><code>@dataclass\nclass XarrayDatasetWriter:\n    \"\"\"\n    Write Xarray Datasets to a group in an Icechunk store.\n\n    This class is private API. Please do not use it.\n    \"\"\"\n\n    dataset: Dataset = field(repr=False)\n    store: IcechunkStore = field(kw_only=True)\n\n    safe_chunks: bool = field(kw_only=True, default=True)\n    # TODO: uncomment when Zarr has support\n    # write_empty_chunks: bool = field(kw_only=True, default=True)\n\n    _initialized: bool = field(default=False, repr=False)\n\n    xarray_store: ZarrStore = field(init=False, repr=False)\n    writer: LazyArrayWriter = field(init=False, repr=False)\n\n    def __post_init__(self) -&gt; None:\n        if not isinstance(self.store, IcechunkStore):\n            raise ValueError(\n                f\"Please pass in an icechunk.Session. Received {type(self.store)!r} instead.\"\n            )\n\n    def _open_group(\n        self,\n        *,\n        group: str | None,\n        mode: ZarrWriteModes | None,\n        append_dim: Hashable | None,\n        region: Region,\n    ) -&gt; None:\n        concrete_mode: ZarrWriteModes = _choose_default_mode(\n            mode=mode, append_dim=append_dim, region=region\n        )\n\n        self.xarray_store = ZarrStore.open_group(\n            store=self.store,\n            group=group,\n            mode=concrete_mode,\n            zarr_format=3,\n            append_dim=append_dim,\n            write_region=region,\n            safe_chunks=self.safe_chunks,\n            # TODO: uncomment when Zarr has support\n            # write_empty=self.write_empty_chunks,\n            synchronizer=None,\n            consolidated=False,\n            consolidate_on_close=False,\n            zarr_version=None,\n        )\n\n    def write_metadata(self, encoding: Mapping[Any, Any] | None = None) -&gt; None:\n        \"\"\"\n        This method creates new Zarr arrays when necessary, writes attributes,\n        and any in-memory arrays.\n        \"\"\"\n        from xarray.backends.api import _validate_dataset_names, dump_to_store\n\n        # validate Dataset keys, DataArray names\n        _validate_dataset_names(self.dataset)\n\n        if encoding is None:\n            encoding = {}\n        self.xarray_store._validate_encoding(encoding)\n\n        # This writes the metadata (zarr.json) for all arrays\n        # This also will resize arrays for any appends\n        self.writer = LazyArrayWriter()\n        dump_to_store(self.dataset, self.xarray_store, self.writer, encoding=encoding)  # type: ignore[no-untyped-call]\n\n        self._initialized = True\n\n    def write_eager(self) -&gt; None:\n        \"\"\"\n        Write in-memory variables to store.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if not self._initialized:\n            raise ValueError(\"Please call `write_metadata` first.\")\n        self.writer.write_eager()\n\n    def write_lazy(\n        self,\n        chunkmanager_store_kwargs: MutableMapping[Any, Any] | None = None,\n        split_every: int | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Write lazy arrays (e.g. dask) to store.\n        \"\"\"\n        if not self._initialized:\n            raise ValueError(\"Please call `write_metadata` first.\")\n\n        if not self.writer.sources:\n            return\n\n        chunkmanager_store_kwargs = chunkmanager_store_kwargs or {}\n        chunkmanager_store_kwargs[\"load_stored\"] = False\n        chunkmanager_store_kwargs[\"return_stored\"] = True\n\n        # This calls dask.array.store, and we receive a dask array where each chunk is a Zarr array\n        # each of those zarr.Array.store contains the changesets we need\n        stored_arrays = self.writer.sync(\n            compute=False, chunkmanager_store_kwargs=chunkmanager_store_kwargs\n        )  # type: ignore[no-untyped-call]\n\n        # Now we tree-reduce all changesets\n        merged_session = stateful_store_reduce(\n            stored_arrays,\n            prefix=\"ice-changeset\",\n            chunk=extract_session,\n            aggregate=merge_sessions,\n            split_every=split_every,\n            compute=True,\n            **chunkmanager_store_kwargs,\n        )\n        self.store.session.merge(merged_session)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.xarray.XarrayDatasetWriter.write_eager","title":"<code>write_eager()</code>","text":"<p>Write in-memory variables to store.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>icechunk/xarray.py</code> <pre><code>def write_eager(self) -&gt; None:\n    \"\"\"\n    Write in-memory variables to store.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if not self._initialized:\n        raise ValueError(\"Please call `write_metadata` first.\")\n    self.writer.write_eager()\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.xarray.XarrayDatasetWriter.write_lazy","title":"<code>write_lazy(chunkmanager_store_kwargs=None, split_every=None)</code>","text":"<p>Write lazy arrays (e.g. dask) to store.</p> Source code in <code>icechunk/xarray.py</code> <pre><code>def write_lazy(\n    self,\n    chunkmanager_store_kwargs: MutableMapping[Any, Any] | None = None,\n    split_every: int | None = None,\n) -&gt; None:\n    \"\"\"\n    Write lazy arrays (e.g. dask) to store.\n    \"\"\"\n    if not self._initialized:\n        raise ValueError(\"Please call `write_metadata` first.\")\n\n    if not self.writer.sources:\n        return\n\n    chunkmanager_store_kwargs = chunkmanager_store_kwargs or {}\n    chunkmanager_store_kwargs[\"load_stored\"] = False\n    chunkmanager_store_kwargs[\"return_stored\"] = True\n\n    # This calls dask.array.store, and we receive a dask array where each chunk is a Zarr array\n    # each of those zarr.Array.store contains the changesets we need\n    stored_arrays = self.writer.sync(\n        compute=False, chunkmanager_store_kwargs=chunkmanager_store_kwargs\n    )  # type: ignore[no-untyped-call]\n\n    # Now we tree-reduce all changesets\n    merged_session = stateful_store_reduce(\n        stored_arrays,\n        prefix=\"ice-changeset\",\n        chunk=extract_session,\n        aggregate=merge_sessions,\n        split_every=split_every,\n        compute=True,\n        **chunkmanager_store_kwargs,\n    )\n    self.store.session.merge(merged_session)\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.xarray.XarrayDatasetWriter.write_metadata","title":"<code>write_metadata(encoding=None)</code>","text":"<p>This method creates new Zarr arrays when necessary, writes attributes, and any in-memory arrays.</p> Source code in <code>icechunk/xarray.py</code> <pre><code>def write_metadata(self, encoding: Mapping[Any, Any] | None = None) -&gt; None:\n    \"\"\"\n    This method creates new Zarr arrays when necessary, writes attributes,\n    and any in-memory arrays.\n    \"\"\"\n    from xarray.backends.api import _validate_dataset_names, dump_to_store\n\n    # validate Dataset keys, DataArray names\n    _validate_dataset_names(self.dataset)\n\n    if encoding is None:\n        encoding = {}\n    self.xarray_store._validate_encoding(encoding)\n\n    # This writes the metadata (zarr.json) for all arrays\n    # This also will resize arrays for any appends\n    self.writer = LazyArrayWriter()\n    dump_to_store(self.dataset, self.xarray_store, self.writer, encoding=encoding)  # type: ignore[no-untyped-call]\n\n    self._initialized = True\n</code></pre>"},{"location":"icechunk-python/reference/#icechunk.xarray.to_icechunk","title":"<code>to_icechunk(dataset, store, *, group=None, mode=None, safe_chunks=True, append_dim=None, region=None, encoding=None, chunkmanager_store_kwargs=None, split_every=None, **kwargs)</code>","text":"<p>Write an Xarray Dataset to a group of an icechunk store.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>(MutableMapping, str or path - like)</code> <p>Store or path to directory in local or remote file system.</p> required <code>mode</code> <code>\"w\", \"w-\", \"a\", \"a-\", r+\", None</code> <p>Persistence mode: \"w\" means create (overwrite if exists); \"w-\" means create (fail if exists); \"a\" means override all existing variables including dimension coordinates (create if does not exist); \"a-\" means only append those variables that have <code>append_dim</code>. \"r+\" means modify existing array values only (raise an error if any metadata or shapes would change). The default mode is \"a\" if <code>append_dim</code> is set. Otherwise, it is \"r+\" if <code>region</code> is set and <code>w-</code> otherwise.</p> <code>\"w\"</code> <code>group</code> <code>str</code> <p>Group path. (a.k.a. <code>path</code> in zarr terminology.)</p> <code>None</code> <code>encoding</code> <code>dict</code> <p>Nested dictionary with variable names as keys and dictionaries of variable specific encodings as values, e.g., <code>{\"my_variable\": {\"dtype\": \"int16\", \"scale_factor\": 0.1,}, ...}</code></p> <code>None</code> <code>append_dim</code> <code>hashable</code> <p>If set, the dimension along which the data will be appended. All other dimensions on overridden variables must remain the same size.</p> <code>None</code> <code>region</code> <code>dict or auto</code> <p>Optional mapping from dimension names to either a) <code>\"auto\"</code>, or b) integer slices, indicating the region of existing zarr array(s) in which to write this dataset's data.</p> <p>If <code>\"auto\"</code> is provided the existing store will be opened and the region inferred by matching indexes. <code>\"auto\"</code> can be used as a single string, which will automatically infer the region for all dimensions, or as dictionary values for specific dimensions mixed together with explicit slices for other dimensions.</p> <p>Alternatively integer slices can be provided; for example, <code>{'x': slice(0, 1000), 'y': slice(10000, 11000)}</code> would indicate that values should be written to the region <code>0:1000</code> along <code>x</code> and <code>10000:11000</code> along <code>y</code>.</p> <p>Users are expected to ensure that the specified region aligns with Zarr chunk boundaries, and that dask chunks are also aligned. Xarray makes limited checks that these multiple chunk boundaries line up. It is possible to write incomplete chunks and corrupt the data with this option if you are not careful.</p> <code>None</code> <code>safe_chunks</code> <code>bool</code> <p>If True, only allow writes to when there is a many-to-one relationship between Zarr chunks (specified in encoding) and Dask chunks. Set False to override this restriction; however, data may become corrupted if Zarr arrays are written in parallel. In addition to the many-to-one relationship validation, it also detects partial chunks writes when using the region parameter, these partial chunks are considered unsafe in the mode \"r+\" but safe in the mode \"a\". Note: Even with these validations it can still be unsafe to write two or more chunked arrays in the same location in parallel if they are not writing in independent regions.</p> <code>True</code> <code>chunkmanager_store_kwargs</code> <code>dict</code> <p>Additional keyword arguments passed on to the <code>ChunkManager.store</code> method used to store chunked arrays. For example for a dask array additional kwargs will be passed eventually to <code>dask.array.store()</code>. Experimental API that should not be relied upon.</p> <code>None</code> <code>split_every</code> <code>int | None</code> <p>Number of tasks to merge at every level of the tree reduction.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> Notes <p>Two restrictions apply to the use of <code>region</code>:</p> <ul> <li>If <code>region</code> is set, all variables in a dataset must have at     least one dimension in common with the region. Other variables     should be written in a separate single call to <code>to_zarr()</code>.</li> <li>Dimensions cannot be included in both <code>region</code> and     <code>append_dim</code> at the same time. To create empty arrays to fill     in with <code>region</code>, use the <code>XarrayDatasetWriter</code> directly.</li> </ul> Source code in <code>icechunk/xarray.py</code> <pre><code>def to_icechunk(\n    dataset: Dataset,\n    store: IcechunkStore,\n    *,\n    group: str | None = None,\n    mode: ZarrWriteModes | None = None,\n    # TODO: uncomment when Zarr has support\n    # write_empty_chunks: bool | None = None,\n    safe_chunks: bool = True,\n    append_dim: Hashable | None = None,\n    region: Region = None,\n    encoding: Mapping[Any, Any] | None = None,\n    chunkmanager_store_kwargs: MutableMapping[Any, Any] | None = None,\n    split_every: int | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"\n    Write an Xarray Dataset to a group of an icechunk store.\n\n    Parameters\n    ----------\n    store : MutableMapping, str or path-like, optional\n        Store or path to directory in local or remote file system.\n    mode : {\"w\", \"w-\", \"a\", \"a-\", r+\", None}, optional\n        Persistence mode: \"w\" means create (overwrite if exists);\n        \"w-\" means create (fail if exists);\n        \"a\" means override all existing variables including dimension coordinates (create if does not exist);\n        \"a-\" means only append those variables that have ``append_dim``.\n        \"r+\" means modify existing array *values* only (raise an error if\n        any metadata or shapes would change).\n        The default mode is \"a\" if ``append_dim`` is set. Otherwise, it is\n        \"r+\" if ``region`` is set and ``w-`` otherwise.\n    group : str, optional\n        Group path. (a.k.a. `path` in zarr terminology.)\n    encoding : dict, optional\n        Nested dictionary with variable names as keys and dictionaries of\n        variable specific encodings as values, e.g.,\n        ``{\"my_variable\": {\"dtype\": \"int16\", \"scale_factor\": 0.1,}, ...}``\n    append_dim : hashable, optional\n        If set, the dimension along which the data will be appended. All\n        other dimensions on overridden variables must remain the same size.\n    region : dict or \"auto\", optional\n        Optional mapping from dimension names to either a) ``\"auto\"``, or b) integer\n        slices, indicating the region of existing zarr array(s) in which to write\n        this dataset's data.\n\n        If ``\"auto\"`` is provided the existing store will be opened and the region\n        inferred by matching indexes. ``\"auto\"`` can be used as a single string,\n        which will automatically infer the region for all dimensions, or as\n        dictionary values for specific dimensions mixed together with explicit\n        slices for other dimensions.\n\n        Alternatively integer slices can be provided; for example, ``{'x': slice(0,\n        1000), 'y': slice(10000, 11000)}`` would indicate that values should be\n        written to the region ``0:1000`` along ``x`` and ``10000:11000`` along\n        ``y``.\n\n        Users are expected to ensure that the specified region aligns with\n        Zarr chunk boundaries, and that dask chunks are also aligned.\n        Xarray makes limited checks that these multiple chunk boundaries line up.\n        It is possible to write incomplete chunks and corrupt the data with this\n        option if you are not careful.\n    safe_chunks : bool, default: True\n        If True, only allow writes to when there is a many-to-one relationship\n        between Zarr chunks (specified in encoding) and Dask chunks.\n        Set False to override this restriction; however, data may become corrupted\n        if Zarr arrays are written in parallel.\n        In addition to the many-to-one relationship validation, it also detects partial\n        chunks writes when using the region parameter,\n        these partial chunks are considered unsafe in the mode \"r+\" but safe in\n        the mode \"a\".\n        Note: Even with these validations it can still be unsafe to write\n        two or more chunked arrays in the same location in parallel if they are\n        not writing in independent regions.\n    chunkmanager_store_kwargs : dict, optional\n        Additional keyword arguments passed on to the `ChunkManager.store` method used to store\n        chunked arrays. For example for a dask array additional kwargs will be passed eventually to\n        `dask.array.store()`. Experimental API that should not be relied upon.\n    split_every: int, optional\n        Number of tasks to merge at every level of the tree reduction.\n\n    Returns\n    -------\n    None\n\n    Notes\n    -----\n    Two restrictions apply to the use of ``region``:\n\n      - If ``region`` is set, _all_ variables in a dataset must have at\n        least one dimension in common with the region. Other variables\n        should be written in a separate single call to ``to_zarr()``.\n      - Dimensions cannot be included in both ``region`` and\n        ``append_dim`` at the same time. To create empty arrays to fill\n        in with ``region``, use the `XarrayDatasetWriter` directly.\n    \"\"\"\n    writer = XarrayDatasetWriter(dataset, store=store)\n\n    writer._open_group(group=group, mode=mode, append_dim=append_dim, region=region)\n\n    # write metadata\n    writer.write_metadata(encoding)\n    # write in-memory arrays\n    writer.write_eager()\n    # eagerly write dask arrays\n    writer.write_lazy(chunkmanager_store_kwargs=chunkmanager_store_kwargs)\n</code></pre>"},{"location":"icechunk-python/version-control/","title":"Version control","text":"<p>Home / icechunk-python / version-control</p>"},{"location":"icechunk-python/version-control/#version-control","title":"Version Control","text":"<p>COMING SOON!</p> <p>In the meantime, you can read about version control in Arraylake, which is very similar to version control in Icechunk.</p>"},{"location":"icechunk-python/virtual/","title":"Virtual Datasets","text":"<p>Home / icechunk-python / virtual</p>"},{"location":"icechunk-python/virtual/#virtual-datasets","title":"Virtual Datasets","text":"<p>While Icechunk works wonderfully with native chunks managed by Zarr, there is lots of archival data out there in other formats already. To interoperate with such data, Icechunk supports \"Virtual\" chunks, where any number of chunks in a given dataset may reference external data in existing archival formats, such as netCDF, HDF, GRIB, or TIFF. Virtual chunks are loaded directly from the original source without copying or modifying the original achival data files. This enables Icechunk to manage large datasets from existing data without needing that data to be in Zarr format already.</p> <p>Warning</p> <p>While virtual references are fully supported in Icechunk, creating virtual datasets currently relies on using experimental or pre-release versions of open source tools. For full instructions on how to install the required tools and their current statuses see the tracking issue on Github. With time, these experimental features will make their way into the released packages.</p> <p>To create virtual Icechunk datasets with Python, the community utilizes the kerchunk and VirtualiZarr packages.</p> <p><code>kerchunk</code> allows scanning the metadata of existing data files to extract virtual references. It also provides methods to combine these references into larger virtual datasets, which can be exported to it's reference format.</p> <p><code>VirtualiZarr</code> lets users ingest existing data files into virtual datasets using various different tools under the hood, including <code>kerchunk</code>, <code>xarray</code>, <code>zarr</code>, and now <code>icechunk</code>. It does so by creating virtual references to existing data that can be combined and manipulated to create larger virtual datasets using <code>xarray</code>. These datasets can then be exported to <code>kerchunk</code> reference format or to an <code>Icechunk</code> store, without ever copying or moving the existing data files.</p>"},{"location":"icechunk-python/virtual/#creating-a-virtual-dataset-with-virtualizarr","title":"Creating a virtual dataset with VirtualiZarr","text":"<p>We are going to create a virtual dataset pointing to all of the OISST data for August 2024. This data is distributed publicly as netCDF files on AWS S3, with one netCDF file containing the Sea Surface Temperature (SST) data for each day of the month. We are going to use <code>VirtualiZarr</code> to combine all of these files into a single virtual dataset spanning the entire month, then write that dataset to Icechunk for use in analysis.</p> <p>Note</p> <p>At this point you should have followed the instructions here to install the necessary experimental dependencies.</p> <p>Before we get started, we also need to install <code>fsspec</code> and <code>s3fs</code> for working with data on s3.</p> <pre><code>pip install fsspec s3fs\n</code></pre> <p>First, we need to find all of the files we are interested in, we will do this with fsspec using a <code>glob</code> expression to find every netcdf file in the August 2024 folder in the bucket:</p> <pre><code>import fsspec\n\nfs = fsspec.filesystem('s3')\n\noisst_files = fs.glob('s3://noaa-cdr-sea-surface-temp-optimum-interpolation-pds/data/v2.1/avhrr/202408/oisst-avhrr-v02r01.*.nc')\n\noisst_files = sorted(['s3://'+f for f in oisst_files])\n#['s3://noaa-cdr-sea-surface-temp-optimum-interpolation-pds/data/v2.1/avhrr/201001/oisst-avhrr-v02r01.20100101.nc',\n# 's3://noaa-cdr-sea-surface-temp-optimum-interpolation-pds/data/v2.1/avhrr/201001/oisst-avhrr-v02r01.20100102.nc',\n# 's3://noaa-cdr-sea-surface-temp-optimum-interpolation-pds/data/v2.1/avhrr/201001/oisst-avhrr-v02r01.20100103.nc',\n# 's3://noaa-cdr-sea-surface-temp-optimum-interpolation-pds/data/v2.1/avhrr/201001/oisst-avhrr-v02r01.20100104.nc',\n#...\n#]\n</code></pre> <p>Now that we have the filenames of the data we need, we can create virtual datasets with <code>VirtualiZarr</code>. This may take a minute.</p> <pre><code>from virtualizarr import open_virtual_dataset\n\nvirtual_datasets =[\n    open_virtual_dataset(url, indexes={})\n    for url in oisst_files\n]\n</code></pre> <p>We can now use <code>xarray</code> to combine these virtual datasets into one large virtual dataset (For more details on this operation see <code>VirtualiZarr</code>'s documentation). We know that each of our files share the same structure but with a different date. So we are going to concatenate these datasets on the <code>time</code> dimension.</p> <pre><code>import xarray as xr\n\nvirtual_ds = xr.concat(\n    virtual_datasets,\n    dim='time',\n    coords='minimal',\n    compat='override',\n    combine_attrs='override'\n)\n\n#&lt;xarray.Dataset&gt; Size: 257MB\n#Dimensions:  (time: 31, zlev: 1, lat: 720, lon: 1440)\n#Coordinates:\n#    time     (time) float32 124B ManifestArray&lt;shape=(31,), dtype=float32, ch...\n#    lat      (lat) float32 3kB ManifestArray&lt;shape=(720,), dtype=float32, chu...\n#    zlev     (zlev) float32 4B ManifestArray&lt;shape=(1,), dtype=float32, chunk...\n#    lon      (lon) float32 6kB ManifestArray&lt;shape=(1440,), dtype=float32, ch...\n#Data variables:\n#    sst      (time, zlev, lat, lon) int16 64MB ManifestArray&lt;shape=(31, 1, 72...\n#    anom     (time, zlev, lat, lon) int16 64MB ManifestArray&lt;shape=(31, 1, 72...\n#    ice      (time, zlev, lat, lon) int16 64MB ManifestArray&lt;shape=(31, 1, 72...\n#    err      (time, zlev, lat, lon) int16 64MB ManifestArray&lt;shape=(31, 1, 72...\n</code></pre> <p>We have a virtual dataset with 31 timestamps! One hint that this worked correctly is that the readout shows the variables and coordinates as <code>ManifestArray</code> instances, the representation that <code>VirtualiZarr</code> uses for virtual arrays. Let's create an Icechunk repo to write this dataset to.</p> <p>Note</p> <p>You will need to modify the <code>StorageConfig</code> bucket name and method to a bucket you have access to. There are multiple options for configuring S3 access: <code>s3_from_config</code>, <code>s3_from_env</code> and <code>s3_anonymous</code>. For more configuration options, see the configuration page.</p> <p>Note</p> <p>Take note of the <code>virtual_ref_config</code> passed into the <code>RepositoryConfig</code> when creating the store. This allows the icechunk store to have the necessary credentials to access the referenced netCDF data on s3 at read time. For more configuration options, see the configuration page.</p> <pre><code>from icechunk import Repository, StorageConfig, RepositoryConfig, VirtualRefConfig\n\nstorage = StorageConfig.s3_from_config(\n    bucket='YOUR_BUCKET_HERE',\n    prefix='icechunk/oisst',\n    region='us-east-1',\n    credentials=S3Credentials(\n        access_key_id=\"REPLACE_ME\",\n        secret_access_key=\"REPLACE_ME\",\n        session_token=\"REPLACE_ME\"\n    )\n)\n\nrepo = Repository.create(\n    storage=storage,\n    config=RepositoryConfig(\n        virtual_ref_config=VirtualRefConfig.s3_anonymous(region='us-east-1'),\n    )\n)\n</code></pre> <p>With the repo created, lets write our virtual dataset to Icechunk with VirtualiZarr!</p> <pre><code>session = repo.writable_session(\"main\")\nvirtual_ds.virtualize.to_icechunk(session.store())\n</code></pre> <p>The refs are written so lets save our progress by committing to the store.</p> <p>Note</p> <p>Your commit hash will be different! For more on the version control features of Icechunk, see the version control page.</p> <pre><code>session.commit(\"My first virtual store!\")\n\n# 'THAJHTYQABGD2B10D5C0'\n</code></pre> <p>Now we can read the dataset from the store using xarray to confirm everything went as expected. <code>xarray</code> reads directly from the Icechunk store because it is a fully compliant <code>zarr Store</code> instance.</p> <pre><code>ds = xr.open_zarr(\n    store,\n    zarr_version=3,\n    consolidated=False,\n    chunks={},\n)\n\n#&lt;xarray.Dataset&gt; Size: 1GB\n#Dimensions:  (lon: 1440, time: 31, zlev: 1, lat: 720)\n#Coordinates:\n#  * lon      (lon) float32 6kB 0.125 0.375 0.625 0.875 ... 359.4 359.6 359.9\n#  * zlev     (zlev) float32 4B 0.0\n#  * time     (time) datetime64[ns] 248B 2024-08-01T12:00:00 ... 2024-08-31T12...\n#  * lat      (lat) float32 3kB -89.88 -89.62 -89.38 -89.12 ... 89.38 89.62 89.88\n#Data variables:\n#    sst      (time, zlev, lat, lon) float64 257MB dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n#    ice      (time, zlev, lat, lon) float64 257MB dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n#    anom     (time, zlev, lat, lon) float64 257MB dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n#    err      (time, zlev, lat, lon) float64 257MB dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n</code></pre> <p>Success! We have created our full dataset with 31 timesteps spanning the month of august, all with virtual references to pre-existing data files in object store. This means we can now version control our dataset, allowing us to update it, and roll it back to a previous version without copying or moving any data from the original files.</p> <p>Finally, let's make a plot of the sea surface temperature!</p> <pre><code>ds.sst.isel(time=26, zlev=0).plot(x='lon', y='lat', vmin=0)\n</code></pre> <p></p>"},{"location":"icechunk-python/virtual/#virtual-reference-api","title":"Virtual Reference API","text":"<p>While <code>VirtualiZarr</code> is the easiest way to create virtual datasets with Icechunk, the Store API that it uses to create the datasets in Icechunk is public. <code>IcechunkStore</code> contains a <code>set_virtual_ref</code> method that specifies a virtual ref for a specified chunk.</p>"},{"location":"icechunk-python/virtual/#virtual-reference-storage-support","title":"Virtual Reference Storage Support","text":"<p>Currently, Icechunk supports two types of storage for virtual references:</p>"},{"location":"icechunk-python/virtual/#s3-compatible","title":"S3 Compatible","text":"<p>References to files accessible via S3 compatible storage.</p>"},{"location":"icechunk-python/virtual/#example","title":"Example","text":"<p>Here is how we can set the chunk at key <code>c/0</code> to point to a file on an s3 bucket,<code>mybucket</code>, with the prefix <code>my/data/file.nc</code>:</p> <pre><code>store.set_virtual_ref('c/0', 's3://mybucket/my/data/file.nc', offset=1000, length=200)\n</code></pre>"},{"location":"icechunk-python/virtual/#configuration","title":"Configuration","text":"<p>S3 virtual references require configuring credential for the store to be able to access the specified s3 bucket. See the configuration docs for instructions.</p>"},{"location":"icechunk-python/virtual/#local-filesystem","title":"Local Filesystem","text":"<p>References to files accessible via local filesystem. This requires any file paths to be absolute at this time.</p>"},{"location":"icechunk-python/virtual/#example_1","title":"Example","text":"<p>Here is how we can set the chunk at key <code>c/0</code> to point to a file on my local filesystem located at <code>/path/to/my/file.nc</code>:</p> <pre><code>store.set_virtual_ref('c/0', 'file:///path/to/my/file.nc', offset=20, length=100)\n</code></pre> <p>No extra configuration is necessary for local filesystem references.</p>"},{"location":"icechunk-python/virtual/#virtual-reference-file-format-support","title":"Virtual Reference File Format Support","text":"<p>Currently, Icechunk supports <code>HDF5</code> and <code>netcdf4</code> files for use in virtual references. See the tracking issue for more info.</p>"},{"location":"icechunk-python/xarray/","title":"Xarray","text":"<p>Home / icechunk-python / xarray</p>"},{"location":"icechunk-python/xarray/#icechunk-xarray","title":"Icechunk + Xarray","text":"<p>Icechunk was designed to work seamlessly with Xarray. Xarray users can read and write data to Icechunk using <code>xarray.open_zarr</code> and <code>xarray.Dataset.to_zarr</code>.</p> <p>Warning</p> <p>Using Xarray and Icechunk together currently requires installing Xarray &gt;= 2024.11.0.</p> <pre><code>pip install \"xarray&gt;=2024.11.0\"\n</code></pre> <p>In this example, we'll explain how to create a new Icechunk repo, write some sample data to it, and append data a second block of data using Icechunk's version control features.</p>"},{"location":"icechunk-python/xarray/#create-a-new-repo","title":"Create a new repo","text":"<p>Similar to the example in quickstart, we'll create an Icechunk repo in S3 or a local file system. You will need to replace the <code>StorageConfig</code> with a bucket or file path that you have access to.</p> <pre><code>import xarray as xr\nfrom icechunk import Repository, StorageConfig\n</code></pre> S3 StorageLocal Storage <pre><code>storage_config = StorageConfig.s3_from_env(\n    bucket=\"icechunk-test\",\n    prefix=\"xarray-demo\"\n)\nrepo = Repository.create(storage_config)\n</code></pre> <pre><code>storage_config = StorageConfig.filesystem(\"./icechunk-xarray\")\nrepo = Repository.create(storage_config)\n</code></pre>"},{"location":"icechunk-python/xarray/#open-tutorial-dataset-from-xarray","title":"Open tutorial dataset from Xarray","text":"<p>For this demo, we'll open Xarray's RASM tutorial dataset and split it into two blocks. We'll write the two blocks to Icechunk in separate transactions later in the this example.</p> <p>Note</p> <p>Downloading xarray tutorial data requires pooch and netCDF4. These can be installed with</p> <pre><code>pip install pooch netCDF4\n</code></pre> <pre><code>ds = xr.tutorial.open_dataset('rasm')\n\nds1 = ds.isel(time=slice(None, 18))  # part 1\nds2 = ds.isel(time=slice(18, None))  # part 2\n</code></pre>"},{"location":"icechunk-python/xarray/#write-xarray-data-to-icechunk","title":"Write Xarray data to Icechunk","text":"<p>Create a new writable session on the <code>main</code> branch to get the <code>IcechunkStore</code>:</p> <pre><code>session = repo.writable_session(\"main\")\nstore = session.store()\n</code></pre> <p>Writing Xarray data to Icechunk is as easy as calling <code>Dataset.to_zarr</code>:</p> <pre><code>ds1.to_zarr(store, zarr_format=3, consolidated=False)\n</code></pre> <p>Note</p> <ol> <li>Consolidated metadata is unnecessary (and unsupported) in Icechunk. Icechunk already organizes the dataset metadata in a way that makes it very fast to fetch from storage.</li> <li><code>zarr_format=3</code> is required until the default Zarr format changes in Xarray.</li> </ol> <p>After writing, we commit the changes using the session:</p> <pre><code>session.commit(\"add RASM data to store\")\n# output: 'ME4VKFPA5QAY0B2YSG8G'\n</code></pre>"},{"location":"icechunk-python/xarray/#append-to-an-existing-store","title":"Append to an existing store","text":"<p>Next, we want to add a second block of data to our store. Above, we created <code>ds2</code> for just this reason. Again, we'll use <code>Dataset.to_zarr</code>, this time with <code>append_dim='time'</code>.</p> <pre><code># we have to get a new session after committing\nsession = repo.writable_session(\"main\")\nds2.to_zarr(session.store(), append_dim='time')\n</code></pre> <p>And then we'll commit the changes:</p> <pre><code>session.commit(\"append more data\")\n# output: 'WW4V8V34QCZ2NXTD5DXG'\n</code></pre>"},{"location":"icechunk-python/xarray/#reading-data-with-xarray","title":"Reading data with Xarray","text":"<p>To read data stored in Icechunk with Xarray, we'll use <code>xarray.open_zarr</code>:</p> <pre><code>xr.open_zarr(store, consolidated=False)\n# output: &lt;xarray.Dataset&gt; Size: 17MB\n# Dimensions:  (time: 36, y: 205, x: 275)\n# Coordinates:\n#   * time     (time) object 288B 1980-09-16 12:00:00 ... 1983-08-17 00:00:00\n#     xc       (y, x) float64 451kB dask.array&lt;chunksize=(103, 275), meta=np.ndarray&gt;\n#     yc       (y, x) float64 451kB dask.array&lt;chunksize=(103, 275), meta=np.ndarray&gt;\n# Dimensions without coordinates: y, x\n# Data variables:\n#     Tair     (time, y, x) float64 16MB dask.array&lt;chunksize=(5, 103, 138), meta=np.ndarray&gt;\n# Attributes:\n#     NCO:                       netCDF Operators version 4.7.9 (Homepage = htt...\n#     comment:                   Output from the Variable Infiltration Capacity...\n#     convention:                CF-1.4\n#     history:                   Fri Aug  7 17:57:38 2020: ncatted -a bounds,,d...\n#     institution:               U.W.\n#     nco_openmp_thread_number:  1\n#     output_frequency:          daily\n#     output_mode:               averaged\n#     references:                Based on the initial model of Liang et al., 19...\n#     source:                    RACM R1002RBRxaaa01a\n#     title:                     /workspace/jhamman/processed/R1002RBRxaaa01a/l...\n</code></pre> <p>We can also read data from previous snapshots by checking out prior versions:</p> <pre><code>store = repo.readable_session(snapshot_id='ME4VKFPA5QAY0B2YSG8G').store()\n\nxr.open_zarr(store, consolidated=False)\n# &lt;xarray.Dataset&gt; Size: 9MB\n# Dimensions:  (time: 18, y: 205, x: 275)\n# Coordinates:\n#     xc       (y, x) float64 451kB dask.array&lt;chunksize=(103, 275), meta=np.ndarray&gt;\n#     yc       (y, x) float64 451kB dask.array&lt;chunksize=(103, 275), meta=np.ndarray&gt;\n#   * time     (time) object 144B 1980-09-16 12:00:00 ... 1982-02-15 12:00:00\n# Dimensions without coordinates: y, x\n# Data variables:\n#     Tair     (time, y, x) float64 8MB dask.array&lt;chunksize=(5, 103, 138), meta=np.ndarray&gt;\n# Attributes:\n#     NCO:                       netCDF Operators version 4.7.9 (Homepage = htt...\n#     comment:                   Output from the Variable Infiltration Capacity...\n#     convention:                CF-1.4\n#     history:                   Fri Aug  7 17:57:38 2020: ncatted -a bounds,,d...\n#     institution:               U.W.\n#     nco_openmp_thread_number:  1\n#     output_frequency:          daily\n#     output_mode:               averaged\n#     references:                Based on the initial model of Liang et al., 19...\n#     source:                    RACM R1002RBRxaaa01a\n#     title:                     /workspace/jhamman/processed/R1002RBRxaaa01a/l...\n</code></pre> <p>Notice that this second <code>xarray.Dataset</code> has a time dimension of length 18 whereas the first has a time dimension of length 36.</p>"},{"location":"icechunk-python/xarray/#next-steps","title":"Next steps","text":"<p>For more details on how to use Xarray's Zarr integration, checkout Xarray's documentation.</p>"},{"location":"icechunk-python/examples/dask_write/","title":"Dask write","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nThis example uses Dask as a task orchestration framework\nto write or update an array in an Icechunk repository.\nTo write an Xarray object with dask array use `icechunk.xarray.to_icechunk`\n\nTo understand all the available options run:\n```\npython ./examples/dask_write.py --help\npython ./examples/dask_write.py create --help\npython ./examples/dask_write.py update --help\npython ./examples/dask_write.py verify --help\n```\n\nExample usage:\n\n```\npython ./examples/dask_write.py create --url s3://my-bucket/my-icechunk-repo --t-chunks 100000 --x-chunks 4 --y-chunks 4 --chunk-x-size 112 --chunk-y-size 112\npython ./examples/dask_write.py update --url s3://my-bucket/my-icechunk-repo --t-from 0 --t-to 1500 --workers 16\npython ./examples/dask_write.py verify --url s3://my-bucket/my-icechunk-repo --t-from 0 --t-to 1500 --workers 16\n```\n\nThe work is split into three different commands.\n* `create` initializes the repository and the array, without writing any chunks. For this example\n   we chose a 3D array that simulates a dataset that needs backfilling across its time dimension.\n* `update` can be called multiple times to write a number of \"pancakes\" to the array.\n  It does so by distributing the work among Dask workers, in small tasks, one pancake per task.\n  The example invocation above, will write 1,500 pancakes using 16 Dask workers.\n* `verify` can read a part of the array and check that it contains the required data.\n\nIcechunk can do distributed writes to object store, but currently, it cannot use the Dask array API\n(we are working on it, see https://github.com/earth-mover/icechunk/issues/185).\nDask can still be used to read and write to Icechunk from multiple processes and machines, we just need to use a lower level\nDask API based, for example, in `map/gather`. This mechanism is what we show in this example.\n\"\"\"\n</pre> \"\"\" This example uses Dask as a task orchestration framework to write or update an array in an Icechunk repository. To write an Xarray object with dask array use `icechunk.xarray.to_icechunk`  To understand all the available options run: ``` python ./examples/dask_write.py --help python ./examples/dask_write.py create --help python ./examples/dask_write.py update --help python ./examples/dask_write.py verify --help ```  Example usage:  ``` python ./examples/dask_write.py create --url s3://my-bucket/my-icechunk-repo --t-chunks 100000 --x-chunks 4 --y-chunks 4 --chunk-x-size 112 --chunk-y-size 112 python ./examples/dask_write.py update --url s3://my-bucket/my-icechunk-repo --t-from 0 --t-to 1500 --workers 16 python ./examples/dask_write.py verify --url s3://my-bucket/my-icechunk-repo --t-from 0 --t-to 1500 --workers 16 ```  The work is split into three different commands. * `create` initializes the repository and the array, without writing any chunks. For this example    we chose a 3D array that simulates a dataset that needs backfilling across its time dimension. * `update` can be called multiple times to write a number of \"pancakes\" to the array.   It does so by distributing the work among Dask workers, in small tasks, one pancake per task.   The example invocation above, will write 1,500 pancakes using 16 Dask workers. * `verify` can read a part of the array and check that it contains the required data.  Icechunk can do distributed writes to object store, but currently, it cannot use the Dask array API (we are working on it, see https://github.com/earth-mover/icechunk/issues/185). Dask can still be used to read and write to Icechunk from multiple processes and machines, we just need to use a lower level Dask API based, for example, in `map/gather`. This mechanism is what we show in this example. \"\"\" In\u00a0[\u00a0]: Copied! <pre>import argparse\nfrom dataclasses import dataclass\nfrom typing import Any, cast\nfrom urllib.parse import urlparse\n</pre> import argparse from dataclasses import dataclass from typing import Any, cast from urllib.parse import urlparse In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n</pre> import numpy as np In\u00a0[\u00a0]: Copied! <pre>import icechunk\nimport zarr\nfrom dask.distributed import Client\nfrom dask.distributed import print as dprint\n</pre> import icechunk import zarr from dask.distributed import Client from dask.distributed import print as dprint In\u00a0[\u00a0]: Copied! <pre>@dataclass\nclass Task:\n    \"\"\"A task distributed to Dask workers\"\"\"\n\n    session: (\n        icechunk.Session\n    )  # The worker will use this Icechunk session to read/write to the dataset\n    time: (\n        int  # The position in the coordinate dimension where the read/write should happen\n    )\n    seed: int  # An RNG seed used to generate or recreate random data for the array\n</pre> @dataclass class Task:     \"\"\"A task distributed to Dask workers\"\"\"      session: (         icechunk.Session     )  # The worker will use this Icechunk session to read/write to the dataset     time: (         int  # The position in the coordinate dimension where the read/write should happen     )     seed: int  # An RNG seed used to generate or recreate random data for the array In\u00a0[\u00a0]: Copied! <pre>def generate_task_array(task: Task, shape: tuple[int, ...]) -&gt; np.typing.ArrayLike:\n    \"\"\"Generates a randm array with the given shape and using the seed in the Task\"\"\"\n    np.random.seed(task.seed)\n    return np.random.rand(*shape)\n</pre> def generate_task_array(task: Task, shape: tuple[int, ...]) -&gt; np.typing.ArrayLike:     \"\"\"Generates a randm array with the given shape and using the seed in the Task\"\"\"     np.random.seed(task.seed)     return np.random.rand(*shape) In\u00a0[\u00a0]: Copied! <pre>def execute_write_task(task: Task) -&gt; icechunk.Session:\n    \"\"\"Execute task as a write task.\n\n    This will read the time coordinade from `task` and write a \"pancake\" in that position,\n    using random data. Random data is generated using the task seed.\n\n    Returns the Icechunk session after the write is done.\n\n    As you can see Icechunk session can be passed to remote workers, and returned from them.\n    The reason to return the session is that we'll need all the remote session, when they are\n    done, to be able to do a single, global commit to Icechunk.\n    \"\"\"\n\n    session = task.session\n    store = session.store\n\n    group = zarr.group(store=store, overwrite=False)\n    array = cast(zarr.Array, group[\"array\"])\n    dprint(f\"Writing at t={task.time}\")\n    data = generate_task_array(task, array.shape[0:2])\n    array[:, :, task.time] = data\n    dprint(f\"Writing at t={task.time} done\")\n    return session\n</pre> def execute_write_task(task: Task) -&gt; icechunk.Session:     \"\"\"Execute task as a write task.      This will read the time coordinade from `task` and write a \"pancake\" in that position,     using random data. Random data is generated using the task seed.      Returns the Icechunk session after the write is done.      As you can see Icechunk session can be passed to remote workers, and returned from them.     The reason to return the session is that we'll need all the remote session, when they are     done, to be able to do a single, global commit to Icechunk.     \"\"\"      session = task.session     store = session.store      group = zarr.group(store=store, overwrite=False)     array = cast(zarr.Array, group[\"array\"])     dprint(f\"Writing at t={task.time}\")     data = generate_task_array(task, array.shape[0:2])     array[:, :, task.time] = data     dprint(f\"Writing at t={task.time} done\")     return session In\u00a0[\u00a0]: Copied! <pre>def execute_read_task(task: Task) -&gt; None:\n    \"\"\"Execute task as a read task.\n\n    This will read the time coordinade from `task` and read a \"pancake\" in that position.\n    Then it will assert the data is valid by re-generating the random data from the passed seed.\n\n    As you can see Icechunk sessions can be passed to remote workers.\n    \"\"\"\n\n    session = task.session\n    store = session.store\n    group = zarr.group(store=store, overwrite=False)\n    array = cast(zarr.Array, group[\"array\"])\n\n    actual = array[:, :, task.time]\n    expected = generate_task_array(task, array.shape[0:2])\n    np.testing.assert_array_equal(actual, expected)\n    dprint(f\"t={task.time} verified\")\n</pre> def execute_read_task(task: Task) -&gt; None:     \"\"\"Execute task as a read task.      This will read the time coordinade from `task` and read a \"pancake\" in that position.     Then it will assert the data is valid by re-generating the random data from the passed seed.      As you can see Icechunk sessions can be passed to remote workers.     \"\"\"      session = task.session     store = session.store     group = zarr.group(store=store, overwrite=False)     array = cast(zarr.Array, group[\"array\"])      actual = array[:, :, task.time]     expected = generate_task_array(task, array.shape[0:2])     np.testing.assert_array_equal(actual, expected)     dprint(f\"t={task.time} verified\") In\u00a0[\u00a0]: Copied! <pre>def storage_config(args: argparse.Namespace) -&gt; dict[str, Any]:\n    \"\"\"Return the Icechunk S3 configuration map\"\"\"\n    bucket = args.url.netloc\n    prefix = args.url.path[1:]\n    return {\n        \"bucket\": bucket,\n        \"prefix\": prefix,\n        \"region\": \"us-east-1\",\n    }\n</pre> def storage_config(args: argparse.Namespace) -&gt; dict[str, Any]:     \"\"\"Return the Icechunk S3 configuration map\"\"\"     bucket = args.url.netloc     prefix = args.url.path[1:]     return {         \"bucket\": bucket,         \"prefix\": prefix,         \"region\": \"us-east-1\",     } In\u00a0[\u00a0]: Copied! <pre>def repository_config(args: argparse.Namespace) -&gt; icechunk.RepositoryConfig:\n    \"\"\"Return the Icechunk repo configuration.\n\n    We lower the default to make sure we write chunks and not inline them.\n    \"\"\"\n    config = icechunk.RepositoryConfig.default()\n    config.inline_chunk_threshold_bytes = 1\n    return config\n</pre> def repository_config(args: argparse.Namespace) -&gt; icechunk.RepositoryConfig:     \"\"\"Return the Icechunk repo configuration.      We lower the default to make sure we write chunks and not inline them.     \"\"\"     config = icechunk.RepositoryConfig.default()     config.inline_chunk_threshold_bytes = 1     return config In\u00a0[\u00a0]: Copied! <pre>def create(args: argparse.Namespace) -&gt; None:\n    \"\"\"Execute the create subcommand.\n\n    Creates an Icechunk repo, a root group and an array named \"array\"\n    with the shape passed as arguments.\n\n    Commits the Icechunk repository when done.\n    \"\"\"\n    repo = icechunk.Repository.create(\n        storage=icechunk.s3_storage(**storage_config(args)),\n        config=repository_config(args),\n    )\n\n    session = repo.writable_session(\"main\")\n    store = session.store\n\n    group = zarr.group(store=store, overwrite=True)\n    shape = (\n        args.x_chunks * args.chunk_x_size,\n        args.y_chunks * args.chunk_y_size,\n        args.t_chunks * 1,\n    )\n    chunk_shape = (args.chunk_x_size, args.chunk_y_size, 1)\n\n    group.create_array(\n        \"array\",\n        shape=shape,\n        chunk_shape=chunk_shape,\n        dtype=\"f8\",\n        fill_value=float(\"nan\"),\n    )\n    first_snapshot = session.commit(\"array created\")\n    print(f\"Array initialized, snapshot {first_snapshot}\")\n</pre> def create(args: argparse.Namespace) -&gt; None:     \"\"\"Execute the create subcommand.      Creates an Icechunk repo, a root group and an array named \"array\"     with the shape passed as arguments.      Commits the Icechunk repository when done.     \"\"\"     repo = icechunk.Repository.create(         storage=icechunk.s3_storage(**storage_config(args)),         config=repository_config(args),     )      session = repo.writable_session(\"main\")     store = session.store      group = zarr.group(store=store, overwrite=True)     shape = (         args.x_chunks * args.chunk_x_size,         args.y_chunks * args.chunk_y_size,         args.t_chunks * 1,     )     chunk_shape = (args.chunk_x_size, args.chunk_y_size, 1)      group.create_array(         \"array\",         shape=shape,         chunk_shape=chunk_shape,         dtype=\"f8\",         fill_value=float(\"nan\"),     )     first_snapshot = session.commit(\"array created\")     print(f\"Array initialized, snapshot {first_snapshot}\") In\u00a0[\u00a0]: Copied! <pre>def update(args: argparse.Namespace) -&gt; None:\n    \"\"\"Execute the update subcommand.\n\n    Uses Dask to write chunks to the Icechunk repository. Currently Icechunk cannot\n    use the Dask array API (see https://github.com/earth-mover/icechunk/issues/185) but we\n    can still use a lower level API to do the writes:\n    * We split the work into small `Task`s, one 'pancake' per task, at a given t coordinate.\n    * We use Dask's `map` to ship the `Task` to a worker\n    * The `Task` includes a copy of the Icechunk Session, so workers can do the writes\n    * When workers are done, they send their Session back\n    * When all workers are done (Dask's `gather`), we take all Sessions and do a distributed commit in Icechunk\n    \"\"\"\n\n    repo = icechunk.Repository.open(\n        storage=icechunk.s3_storage(**storage_config(args)),\n        config=repository_config(args),\n    )\n\n    session = repo.writable_session(\"main\")\n\n    tasks = [\n        Task(\n            session=session,\n            time=time,\n            seed=time,\n        )\n        for time in range(args.t_from, args.t_to, 1)\n    ]\n\n    client = Client(n_workers=args.workers, threads_per_worker=1)\n\n    map_result = client.map(execute_write_task, tasks)\n    worker_sessions = client.gather(map_result)\n\n    print(\"Starting distributed commit\")\n    # we can use the current session as the commit coordinator, because it doesn't have any pending changes,\n    # all changes come from the tasks, Icechunk doesn't care about where the changes come from, the only\n    # important thing is to not count changes twice\n    for worker_session in worker_sessions:\n        session.merge(worker_session)\n    commit_res = session.commit(\"distributed commit\")\n    assert commit_res\n    print(\"Distributed commit done\")\n</pre> def update(args: argparse.Namespace) -&gt; None:     \"\"\"Execute the update subcommand.      Uses Dask to write chunks to the Icechunk repository. Currently Icechunk cannot     use the Dask array API (see https://github.com/earth-mover/icechunk/issues/185) but we     can still use a lower level API to do the writes:     * We split the work into small `Task`s, one 'pancake' per task, at a given t coordinate.     * We use Dask's `map` to ship the `Task` to a worker     * The `Task` includes a copy of the Icechunk Session, so workers can do the writes     * When workers are done, they send their Session back     * When all workers are done (Dask's `gather`), we take all Sessions and do a distributed commit in Icechunk     \"\"\"      repo = icechunk.Repository.open(         storage=icechunk.s3_storage(**storage_config(args)),         config=repository_config(args),     )      session = repo.writable_session(\"main\")      tasks = [         Task(             session=session,             time=time,             seed=time,         )         for time in range(args.t_from, args.t_to, 1)     ]      client = Client(n_workers=args.workers, threads_per_worker=1)      map_result = client.map(execute_write_task, tasks)     worker_sessions = client.gather(map_result)      print(\"Starting distributed commit\")     # we can use the current session as the commit coordinator, because it doesn't have any pending changes,     # all changes come from the tasks, Icechunk doesn't care about where the changes come from, the only     # important thing is to not count changes twice     for worker_session in worker_sessions:         session.merge(worker_session)     commit_res = session.commit(\"distributed commit\")     assert commit_res     print(\"Distributed commit done\") In\u00a0[\u00a0]: Copied! <pre>def verify(args: argparse.Namespace) -&gt; None:\n    \"\"\"Execute the verify subcommand.\n\n    Uses Dask to read and verify chunks from the Icechunk repository. Currently Icechunk cannot\n    use the Dask array API (see https://github.com/earth-mover/icechunk/issues/185) but we\n    can still use a lower level API to do the verification:\n    * We split the work into small `Task`s, one 'pancake' per task, at a given t coordinate.\n    * We use Dask's `map` to ship the `Task` to a worker\n    * The `Task` includes a copy of the Icechunk Store, so workers can do the Icechunk reads\n    \"\"\"\n    repo = icechunk.Repository.open(\n        storage=icechunk.s3_storage(**storage_config(args)),\n        config=repository_config(args),\n    )\n\n    session = repo.writable_session(\"main\")\n    store = session.store\n\n    group = zarr.group(store=store, overwrite=False)\n    array = cast(zarr.Array, group[\"array\"])\n    print(f\"Found an array with shape: {array.shape}\")\n\n    tasks = [\n        Task(\n            session=session,\n            time=time,\n            seed=time,\n        )\n        for time in range(args.t_from, args.t_to, 1)\n    ]\n\n    client = Client(n_workers=args.workers, threads_per_worker=1)\n\n    map_result = client.map(execute_read_task, tasks)\n    client.gather(map_result)\n    print(\"done, all good\")\n</pre> def verify(args: argparse.Namespace) -&gt; None:     \"\"\"Execute the verify subcommand.      Uses Dask to read and verify chunks from the Icechunk repository. Currently Icechunk cannot     use the Dask array API (see https://github.com/earth-mover/icechunk/issues/185) but we     can still use a lower level API to do the verification:     * We split the work into small `Task`s, one 'pancake' per task, at a given t coordinate.     * We use Dask's `map` to ship the `Task` to a worker     * The `Task` includes a copy of the Icechunk Store, so workers can do the Icechunk reads     \"\"\"     repo = icechunk.Repository.open(         storage=icechunk.s3_storage(**storage_config(args)),         config=repository_config(args),     )      session = repo.writable_session(\"main\")     store = session.store      group = zarr.group(store=store, overwrite=False)     array = cast(zarr.Array, group[\"array\"])     print(f\"Found an array with shape: {array.shape}\")      tasks = [         Task(             session=session,             time=time,             seed=time,         )         for time in range(args.t_from, args.t_to, 1)     ]      client = Client(n_workers=args.workers, threads_per_worker=1)      map_result = client.map(execute_read_task, tasks)     client.gather(map_result)     print(\"done, all good\") In\u00a0[\u00a0]: Copied! <pre>def main() -&gt; None:\n    \"\"\"Main entry point for the script.\n\n    Parses arguments and delegates to a subcommand.\n    \"\"\"\n\n    global_parser = argparse.ArgumentParser(prog=\"dask_write\")\n    global_parser.add_argument(\n        \"--url\",\n        type=str,\n        help=\"url for the repository: s3://bucket/optional-prefix/repository-name\",\n        required=True,\n    )\n    subparsers = global_parser.add_subparsers(title=\"subcommands\", required=True)\n\n    create_parser = subparsers.add_parser(\"create\", help=\"create repo and array\")\n    create_parser.add_argument(\n        \"--x-chunks\", type=int, help=\"number of chunks in the x dimension\", default=4\n    )\n    create_parser.add_argument(\n        \"--y-chunks\", type=int, help=\"number of chunks in the y dimension\", default=4\n    )\n    create_parser.add_argument(\n        \"--t-chunks\", type=int, help=\"number of chunks in the t dimension\", default=1000\n    )\n    create_parser.add_argument(\n        \"--chunk-x-size\",\n        type=int,\n        help=\"size of chunks in the x dimension\",\n        default=112,\n    )\n    create_parser.add_argument(\n        \"--chunk-y-size\",\n        type=int,\n        help=\"size of chunks in the y dimension\",\n        default=112,\n    )\n    create_parser.set_defaults(command=\"create\")\n\n    update_parser = subparsers.add_parser(\"update\", help=\"add chunks to the array\")\n    update_parser.add_argument(\n        \"--t-from\",\n        type=int,\n        help=\"time position where to start adding chunks (included)\",\n        required=True,\n    )\n    update_parser.add_argument(\n        \"--t-to\",\n        type=int,\n        help=\"time position where to stop adding chunks (not included)\",\n        required=True,\n    )\n    update_parser.add_argument(\n        \"--workers\", type=int, help=\"number of workers to use\", required=True\n    )\n    update_parser.set_defaults(command=\"update\")\n\n    verify_parser = subparsers.add_parser(\"verify\", help=\"verify array chunks\")\n    verify_parser.add_argument(\n        \"--t-from\",\n        type=int,\n        help=\"time position where to start adding chunks (included)\",\n        required=True,\n    )\n    verify_parser.add_argument(\n        \"--t-to\",\n        type=int,\n        help=\"time position where to stop adding chunks (not included)\",\n        required=True,\n    )\n    verify_parser.add_argument(\n        \"--workers\", type=int, help=\"number of workers to use\", required=True\n    )\n    verify_parser.set_defaults(command=\"verify\")\n\n    args = global_parser.parse_args()\n    url = urlparse(args.url, \"s3\")\n    if (\n        url.scheme != \"s3\"\n        or url.netloc == \"\"\n        or url.path == \"\"\n        or url.params != \"\"\n        or url.query != \"\"\n        or url.fragment != \"\"\n    ):\n        raise ValueError(f\"Invalid url {args.url}\")\n\n    args.url = url\n\n    match args.command:\n        case \"create\":\n            create(args)\n        case \"update\":\n            update(args)\n        case \"verify\":\n            verify(args)\n</pre> def main() -&gt; None:     \"\"\"Main entry point for the script.      Parses arguments and delegates to a subcommand.     \"\"\"      global_parser = argparse.ArgumentParser(prog=\"dask_write\")     global_parser.add_argument(         \"--url\",         type=str,         help=\"url for the repository: s3://bucket/optional-prefix/repository-name\",         required=True,     )     subparsers = global_parser.add_subparsers(title=\"subcommands\", required=True)      create_parser = subparsers.add_parser(\"create\", help=\"create repo and array\")     create_parser.add_argument(         \"--x-chunks\", type=int, help=\"number of chunks in the x dimension\", default=4     )     create_parser.add_argument(         \"--y-chunks\", type=int, help=\"number of chunks in the y dimension\", default=4     )     create_parser.add_argument(         \"--t-chunks\", type=int, help=\"number of chunks in the t dimension\", default=1000     )     create_parser.add_argument(         \"--chunk-x-size\",         type=int,         help=\"size of chunks in the x dimension\",         default=112,     )     create_parser.add_argument(         \"--chunk-y-size\",         type=int,         help=\"size of chunks in the y dimension\",         default=112,     )     create_parser.set_defaults(command=\"create\")      update_parser = subparsers.add_parser(\"update\", help=\"add chunks to the array\")     update_parser.add_argument(         \"--t-from\",         type=int,         help=\"time position where to start adding chunks (included)\",         required=True,     )     update_parser.add_argument(         \"--t-to\",         type=int,         help=\"time position where to stop adding chunks (not included)\",         required=True,     )     update_parser.add_argument(         \"--workers\", type=int, help=\"number of workers to use\", required=True     )     update_parser.set_defaults(command=\"update\")      verify_parser = subparsers.add_parser(\"verify\", help=\"verify array chunks\")     verify_parser.add_argument(         \"--t-from\",         type=int,         help=\"time position where to start adding chunks (included)\",         required=True,     )     verify_parser.add_argument(         \"--t-to\",         type=int,         help=\"time position where to stop adding chunks (not included)\",         required=True,     )     verify_parser.add_argument(         \"--workers\", type=int, help=\"number of workers to use\", required=True     )     verify_parser.set_defaults(command=\"verify\")      args = global_parser.parse_args()     url = urlparse(args.url, \"s3\")     if (         url.scheme != \"s3\"         or url.netloc == \"\"         or url.path == \"\"         or url.params != \"\"         or url.query != \"\"         or url.fragment != \"\"     ):         raise ValueError(f\"Invalid url {args.url}\")      args.url = url      match args.command:         case \"create\":             create(args)         case \"update\":             update(args)         case \"verify\":             verify(args) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    main()\n</pre> if __name__ == \"__main__\":     main()"},{"location":"icechunk-python/notebooks/demo-azure-blob/","title":"Demo azure blob","text":"In\u00a0[1]: Copied! <pre>import icechunk\n\nrepo = icechunk.Repository.open_or_create(\n    icechunk.azure_storage(\n        container=\"icechunk-demo\",\n        prefix=\"icechunk-demo-dataset\"\n    )\n)\nrepo\n</pre> import icechunk  repo = icechunk.Repository.open_or_create(     icechunk.azure_storage(         container=\"icechunk-demo\",         prefix=\"icechunk-demo-dataset\"     ) ) repo Out[1]: <pre>&lt;icechunk.repository.Repository at 0x236567df3b0&gt;</pre>"},{"location":"icechunk-python/notebooks/demo-dummy-data/","title":"Icechunk with dummy data","text":"In\u00a0[1]: Copied! <pre>import math\n\nimport numpy as np\nimport zarr\nfrom icechunk import Repository, StorageConfig\n</pre> import math  import numpy as np import zarr from icechunk import Repository, StorageConfig In\u00a0[2]: Copied! <pre>repo = Repository.create(\n    storage=StorageConfig.memory(\"icechunk-demo\"),\n)\nrepo\n</pre> repo = Repository.create(     storage=StorageConfig.memory(\"icechunk-demo\"), ) repo Out[2]: <pre>&lt;icechunk.repository.Repository at 0x11410fd90&gt;</pre> <p>This dictionary will contain array paths and data that were written to Icechunk, so that we can check correctness.</p> In\u00a0[3]: Copied! <pre>expected = {}\n</pre> expected = {} <p>These two utility functions generate and write dummy array data to a group.</p> In\u00a0[4]: Copied! <pre>def generate_array_chunks(size: int, dtype=np.int32):\n    # dim sizes\n    nz = 64\n    nt = 128\n    nx = ny = int(math.sqrt(size / nz / nt))\n\n    # chunk sizes\n    ct = 2\n    cz = 8\n    cx = max(nx // 3, 1)\n    cy = max(ny // 2, 1)\n    chunk_shape = (cx, cy, cz, ct)\n    shape = (nx, ny, nz, nt)\n\n    array = np.arange(nx * ny * nz * nt, dtype=dtype).reshape(shape)\n\n    return array, chunk_shape\n\n\ndef create_array(*, group, name, size, dtype, fill_value) -&gt; np.ndarray:\n    dims = (\"x\", \"y\", \"z\", \"t\")\n    attrs = {\"description\": \"icechunk test data\"}\n\n    array, chunk_shape = generate_array_chunks(size=size, dtype=dtype)\n\n    group.create_array(\n        name=name,\n        shape=array.shape,\n        dtype=dtype,\n        fill_value=fill_value,\n        chunk_shape=chunk_shape,\n        dimension_names=dims,\n        attributes=attrs,\n        data=array,\n        overwrite=True,\n    )\n\n    return array\n</pre> def generate_array_chunks(size: int, dtype=np.int32):     # dim sizes     nz = 64     nt = 128     nx = ny = int(math.sqrt(size / nz / nt))      # chunk sizes     ct = 2     cz = 8     cx = max(nx // 3, 1)     cy = max(ny // 2, 1)     chunk_shape = (cx, cy, cz, ct)     shape = (nx, ny, nz, nt)      array = np.arange(nx * ny * nz * nt, dtype=dtype).reshape(shape)      return array, chunk_shape   def create_array(*, group, name, size, dtype, fill_value) -&gt; np.ndarray:     dims = (\"x\", \"y\", \"z\", \"t\")     attrs = {\"description\": \"icechunk test data\"}      array, chunk_shape = generate_array_chunks(size=size, dtype=dtype)      group.create_array(         name=name,         shape=array.shape,         dtype=dtype,         fill_value=fill_value,         chunk_shape=chunk_shape,         dimension_names=dims,         attributes=attrs,         data=array,         overwrite=True,     )      return array In\u00a0[5]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\n</pre> session = repo.writable_session(\"main\") store = session.store() In\u00a0[6]: Copied! <pre>root_group = zarr.group(store=store, overwrite=True)\nroot_group.attrs[\"foo\"] = \"foo\"\ndict(root_group.attrs)  # check that it was written\n</pre> root_group = zarr.group(store=store, overwrite=True) root_group.attrs[\"foo\"] = \"foo\" dict(root_group.attrs)  # check that it was written Out[6]: <pre>{'foo': 'foo'}</pre> <p>Commit that change</p> In\u00a0[7]: Copied! <pre>first_commit = session.commit(\"wrote a root group attribute\")\nfirst_commit\n</pre> first_commit = session.commit(\"wrote a root group attribute\") first_commit Out[7]: <pre>'J0BGGVW1RE95RZF027G0'</pre> In\u00a0[8]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\nroot_group = zarr.open_group(store)\n</pre> session = repo.writable_session(\"main\") store = session.store() root_group = zarr.open_group(store) In\u00a0[9]: Copied! <pre>expected[\"root-foo\"] = create_array(\n    group=root_group,\n    name=\"root-foo\",\n    size=1 * 1024 * 256,\n    dtype=np.int32,\n    fill_value=-1,\n)\n</pre> expected[\"root-foo\"] = create_array(     group=root_group,     name=\"root-foo\",     size=1 * 1024 * 256,     dtype=np.int32,     fill_value=-1, ) In\u00a0[10]: Copied! <pre>print(root_group.members())\n</pre> print(root_group.members()) <pre>(('root-foo', &lt;Array &lt;icechunk.store.IcechunkStore object at 0x114197d10&gt;/root-foo shape=(5, 5, 64, 128) dtype=int32&gt;),)\n</pre> In\u00a0[11]: Copied! <pre>dict(root_group[\"root-foo\"].attrs)\n</pre> dict(root_group[\"root-foo\"].attrs) Out[11]: <pre>{'description': 'icechunk test data'}</pre> In\u00a0[12]: Copied! <pre>root_group[\"root-foo\"].attrs[\"update\"] = \"new attr\"\n</pre> root_group[\"root-foo\"].attrs[\"update\"] = \"new attr\" In\u00a0[13]: Copied! <pre>second_commit = session.commit(\"added array, updated attr\")\nsecond_commit\n</pre> second_commit = session.commit(\"added array, updated attr\") second_commit Out[13]: <pre>'0Q9TYRA4Q0R6P8Z799A0'</pre> In\u00a0[14]: Copied! <pre>assert len(root_group[\"root-foo\"].attrs) == 2\nassert len(root_group.members()) == 1\n</pre> assert len(root_group[\"root-foo\"].attrs) == 2 assert len(root_group.members()) == 1 In\u00a0[17]: Copied! <pre>session = repo.readonly_session(snapshot_id=first_commit)\nroot_group = zarr.open_group(session.store(), mode=\"r\")\n\ntry:\n    root_group.attrs[\"update\"] = \"new attr 2\"\n    session.commit(\"new attr 2\")\nexcept ValueError as e:\n    print(e)\nelse:\n    raise ValueError(\"should have failed\")\n</pre> session = repo.readonly_session(snapshot_id=first_commit) root_group = zarr.open_group(session.store(), mode=\"r\")  try:     root_group.attrs[\"update\"] = \"new attr 2\"     session.commit(\"new attr 2\") except ValueError as e:     print(e) else:     raise ValueError(\"should have failed\") <pre>store error: cannot write to read-only store\n</pre> In\u00a0[18]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\nroot_group = zarr.open_group(store)\nroot_group[\"root-foo\"].attrs[\"update\"] = \"new attr 2\"\nthird_commit = session.commit(\"new attr 2\")\nthird_commit\n</pre> session = repo.writable_session(\"main\") store = session.store() root_group = zarr.open_group(store) root_group[\"root-foo\"].attrs[\"update\"] = \"new attr 2\" third_commit = session.commit(\"new attr 2\") third_commit Out[18]: <pre>'E90PKVRPW0RXY8TBW1F0'</pre> In\u00a0[19]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\nroot_group = zarr.open_group(store)\n\nroot_group.attrs[\"update\"] = \"new attr 2\"\nfourth_commit = session.commit(\"rewrote array\")\nfourth_commit\n</pre> session = repo.writable_session(\"main\") store = session.store() root_group = zarr.open_group(store)  root_group.attrs[\"update\"] = \"new attr 2\" fourth_commit = session.commit(\"rewrote array\") fourth_commit Out[19]: <pre>'A18E787SJQEVY0546XTG'</pre> In\u00a0[20]: Copied! <pre>{k: v.dtype for k, v in expected.items()}\n</pre> {k: v.dtype for k, v in expected.items()} Out[20]: <pre>{'root-foo': dtype('int32')}</pre> In\u00a0[21]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\nroot_group = zarr.open_group(store)\n\nnewgroup = zarr.group(store=store, path=\"group1/\")\nexpected[\"group1/foo1\"] = create_array(\n    group=newgroup, name=\"foo1\", dtype=np.float32, size=1 * 1024 * 128, fill_value=-1234\n)\nexpected[\"group1/foo2\"] = create_array(\n    group=newgroup, name=\"foo2\", dtype=np.float16, size=1 * 1024 * 64, fill_value=-1234\n)\nnewgroup = zarr.group(store=store, path=\"group2/\")\nexpected[\"group2/foo3\"] = create_array(\n    group=newgroup, name=\"foo3\", dtype=np.int64, size=1 * 1024 * 32, fill_value=-1234\n)\nfifth_commit = session.commit(\"added groups and arrays\")\nfifth_commit\n</pre> session = repo.writable_session(\"main\") store = session.store() root_group = zarr.open_group(store)  newgroup = zarr.group(store=store, path=\"group1/\") expected[\"group1/foo1\"] = create_array(     group=newgroup, name=\"foo1\", dtype=np.float32, size=1 * 1024 * 128, fill_value=-1234 ) expected[\"group1/foo2\"] = create_array(     group=newgroup, name=\"foo2\", dtype=np.float16, size=1 * 1024 * 64, fill_value=-1234 ) newgroup = zarr.group(store=store, path=\"group2/\") expected[\"group2/foo3\"] = create_array(     group=newgroup, name=\"foo3\", dtype=np.int64, size=1 * 1024 * 32, fill_value=-1234 ) fifth_commit = session.commit(\"added groups and arrays\") fifth_commit Out[21]: <pre>'9TWWMX1BMFPYZ200MDYG'</pre> In\u00a0[22]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\nroot_group = zarr.open_group(store)\n\nexpected[\"root-foo\"] = create_array(\n    group=root_group,\n    name=\"root-foo\",\n    size=1 * 1024 * 128,\n    dtype=np.int32,\n    fill_value=-1,\n)\n</pre> session = repo.writable_session(\"main\") store = session.store() root_group = zarr.open_group(store)  expected[\"root-foo\"] = create_array(     group=root_group,     name=\"root-foo\",     size=1 * 1024 * 128,     dtype=np.int32,     fill_value=-1, ) In\u00a0[23]: Copied! <pre>session.commit(\"overwrote root-foo\")\n</pre> session.commit(\"overwrote root-foo\") Out[23]: <pre>'3AB2MKGKKZYFFY3WN070'</pre> In\u00a0[24]: Copied! <pre>root_group.members()\n</pre> root_group.members() Out[24]: <pre>(('root-foo',\n  &lt;Array &lt;icechunk.store.IcechunkStore object at 0x11563f550&gt;/root-foo shape=(4, 4, 64, 128) dtype=int32&gt;),\n ('group1',\n  &lt;Group &lt;icechunk.store.IcechunkStore object at 0x11563f550&gt;/group1&gt;),\n ('group2',\n  &lt;Group &lt;icechunk.store.IcechunkStore object at 0x11563f550&gt;/group2&gt;))</pre> In\u00a0[25]: Copied! <pre>root_group[\"group1\"].members()\n</pre> root_group[\"group1\"].members() Out[25]: <pre>(('foo1',\n  &lt;Array &lt;icechunk.store.IcechunkStore object at 0x11563f550&gt;/group1/foo1 shape=(4, 4, 64, 128) dtype=float32&gt;),\n ('foo2',\n  &lt;Array &lt;icechunk.store.IcechunkStore object at 0x11563f550&gt;/group1/foo2 shape=(2, 2, 64, 128) dtype=float16&gt;))</pre> In\u00a0[26]: Copied! <pre>root_group[\"group2\"].members()\n</pre> root_group[\"group2\"].members() Out[26]: <pre>(('foo3',\n  &lt;Array &lt;icechunk.store.IcechunkStore object at 0x11563f550&gt;/group2/foo3 shape=(2, 2, 64, 128) dtype=int64&gt;),)</pre> In\u00a0[28]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\nroot_group = zarr.open_group(store)\n\narray = root_group[\"group2/foo3\"]\nprint(array)\n\narray = array.resize((array.shape[0] * 2, *array.shape[1:]))\nprint(array)\narray[array.shape[0] // 2 :, ...] = expected[\"group2/foo3\"]\nprint(array[2:, 0, 0, 0])\nexpected[\"group2/foo3\"] = np.concatenate([expected[\"group2/foo3\"]] * 2, axis=0)\n\nsession.commit(\"appended to group2/foo3\")\n</pre> session = repo.writable_session(\"main\") store = session.store() root_group = zarr.open_group(store)  array = root_group[\"group2/foo3\"] print(array)  array = array.resize((array.shape[0] * 2, *array.shape[1:])) print(array) array[array.shape[0] // 2 :, ...] = expected[\"group2/foo3\"] print(array[2:, 0, 0, 0]) expected[\"group2/foo3\"] = np.concatenate([expected[\"group2/foo3\"]] * 2, axis=0)  session.commit(\"appended to group2/foo3\") <pre>&lt;Array &lt;icechunk.store.IcechunkStore object at 0x1155141d0&gt;/group2/foo3 shape=(2, 2, 64, 128) dtype=int64&gt;\nNone\n</pre> <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[28], line 10\n      8 array = array.resize((array.shape[0] * 2, *array.shape[1:]))\n      9 print(array)\n---&gt; 10 array[array.shape[0] // 2 :, ...] = expected[\"group2/foo3\"]\n     11 print(array[2:, 0, 0, 0])\n     12 expected[\"group2/foo3\"] = np.concatenate([expected[\"group2/foo3\"]] * 2, axis=0)\n\nAttributeError: 'NoneType' object has no attribute 'shape'</pre> In\u00a0[26]: Copied! <pre># import time\n\n# for key, value in expected.items():\n#     print(key)\n#     tic = time.time()\n#     array = root_group[key]\n#     assert array.dtype == value.dtype, (array.dtype, value.dtype)\n#     print(f\"numchunks: {math.prod(s // c for s, c in zip(array.shape, array.chunks, strict=False))}\")\n#     np.testing.assert_array_equal(array[:], value)\n#     print(time.time() - tic)\n</pre> # import time  # for key, value in expected.items(): #     print(key) #     tic = time.time() #     array = root_group[key] #     assert array.dtype == value.dtype, (array.dtype, value.dtype) #     print(f\"numchunks: {math.prod(s // c for s, c in zip(array.shape, array.chunks, strict=False))}\") #     np.testing.assert_array_equal(array[:], value) #     print(time.time() - tic)"},{"location":"icechunk-python/notebooks/demo-dummy-data/#icechunk-with-dummy-data","title":"Icechunk with dummy data\u00b6","text":"<p>This demo illustrates how to use Icechunk as a Zarr store</p>"},{"location":"icechunk-python/notebooks/demo-dummy-data/#create-a-new-zarr-store-backed-by-icechunk","title":"Create a new Zarr store backed by Icechunk\u00b6","text":"<p>This example uses an in-memory store.</p>"},{"location":"icechunk-python/notebooks/demo-dummy-data/#a-versioned-transactional-zarr-store","title":"A versioned transactional Zarr store\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-dummy-data/#open-the-root-group-write-an-attribute-commit","title":"Open the root group, write an attribute, commit\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-dummy-data/#add-a-array-to-the-root-group","title":"Add a array to the root group\u00b6","text":"<p>We save the created array in <code>expected</code> to check that the write was correct (later).</p>"},{"location":"icechunk-python/notebooks/demo-dummy-data/#writing-and-committing-when-not-on-head-will-fail","title":"Writing and Committing when not on <code>HEAD</code> will fail.\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-dummy-data/#checkout-head-make-a-change-and-commit","title":"Checkout <code>HEAD</code>, make a change, and commit.\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-dummy-data/#create-a-hierarchy","title":"Create a hierarchy\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-dummy-data/#overwrite-an-array","title":"Overwrite an array\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-dummy-data/#examine-the-hierarchy","title":"Examine the hierarchy\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-dummy-data/#append","title":"Append\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-dummy-data/#check-that-values-are-correct","title":"Check that values are correct\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-gcs/","title":"Demo gcs","text":"In\u00a0[1]: Copied! <pre>import icechunk\n\nrepo = icechunk.Repository.open_or_create(\n    icechunk.gcs_storage(\n        bucket=\"icechunk-demo\",\n        prefix=\"icechunk-demo-dataset\",\n        service_account_file=\"/Users/matthew.earthmover/Developer/keys/icechunk-service-account.json\"\n    )\n)\nrepo\n</pre> import icechunk  repo = icechunk.Repository.open_or_create(     icechunk.gcs_storage(         bucket=\"icechunk-demo\",         prefix=\"icechunk-demo-dataset\",         service_account_file=\"/Users/matthew.earthmover/Developer/keys/icechunk-service-account.json\"     ) ) repo Out[1]: <pre>&lt;icechunk.repository.Repository at 0x1067a7d90&gt;</pre>"},{"location":"icechunk-python/notebooks/demo-s3/","title":"Xarray/Zarr/Icechunk on S3","text":"In\u00a0[\u00a0]: Copied! <pre>import zarr\nfrom icechunk import Repository, StorageConfig\n</pre> import zarr from icechunk import Repository, StorageConfig In\u00a0[\u00a0]: Copied! <pre>s3_storage = StorageConfig.s3_from_env(\n    bucket=\"icechunk-test\", prefix=\"oscar-demo-repository\"\n)\n</pre> s3_storage = StorageConfig.s3_from_env(     bucket=\"icechunk-test\", prefix=\"oscar-demo-repository\" ) In\u00a0[\u00a0]: Copied! <pre>repo = Repository.create(\n    storage=s3_storage,\n)\n</pre> repo = Repository.create(     storage=s3_storage, ) In\u00a0[\u00a0]: Copied! <pre>import xarray as xr\n</pre> import xarray as xr In\u00a0[\u00a0]: Copied! <pre>import fsspec\n\nfs = fsspec.filesystem(\"s3\")\n</pre> import fsspec  fs = fsspec.filesystem(\"s3\") In\u00a0[\u00a0]: Copied! <pre>oscar = xr.open_dataset(\n    fs.open(\"s3://earthmover-sample-data/netcdf/oscar_vel2018.nc\"),\n    chunks={},\n    engine=\"h5netcdf\",\n)\noscar\n</pre> oscar = xr.open_dataset(     fs.open(\"s3://earthmover-sample-data/netcdf/oscar_vel2018.nc\"),     chunks={},     engine=\"h5netcdf\", ) oscar In\u00a0[\u00a0]: Copied! <pre>session = repo.session(\"main\")\n\ngroup = zarr.group(store=session.store(), overwrite=True)\ngroup\n</pre> session = repo.session(\"main\")  group = zarr.group(store=session.store(), overwrite=True) group In\u00a0[\u00a0]: Copied! <pre>import time\n\nfor var in oscar:\n    session = repo.writable_session(\"main\")\n    group = zarr.open_group(store=session.store())\n    print(var)\n    tic = time.time()\n    group.create_array(\n        name=var,\n        shape=oscar[var].shape,\n        chunk_shape=(1, 1, 481, 1201),\n        fill_value=-1234567,\n        dtype=oscar[var].dtype,\n        data=oscar[var],\n        overwrite=True,\n    )\n    print(session.commit(f\"wrote {var}\"))\n    print(f\"committed; {time.time() - tic} seconds\")\n</pre> import time  for var in oscar:     session = repo.writable_session(\"main\")     group = zarr.open_group(store=session.store())     print(var)     tic = time.time()     group.create_array(         name=var,         shape=oscar[var].shape,         chunk_shape=(1, 1, 481, 1201),         fill_value=-1234567,         dtype=oscar[var].dtype,         data=oscar[var],         overwrite=True,     )     print(session.commit(f\"wrote {var}\"))     print(f\"committed; {time.time() - tic} seconds\") In\u00a0[\u00a0]: Copied! <pre>main_snapshot_id = repo.lookup_branch(\"main\")\nrepo.ancestry(main_snapshot_id)\n</pre> main_snapshot_id = repo.lookup_branch(\"main\") repo.ancestry(main_snapshot_id) In\u00a0[\u00a0]: Copied! <pre>import zarr\nfrom icechunk import Repository, StorageConfig\n\n# TODO: catalog will handle this\ns3_storage = StorageConfig.s3_from_env(\n    bucket=\"icechunk-test\", prefix=\"oscar-demo-repository\"\n)\n</pre> import zarr from icechunk import Repository, StorageConfig  # TODO: catalog will handle this s3_storage = StorageConfig.s3_from_env(     bucket=\"icechunk-test\", prefix=\"oscar-demo-repository\" ) In\u00a0[\u00a0]: Copied! <pre>repo = Repository.open(\n    storage=s3_storage,\n)\nrepo\n</pre> repo = Repository.open(     storage=s3_storage, ) repo <p>Look at history</p> In\u00a0[\u00a0]: Copied! <pre>main_snapshot_id = repo.lookup_branch(\"main\")\n[s.message for s in repo.ancestry(main_snapshot_id)]\n</pre> main_snapshot_id = repo.lookup_branch(\"main\") [s.message for s in repo.ancestry(main_snapshot_id)] In\u00a0[\u00a0]: Copied! <pre>root_group = zarr.open_group(store=store)\n</pre> root_group = zarr.open_group(store=store) In\u00a0[\u00a0]: Copied! <pre>root_group.members()\n</pre> root_group.members() In\u00a0[\u00a0]: Copied! <pre>root_group.members()\n</pre> root_group.members() In\u00a0[\u00a0]: Copied! <pre>import matplotlib as mpl\nimport matplotlib.pyplot as plt\n</pre> import matplotlib as mpl import matplotlib.pyplot as plt In\u00a0[\u00a0]: Copied! <pre>plt.imshow(root_group[\"u\"][20, 0, :, :], cmap=mpl.cm.RdBu_r, vmin=-0.5, vmax=0.5)\nplt.gcf().set_size_inches((9, 5))\nplt.colorbar(location=\"bottom\", orientation=\"horizontal\", shrink=0.5, aspect=30)\n</pre> plt.imshow(root_group[\"u\"][20, 0, :, :], cmap=mpl.cm.RdBu_r, vmin=-0.5, vmax=0.5) plt.gcf().set_size_inches((9, 5)) plt.colorbar(location=\"bottom\", orientation=\"horizontal\", shrink=0.5, aspect=30)"},{"location":"icechunk-python/notebooks/demo-s3/#xarrayzarricechunk-on-s3","title":"Xarray/Zarr/Icechunk on S3\u00b6","text":"<p>You will need to run this notebook in a <code>conda</code> environment created from <code>environment.yml</code>.</p>"},{"location":"icechunk-python/notebooks/demo-s3/#create-a-new-zarr-store-backed-by-icechunk","title":"Create a new Zarr store backed by Icechunk\u00b6","text":"<p>This example uses a S3 store</p>"},{"location":"icechunk-python/notebooks/demo-s3/#real-data","title":"Real data\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-s3/#write-to-icechunk","title":"Write to icechunk\u00b6","text":""},{"location":"icechunk-python/notebooks/demo-s3/#open-store","title":"Open store\u00b6","text":""},{"location":"icechunk-python/notebooks/memorystore/","title":"Memorystore","text":"In\u00a0[1]: Copied! <pre>import icechunk\nimport zarr\n</pre> import icechunk import zarr <p>Lets create an in-memory icechunk store</p> In\u00a0[2]: Copied! <pre>repo = icechunk.Repository.create(\n    storage=icechunk.StorageConfig.memory(\"\")\n)\nrepo\n</pre> repo = icechunk.Repository.create(     storage=icechunk.StorageConfig.memory(\"\") ) repo Out[2]: <pre>&lt;icechunk.repository.Repository at 0x1117d8910&gt;</pre> <p>Ok! Lets create some data!</p> In\u00a0[3]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\ngroup = zarr.group(store=store, overwrite=True)\ngroup\n</pre> session = repo.writable_session(\"main\") store = session.store() group = zarr.group(store=store, overwrite=True) group Out[3]: <pre>&lt;Group &lt;icechunk.store.IcechunkStore object at 0x116706b90&gt;&gt;</pre> In\u00a0[4]: Copied! <pre>air_temp = group.create_array(\n    \"air_temp\", shape=(1000, 1000), chunk_shape=(100, 100), dtype=\"i4\"\n)\nair_temp\n</pre> air_temp = group.create_array(     \"air_temp\", shape=(1000, 1000), chunk_shape=(100, 100), dtype=\"i4\" ) air_temp Out[4]: <pre>&lt;Array &lt;icechunk.store.IcechunkStore object at 0x116706b90&gt;/air_temp shape=(1000, 1000) dtype=int32&gt;</pre> In\u00a0[5]: Copied! <pre>async for key in store.list():\n    print(key)\n</pre> async for key in store.list():     print(key) <pre>zarr.json\nair_temp/zarr.json\n</pre> In\u00a0[6]: Copied! <pre>air_temp[:, :] = 42\n</pre> air_temp[:, :] = 42 In\u00a0[7]: Copied! <pre>air_temp[200, 6]\n</pre> air_temp[200, 6] Out[7]: <pre>array(42, dtype=int32)</pre> <p>Now that we have set the values, lets commit</p> In\u00a0[8]: Copied! <pre>snapshot_id = session.commit(\"Initial commit\")\nsnapshot_id\n</pre> snapshot_id = session.commit(\"Initial commit\") snapshot_id Out[8]: <pre>'QS2Z02V6HEQ3PZYB31BG'</pre> <p>Lets get another session</p> In\u00a0[9]: Copied! <pre>from typing import cast\n\n\nsession = repo.writable_session(\"main\")\nstore = session.store()\ngroup = zarr.open_group(store)\nair_temp = cast(zarr.Array, group[\"air_temp\"])\n</pre> from typing import cast   session = repo.writable_session(\"main\") store = session.store() group = zarr.open_group(store) air_temp = cast(zarr.Array, group[\"air_temp\"]) <p>Okay now we can change the data</p> In\u00a0[10]: Copied! <pre>air_temp[:, :] = 54\n</pre> air_temp[:, :] = 54 In\u00a0[11]: Copied! <pre>air_temp[200, 6]\n</pre> air_temp[200, 6] Out[11]: <pre>array(54, dtype=int32)</pre> <p>And we can commit again</p> In\u00a0[12]: Copied! <pre>new_snapshot_id = session.commit(\"Change air temp to 54\")\nnew_snapshot_id\n</pre> new_snapshot_id = session.commit(\"Change air temp to 54\") new_snapshot_id Out[12]: <pre>'KKWDTZQDHS3G86D797BG'</pre> <p>Cool, now lets checkout the original snapshot and see if the value is 42 again</p> In\u00a0[13]: Copied! <pre>store = repo.readonly_session(snapshot_id=new_snapshot_id).store()\ngroup = zarr.open_group(store, mode='r')\nair_temp = cast(zarr.Array, group[\"air_temp\"])\nair_temp[200, 6]\n</pre> store = repo.readonly_session(snapshot_id=new_snapshot_id).store() group = zarr.open_group(store, mode='r') air_temp = cast(zarr.Array, group[\"air_temp\"]) air_temp[200, 6] Out[13]: <pre>array(54, dtype=int32)</pre>"},{"location":"icechunk-python/notebooks/version-control/","title":"Version Control with Icechunk","text":"In\u00a0[1]: Copied! <pre>import zarr\nfrom icechunk import Repository, StorageConfig\n</pre> import zarr from icechunk import Repository, StorageConfig In\u00a0[2]: Copied! <pre>repo = Repository.create(\n    storage=StorageConfig.memory(\"test\")\n)\nrepo\n</pre> repo = Repository.create(     storage=StorageConfig.memory(\"test\") ) repo Out[2]: <pre>&lt;icechunk.repository.Repository at 0x10a966950&gt;</pre> <ol> <li>Why not checkout main by default?</li> <li>Why can I create snapshots on the <code>None</code> branch</li> </ol> In\u00a0[3]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\nroot_group = zarr.group(store=store)\n</pre> session = repo.writable_session(\"main\") store = session.store() root_group = zarr.group(store=store) In\u00a0[4]: Copied! <pre>root_group.attrs[\"attr\"] = \"first_attr\"\n</pre> root_group.attrs[\"attr\"] = \"first_attr\" In\u00a0[5]: Copied! <pre>first_commit = session.commit(\"first commit\")\nfirst_commit\n</pre> first_commit = session.commit(\"first commit\") first_commit Out[5]: <pre>'23G8HS855AW4W7E5QX20'</pre> In\u00a0[6]: Copied! <pre>dict(root_group.attrs)\n</pre> dict(root_group.attrs) Out[6]: <pre>{'attr': 'first_attr'}</pre> In\u00a0[7]: Copied! <pre>session = repo.writable_session(\"main\")\nstore = session.store()\nroot_group = zarr.group(store=store)\n\nroot_group.attrs[\"attr\"] = \"second_attr\"\nsecond_commit = session.commit(\"second commit\")\nsecond_commit\n</pre> session = repo.writable_session(\"main\") store = session.store() root_group = zarr.group(store=store)  root_group.attrs[\"attr\"] = \"second_attr\" second_commit = session.commit(\"second commit\") second_commit Out[7]: <pre>'5YQ4CHFRTA8WY621RREG'</pre> In\u00a0[8]: Copied! <pre>repo.lookup_branch(\"main\")\n</pre> repo.lookup_branch(\"main\") Out[8]: <pre>'5YQ4CHFRTA8WY621RREG'</pre> <p>Here's where we are:</p> In\u00a0[9]: Copied! <pre>session.snapshot_id, dict(root_group.attrs)\n</pre> session.snapshot_id, dict(root_group.attrs) Out[9]: <pre>('5YQ4CHFRTA8WY621RREG', {'attr': 'second_attr'})</pre> In\u00a0[11]: Copied! <pre>session = repo.readonly_session(snapshot_id=first_commit)\nroot_group = zarr.open_group(store=store, mode=\"r\")\ndict(root_group.attrs)\n</pre> session = repo.readonly_session(snapshot_id=first_commit) root_group = zarr.open_group(store=store, mode=\"r\") dict(root_group.attrs) Out[11]: <pre>{'attr': 'second_attr'}</pre> In\u00a0[13]: Copied! <pre>try:\n    root_group.attrs[\"attr\"] = \"will_fail\"\n    session.commit(\"this should fail\")\nexcept Exception as e:\n    print(e)\n</pre> try:     root_group.attrs[\"attr\"] = \"will_fail\"     session.commit(\"this should fail\") except Exception as e:     print(e) <pre>store error: cannot write to read-only store\n</pre> In\u00a0[14]: Copied! <pre>repo.create_branch(\"feature\", first_commit)\n</pre> repo.create_branch(\"feature\", first_commit) In\u00a0[15]: Copied! <pre>assert repo.lookup_branch(\"feature\") == first_commit\n</pre> assert repo.lookup_branch(\"feature\") == first_commit In\u00a0[16]: Copied! <pre>session = repo.writable_session(\"feature\")\nstore = session.store()\n\nroot_group = zarr.group(store=store)\ndict(root_group.attrs)\n</pre> session = repo.writable_session(\"feature\") store = session.store()  root_group = zarr.group(store=store) dict(root_group.attrs) Out[16]: <pre>{'attr': 'first_attr'}</pre> In\u00a0[17]: Copied! <pre>root_group.attrs[\"attr\"] = \"new_branch_attr\"\nnew_branch_commit = session.commit(\"commit on new branch\")\n</pre> root_group.attrs[\"attr\"] = \"new_branch_attr\" new_branch_commit = session.commit(\"commit on new branch\") In\u00a0[18]: Copied! <pre>repo.create_tag(\"v1\", snapshot_id=first_commit)\n</pre> repo.create_tag(\"v1\", snapshot_id=first_commit) In\u00a0[19]: Copied! <pre>repo.create_tag(\"v2\", snapshot_id=second_commit)\n</pre> repo.create_tag(\"v2\", snapshot_id=second_commit) In\u00a0[20]: Copied! <pre>session = repo.readonly_session(tag=\"v1\")\nsession.snapshot_id\n</pre> session = repo.readonly_session(tag=\"v1\") session.snapshot_id Out[20]: <pre>'23G8HS855AW4W7E5QX20'</pre>"},{"location":"icechunk-python/notebooks/version-control/#version-control-with-icechunk","title":"Version Control with Icechunk\u00b6","text":""},{"location":"icechunk-python/notebooks/version-control/#create-a-new-zarr-store-backed-by-icechunk","title":"Create a new Zarr store backed by Icechunk\u00b6","text":"<p>This example uses an in-memory store.</p>"},{"location":"icechunk-python/notebooks/version-control/#snaphotting","title":"Snaphotting\u00b6","text":""},{"location":"icechunk-python/notebooks/version-control/#concepts","title":"Concepts\u00b6","text":"<ol> <li><code>store.commit</code> creates a snapshot of the data.</li> <li>Every snapshot is associated with a snapshot ID.</li> <li>Use the snapshot ID to time-travel within your data's history.</li> </ol>"},{"location":"icechunk-python/notebooks/version-control/#create-a-snapshot","title":"Create a snapshot\u00b6","text":""},{"location":"icechunk-python/notebooks/version-control/#view-the-current-snapshot-id","title":"View the current snapshot ID\u00b6","text":""},{"location":"icechunk-python/notebooks/version-control/#time-travel-to-a-snapshot","title":"Time-travel to a snapshot\u00b6","text":""},{"location":"icechunk-python/notebooks/version-control/#snapshotting-is-only-allowed-at-the-tip-of-a-branch","title":"Snapshotting is only allowed at the tip of a branch\u00b6","text":"<p>TODO: need better error message</p>"},{"location":"icechunk-python/notebooks/version-control/#branching","title":"Branching\u00b6","text":""},{"location":"icechunk-python/notebooks/version-control/#create-a-new-branch","title":"Create a new branch\u00b6","text":"<p>We will create a new branch starting at <code>first_commit</code></p>"},{"location":"icechunk-python/notebooks/version-control/#tagging","title":"Tagging\u00b6","text":""},{"location":"icechunk-python/notebooks/version-control/#creating-a-new-tag","title":"Creating a new tag\u00b6","text":""},{"location":"icechunk-python/notebooks/version-control/#time-travel-to-a-tag","title":"Time-travel to a tag\u00b6","text":"<p>Pass the <code>tag</code> argument to <code>checkout</code></p>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-Icechunk/","title":"Icechunk Performance - Icechunk","text":"In\u00a0[1]: Copied! <pre>import xarray as xr\nimport zarr\nimport dask\nimport fsspec\nfrom dask.diagnostics import ProgressBar\n\nimport icechunk\nfrom icechunk import IcechunkStore, StorageConfig\n\nprint('xarray:  ', xr.__version__)\nprint('dask:    ', dask.__version__)\nprint('zarr:    ', zarr.__version__)\nprint('icechunk:', icechunk.__version__)\n</pre> import xarray as xr import zarr import dask import fsspec from dask.diagnostics import ProgressBar  import icechunk from icechunk import IcechunkStore, StorageConfig  print('xarray:  ', xr.__version__) print('dask:    ', dask.__version__) print('zarr:    ', zarr.__version__) print('icechunk:', icechunk.__version__) <pre>xarray:   0.9.7.dev3734+g26081d4f\ndask:     2024.9.1+8.g70f56e28\nzarr:     3.0.0b0\nicechunk: 0.1.0-alpha.1\n</pre> In\u00a0[2]: Copied! <pre>zarr.config.set(\n    {\n        'threading.max_workers': 16,\n        'async.concurrency': 128\n    }\n)\n</pre> zarr.config.set(     {         'threading.max_workers': 16,         'async.concurrency': 128     } ) Out[2]: <pre>&lt;donfig.config_obj.ConfigSet at 0x7f9ea9f36690&gt;</pre> In\u00a0[3]: Copied! <pre>url = \"https://nsf-ncar-era5.s3.amazonaws.com/e5.oper.an.pl/194106/e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.nc\"\n%time ds = xr.open_dataset(fsspec.open(url).open(), engine=\"h5netcdf\", chunks={\"time\": 1})\nds = ds.drop_encoding()\n</pre> url = \"https://nsf-ncar-era5.s3.amazonaws.com/e5.oper.an.pl/194106/e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.nc\" %time ds = xr.open_dataset(fsspec.open(url).open(), engine=\"h5netcdf\", chunks={\"time\": 1}) ds = ds.drop_encoding() <pre>CPU times: user 246 ms, sys: 51.8 ms, total: 297 ms\nWall time: 2.22 s\n</pre> <pre>/srv/conda/envs/icechunk-pip/lib/python3.12/site-packages/xarray/backends/api.py:357: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 1. This could degrade performance. Instead, consider rechunking after loading.\n  var_chunks = _get_chunk(var, chunks, chunkmanager)\n</pre> In\u00a0[4]: Copied! <pre>print(ds)\n</pre> print(ds) <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:    (time: 24, level: 37, latitude: 721, longitude: 1440)\nCoordinates:\n  * latitude   (latitude) float64 6kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n  * level      (level) float64 296B 1.0 2.0 3.0 5.0 ... 925.0 950.0 975.0 1e+03\n  * longitude  (longitude) float64 12kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n  * time       (time) datetime64[ns] 192B 1941-06-01 ... 1941-06-01T23:00:00\nData variables:\n    PV         (time, level, latitude, longitude) float32 4GB dask.array&lt;chunksize=(1, 37, 721, 1440), meta=np.ndarray&gt;\n    utc_date   (time) int32 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nAttributes:\n    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB 1 data to netC...\n    NETCDF_VERSION:       4.8.1\n    CONVERSION_PLATFORM:  Linux r1i4n4 4.12.14-95.51-default #1 SMP Fri Apr 1...\n    CONVERSION_DATE:      Wed May 10 06:33:49 MDT 2023\n    Conventions:          CF-1.6\n    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n    history:              Wed May 10 06:34:19 2023: ncks -4 --ppc default=7 e...\n    NCO:                  netCDF Operators version 5.0.3 (Homepage = http://n...\n</pre> In\u00a0[5]: Copied! <pre>with ProgressBar():\n    dsl = ds.load()\n</pre> with ProgressBar():     dsl = ds.load() <pre>[########################################] | 100% Completed | 53.73 ss\n</pre> In\u00a0[6]: Copied! <pre>prefix = \"ryan/icechunk-tests-era5-999\"\nstore = IcechunkStore.create(\n    storage=StorageConfig.s3_from_env(\n        bucket=\"icechunk-test\",\n        prefix=prefix\n    ),\n    mode=\"w\"\n)\nstore\n</pre> prefix = \"ryan/icechunk-tests-era5-999\" store = IcechunkStore.create(     storage=StorageConfig.s3_from_env(         bucket=\"icechunk-test\",         prefix=prefix     ),     mode=\"w\" ) store Out[6]: <pre>&lt;icechunk.IcechunkStore at 0x7f9eb84402c0&gt;</pre> In\u00a0[7]: Copied! <pre>store.branch, store.snapshot_id\n</pre> store.branch, store.snapshot_id Out[7]: <pre>('main', 'B8ZZN2YZS6NQKM17X68G')</pre> In\u00a0[8]: Copied! <pre>encoding = {\n    \"PV\": {\n        \"codecs\": [zarr.codecs.BytesCodec(), zarr.codecs.ZstdCodec()],\n        \"chunks\": (1, 1, 721, 1440)\n    }\n}\n</pre> encoding = {     \"PV\": {         \"codecs\": [zarr.codecs.BytesCodec(), zarr.codecs.ZstdCodec()],         \"chunks\": (1, 1, 721, 1440)     } } <p>Note that Dask is not required to obtain good performance when reading and writing. Zarr and Icechunk use multithreading and asyncio internally.</p> In\u00a0[9]: Copied! <pre>%time dsl.to_zarr(store, zarr_format=3, consolidated=False, encoding=encoding)\n</pre> %time dsl.to_zarr(store, zarr_format=3, consolidated=False, encoding=encoding) <pre>CPU times: user 54 s, sys: 1.56 s, total: 55.5 s\nWall time: 18.9 s\n</pre> Out[9]: <pre>&lt;xarray.backends.zarr.ZarrStore at 0x7f9ea8781ec0&gt;</pre> In\u00a0[43]: Copied! <pre># with ProgressBar():\n#     (dsl\n#      .chunk({\"time\": 1, \"level\": 10})\n#      .to_zarr(store, zarr_format=3, consolidated=False, encoding=encoding)\n#     )\n</pre> # with ProgressBar(): #     (dsl #      .chunk({\"time\": 1, \"level\": 10}) #      .to_zarr(store, zarr_format=3, consolidated=False, encoding=encoding) #     ) <pre>[########################################] | 100% Completed | 18.02 ss\n</pre> In\u00a0[10]: Copied! <pre>store.commit(\"wrote data\")\n</pre> store.commit(\"wrote data\") Out[10]: <pre>'AS64P9SQ7NY1P22P8GS0'</pre> In\u00a0[11]: Copied! <pre>store = IcechunkStore.open_existing(\n    storage=StorageConfig.s3_from_env(\n        bucket=\"icechunk-test\",\n        prefix=prefix\n    ),\n    mode=\"r\"\n)\n</pre> store = IcechunkStore.open_existing(     storage=StorageConfig.s3_from_env(         bucket=\"icechunk-test\",         prefix=prefix     ),     mode=\"r\" ) In\u00a0[12]: Copied! <pre>%time dsic = xr.open_dataset(store, consolidated=False, engine=\"zarr\")\n</pre> %time dsic = xr.open_dataset(store, consolidated=False, engine=\"zarr\") <pre>CPU times: user 16.8 ms, sys: 2.45 ms, total: 19.2 ms\nWall time: 97.4 ms\n</pre> In\u00a0[13]: Copied! <pre>print(dsic)\n</pre> print(dsic) <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:    (level: 37, latitude: 721, longitude: 1440, time: 24)\nCoordinates:\n  * level      (level) float64 296B 1.0 2.0 3.0 5.0 ... 925.0 950.0 975.0 1e+03\n  * latitude   (latitude) float64 6kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n  * longitude  (longitude) float64 12kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n  * time       (time) datetime64[ns] 192B 1941-06-01 ... 1941-06-01T23:00:00\nData variables:\n    PV         (time, level, latitude, longitude) float32 4GB ...\n    utc_date   (time) int32 96B ...\nAttributes:\n    CONVERSION_DATE:      Wed May 10 06:33:49 MDT 2023\n    CONVERSION_PLATFORM:  Linux r1i4n4 4.12.14-95.51-default #1 SMP Fri Apr 1...\n    Conventions:          CF-1.6\n    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n    NCO:                  netCDF Operators version 5.0.3 (Homepage = http://n...\n    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB 1 data to netC...\n    NETCDF_VERSION:       4.8.1\n    history:              Wed May 10 06:34:19 2023: ncks -4 --ppc default=7 e...\n</pre> In\u00a0[14]: Copied! <pre>%time dsic.PV[0, 0, 0, 0].values\n</pre> %time dsic.PV[0, 0, 0, 0].values <pre>CPU times: user 16.8 ms, sys: 78 \u03bcs, total: 16.8 ms\nWall time: 102 ms\n</pre> Out[14]: <pre>array(0.00710905, dtype=float32)</pre> <p>As with writing, Dask is not required for performant reading of the data. In this example we can load the entire dataset (nearly 4GB) in 8s.</p> In\u00a0[15]: Copied! <pre>%time _ = dsic.compute()\n</pre> %time _ = dsic.compute() <pre>CPU times: user 11 s, sys: 3.67 s, total: 14.7 s\nWall time: 2.03 s\n</pre> In\u00a0[16]: Copied! <pre>xr.testing.assert_identical(_, ds)\n</pre> xr.testing.assert_identical(_, ds) In\u00a0[17]: Copied! <pre>dsicc = dsic.chunk({\"time\": 1, \"level\": 10})\n</pre> dsicc = dsic.chunk({\"time\": 1, \"level\": 10}) In\u00a0[19]: Copied! <pre>from dask.diagnostics import ProgressBar\nwith ProgressBar():\n    _ = dsicc.compute()\n</pre> from dask.diagnostics import ProgressBar with ProgressBar():     _ = dsicc.compute() <pre>[########################################] | 100% Completed | 2.13 sms\n</pre> In\u00a0[45]: Copied! <pre>actual = _\nactual\n</pre> actual = _ actual Out[45]: <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:    (latitude: 721, level: 37, time: 24, longitude: 1440)\nCoordinates:\n  * latitude   (latitude) float64 6kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n  * level      (level) float64 296B 1.0 2.0 3.0 5.0 ... 925.0 950.0 975.0 1e+03\n  * longitude  (longitude) float64 12kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n  * time       (time) datetime64[ns] 192B 1941-06-01 ... 1941-06-01T23:00:00\nData variables:\n    utc_date   (time) int32 96B 1941060100 1941060101 ... 1941060122 1941060123\n    PV         (time, level, latitude, longitude) float32 4GB 0.007109 ... -1...\nAttributes:\n    CONVERSION_DATE:      Wed May 10 06:33:49 MDT 2023\n    CONVERSION_PLATFORM:  Linux r1i4n4 4.12.14-95.51-default #1 SMP Fri Apr 1...\n    Conventions:          CF-1.6\n    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n    NCO:                  netCDF Operators version 5.0.3 (Homepage = http://n...\n    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB 1 data to netC...\n    NETCDF_VERSION:       4.8.1\n    history:              Wed May 10 06:34:19 2023: ncks -4 --ppc default=7 e...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>latitude: 721</li><li>level: 37</li><li>time: 24</li><li>longitude: 1440</li></ul></li><li>Coordinates: (4)<ul><li>latitude(latitude)float6490.0 89.75 89.5 ... -89.75 -90.0long_name :latitudeshort_name :latunits :degrees_north<pre>array([ 90.  ,  89.75,  89.5 , ..., -89.5 , -89.75, -90.  ])</pre></li><li>level(level)float641.0 2.0 3.0 ... 950.0 975.0 1e+03alternate_units :millibarlong_name :pressure levelshort_name :plevunits :hPa<pre>array([   1.,    2.,    3.,    5.,    7.,   10.,   20.,   30.,   50.,   70.,\n        100.,  125.,  150.,  175.,  200.,  225.,  250.,  300.,  350.,  400.,\n        450.,  500.,  550.,  600.,  650.,  700.,  750.,  775.,  800.,  825.,\n        850.,  875.,  900.,  925.,  950.,  975., 1000.])</pre></li><li>longitude(longitude)float640.0 0.25 0.5 ... 359.2 359.5 359.8long_name :longitudeshort_name :lonunits :degrees_east<pre>array([0.0000e+00, 2.5000e-01, 5.0000e-01, ..., 3.5925e+02, 3.5950e+02,\n       3.5975e+02])</pre></li><li>time(time)datetime64[ns]1941-06-01 ... 1941-06-01T23:00:00long_name :time<pre>array(['1941-06-01T00:00:00.000000000', '1941-06-01T01:00:00.000000000',\n       '1941-06-01T02:00:00.000000000', '1941-06-01T03:00:00.000000000',\n       '1941-06-01T04:00:00.000000000', '1941-06-01T05:00:00.000000000',\n       '1941-06-01T06:00:00.000000000', '1941-06-01T07:00:00.000000000',\n       '1941-06-01T08:00:00.000000000', '1941-06-01T09:00:00.000000000',\n       '1941-06-01T10:00:00.000000000', '1941-06-01T11:00:00.000000000',\n       '1941-06-01T12:00:00.000000000', '1941-06-01T13:00:00.000000000',\n       '1941-06-01T14:00:00.000000000', '1941-06-01T15:00:00.000000000',\n       '1941-06-01T16:00:00.000000000', '1941-06-01T17:00:00.000000000',\n       '1941-06-01T18:00:00.000000000', '1941-06-01T19:00:00.000000000',\n       '1941-06-01T20:00:00.000000000', '1941-06-01T21:00:00.000000000',\n       '1941-06-01T22:00:00.000000000', '1941-06-01T23:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>utc_date(time)int321941060100 ... 1941060123long_name :UTC date yyyy-mm-dd hh:00:00 as yyyymmddhhunits :Gregorian_year month day hour<pre>array([1941060100, 1941060101, 1941060102, 1941060103, 1941060104,\n       1941060105, 1941060106, 1941060107, 1941060108, 1941060109,\n       1941060110, 1941060111, 1941060112, 1941060113, 1941060114,\n       1941060115, 1941060116, 1941060117, 1941060118, 1941060119,\n       1941060120, 1941060121, 1941060122, 1941060123], dtype=int32)</pre></li><li>PV(time, level, latitude, longitude)float320.007109 0.007109 ... -1.53e-05QuantizeGranularBitGroomNumberOfSignificantDigits :7ecmwf_local_table :128ecmwf_parameter :60grid_specification :0.25 degree x 0.25 degree from 90N to 90S and 0E to 359.75E (721 x 1440 Latitude/Longitude)long_name :Potential vorticitymaximum_value :0.02379735186696053minimum_value :-0.03200835734605789original_format :WMO GRIB 1 with ECMWF local tablerda_dataset :ds633.0rda_dataset_doi :DOI: 10.5065/BH6N-5N20rda_dataset_group :ERA5 atmospheric pressure level analysis [netCDF4]rda_dataset_url :https:/rda.ucar.edu/datasets/ds633.0/short_name :pvunits :K m**2 kg**-1 s**-1<pre>array([[[[ 7.10904598e-03,  7.10904598e-03,  7.10904598e-03, ...,\n           7.10904598e-03,  7.10904598e-03,  7.10904598e-03],\n         [ 7.19106197e-03,  7.19010830e-03,  7.18915462e-03, ...,\n           7.19487667e-03,  7.19392300e-03,  7.19201565e-03],\n         [ 7.24160671e-03,  7.23969936e-03,  7.23779202e-03, ...,\n           7.24732876e-03,  7.24542141e-03,  7.24351406e-03],\n         ...,\n         [-1.38288736e-02, -1.38307810e-02, -1.38336420e-02, ...,\n          -1.38231516e-02, -1.38250589e-02, -1.38269663e-02],\n         [-1.36028528e-02, -1.36038065e-02, -1.36047602e-02, ...,\n          -1.35999918e-02, -1.36009455e-02, -1.36018991e-02],\n         [-1.36286020e-02, -1.36286020e-02, -1.36286020e-02, ...,\n          -1.36286020e-02, -1.36286020e-02, -1.36286020e-02]],\n\n        [[ 4.26043943e-03,  4.26043943e-03,  4.26043943e-03, ...,\n           4.26043943e-03,  4.26043943e-03,  4.26043943e-03],\n         [ 4.38370183e-03,  4.38346341e-03,  4.38322499e-03, ...,\n           4.38465551e-03,  4.38441709e-03,  4.38394025e-03],\n         [ 4.43472341e-03,  4.43424657e-03,  4.43400815e-03, ...,\n           4.43591550e-03,  4.43543866e-03,  4.43496183e-03],\n...\n          -9.63546336e-06, -9.58330929e-06, -9.51625407e-06],\n         [-2.10795552e-05, -2.10572034e-05, -2.10348517e-05, ...,\n          -2.11540610e-05, -2.11317092e-05, -2.11019069e-05],\n         [-1.52979046e-05, -1.52979046e-05, -1.52979046e-05, ...,\n          -1.52979046e-05, -1.52979046e-05, -1.52979046e-05]],\n\n        [[-9.31322575e-09, -9.31322575e-09, -9.31322575e-09, ...,\n          -9.31322575e-09, -9.31322575e-09, -9.31322575e-09],\n         [ 2.04890966e-08,  2.04890966e-08,  2.04890966e-08, ...,\n           2.04890966e-08,  2.04890966e-08,  2.04890966e-08],\n         [-1.67638063e-08, -1.67638063e-08, -1.67638063e-08, ...,\n          -1.67638063e-08, -1.67638063e-08, -1.67638063e-08],\n         ...,\n         [-9.44919884e-06, -9.41194594e-06, -9.37469304e-06, ...,\n          -9.63546336e-06, -9.58330929e-06, -9.51625407e-06],\n         [-2.10795552e-05, -2.10572034e-05, -2.10348517e-05, ...,\n          -2.11540610e-05, -2.11317092e-05, -2.11019069e-05],\n         [-1.52979046e-05, -1.52979046e-05, -1.52979046e-05, ...,\n          -1.52979046e-05, -1.52979046e-05, -1.52979046e-05]]]],\n      dtype=float32)</pre></li></ul></li><li>Indexes: (4)<ul><li>latitudePandasIndex<pre>PandasIndex(Index([  90.0,  89.75,   89.5,  89.25,   89.0,  88.75,   88.5,  88.25,   88.0,\n        87.75,\n       ...\n       -87.75,  -88.0, -88.25,  -88.5, -88.75,  -89.0, -89.25,  -89.5, -89.75,\n        -90.0],\n      dtype='float64', name='latitude', length=721))</pre></li><li>levelPandasIndex<pre>PandasIndex(Index([   1.0,    2.0,    3.0,    5.0,    7.0,   10.0,   20.0,   30.0,   50.0,\n         70.0,  100.0,  125.0,  150.0,  175.0,  200.0,  225.0,  250.0,  300.0,\n        350.0,  400.0,  450.0,  500.0,  550.0,  600.0,  650.0,  700.0,  750.0,\n        775.0,  800.0,  825.0,  850.0,  875.0,  900.0,  925.0,  950.0,  975.0,\n       1000.0],\n      dtype='float64', name='level'))</pre></li><li>longitudePandasIndex<pre>PandasIndex(Index([   0.0,   0.25,    0.5,   0.75,    1.0,   1.25,    1.5,   1.75,    2.0,\n         2.25,\n       ...\n        357.5, 357.75,  358.0, 358.25,  358.5, 358.75,  359.0, 359.25,  359.5,\n       359.75],\n      dtype='float64', name='longitude', length=1440))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['1941-06-01 00:00:00', '1941-06-01 01:00:00',\n               '1941-06-01 02:00:00', '1941-06-01 03:00:00',\n               '1941-06-01 04:00:00', '1941-06-01 05:00:00',\n               '1941-06-01 06:00:00', '1941-06-01 07:00:00',\n               '1941-06-01 08:00:00', '1941-06-01 09:00:00',\n               '1941-06-01 10:00:00', '1941-06-01 11:00:00',\n               '1941-06-01 12:00:00', '1941-06-01 13:00:00',\n               '1941-06-01 14:00:00', '1941-06-01 15:00:00',\n               '1941-06-01 16:00:00', '1941-06-01 17:00:00',\n               '1941-06-01 18:00:00', '1941-06-01 19:00:00',\n               '1941-06-01 20:00:00', '1941-06-01 21:00:00',\n               '1941-06-01 22:00:00', '1941-06-01 23:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (9)CONVERSION_DATE :Wed May 10 06:33:49 MDT 2023CONVERSION_PLATFORM :Linux r1i4n4 4.12.14-95.51-default #1 SMP Fri Apr 17 08:14:12 UTC 2020 (c6bab98) x86_64 x86_64 x86_64 GNU/LinuxConventions :CF-1.6DATA_SOURCE :ECMWF: https://cds.climate.copernicus.eu, Copernicus Climate Data StoreNCO :netCDF Operators version 5.0.3 (Homepage = http://nco.sf.net, Code = http://github.com/nco/nco)NETCDF_COMPRESSION :NCO: Precision-preserving compression to netCDF4/HDF5 (see \"history\" and \"NCO\" global attributes below for specifics).NETCDF_CONVERSION :CISL RDA: Conversion from ECMWF GRIB 1 data to netCDF4.NETCDF_VERSION :4.8.1history :Wed May 10 06:34:19 2023: ncks -4 --ppc default=7 e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.unc.nc e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.nc</li></ul> In\u00a0[46]: Copied! <pre>xr.testing.assert_identical(actual, dsl)\n</pre> xr.testing.assert_identical(actual, dsl) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-Icechunk/#icechunk-performance-icechunk","title":"Icechunk Performance - Icechunk\u00b6","text":"<p>Using data from the NCAR ERA5 AWS Public Dataset.</p>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-Icechunk/#load-data-from-hdf5-file","title":"Load Data from HDF5 File\u00b6","text":"<p>This illustrates how loading directly from HDF5 files on S3 can be slow, even with Dask.</p>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-Icechunk/#initialize-icechunk-repo","title":"Initialize Icechunk Repo\u00b6","text":""},{"location":"icechunk-python/notebooks/performance/era5_xarray-Icechunk/#store-data-to-icechunk","title":"Store Data To Icechunk\u00b6","text":"<p>We specify encoding to set both compression and chunk size.</p>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-Icechunk/#read-data-back","title":"Read Data Back\u00b6","text":""},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr2/","title":"Icechunk Performance - Zarr V2","text":"In\u00a0[1]: Copied! <pre>import xarray as xr\nimport zarr\nimport dask\nimport fsspec\nfrom dask.diagnostics import ProgressBar\n\nprint('xarray:  ', xr.__version__)\nprint('dask:    ', dask.__version__)\nprint('zarr:    ', zarr.__version__)\n</pre> import xarray as xr import zarr import dask import fsspec from dask.diagnostics import ProgressBar  print('xarray:  ', xr.__version__) print('dask:    ', dask.__version__) print('zarr:    ', zarr.__version__) <pre>xarray:   2024.7.0\ndask:     2024.6.2\nzarr:     2.18.2\n</pre> In\u00a0[6]: Copied! <pre>url = \"https://nsf-ncar-era5.s3.amazonaws.com/e5.oper.an.pl/194106/e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.nc\"\n%time dsc = xr.open_dataset(fsspec.open(url).open(), engine=\"h5netcdf\", chunks={\"time\": 1}).drop_encoding()\n</pre> url = \"https://nsf-ncar-era5.s3.amazonaws.com/e5.oper.an.pl/194106/e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.nc\" %time dsc = xr.open_dataset(fsspec.open(url).open(), engine=\"h5netcdf\", chunks={\"time\": 1}).drop_encoding() <pre>CPU times: user 123 ms, sys: 44.5 ms, total: 168 ms\nWall time: 1.91 s\n</pre> <pre>/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/dataset.py:277: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 1. This could degrade performance. Instead, consider rechunking after loading.\n  warnings.warn(\n</pre> In\u00a0[7]: Copied! <pre>print(ds)\n</pre> print(ds) <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:    (time: 24, level: 37, latitude: 721, longitude: 1440)\nCoordinates:\n  * latitude   (latitude) float64 6kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n  * level      (level) float64 296B 1.0 2.0 3.0 5.0 ... 925.0 950.0 975.0 1e+03\n  * longitude  (longitude) float64 12kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n  * time       (time) datetime64[ns] 192B 1941-06-01 ... 1941-06-01T23:00:00\nData variables:\n    PV         (time, level, latitude, longitude) float32 4GB dask.array&lt;chunksize=(1, 37, 721, 1440), meta=np.ndarray&gt;\n    utc_date   (time) int32 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nAttributes:\n    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB 1 data to netC...\n    NETCDF_VERSION:       4.8.1\n    CONVERSION_PLATFORM:  Linux r1i4n4 4.12.14-95.51-default #1 SMP Fri Apr 1...\n    CONVERSION_DATE:      Wed May 10 06:33:49 MDT 2023\n    Conventions:          CF-1.6\n    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n    history:              Wed May 10 06:34:19 2023: ncks -4 --ppc default=7 e...\n    NCO:                  netCDF Operators version 5.0.3 (Homepage = http://n...\n</pre> In\u00a0[8]: Copied! <pre>with ProgressBar():\n    dsl = ds.load()\n</pre> with ProgressBar():     dsl = ds.load() <pre>[########################################] | 100% Completed | 61.19 ss\n</pre> In\u00a0[9]: Copied! <pre>encoding = {\n    \"PV\": {\n        \"compressor\": zarr.Zstd(),\n        \"chunks\": (1, 1, 721, 1440)\n    }\n}\n</pre> encoding = {     \"PV\": {         \"compressor\": zarr.Zstd(),         \"chunks\": (1, 1, 721, 1440)     } } In\u00a0[17]: Copied! <pre>target_url = \"s3://icechunk-test/ryan/zarr-v2/test-era5-11\"\nstore = zarr.storage.FSStore(target_url)\n</pre> target_url = \"s3://icechunk-test/ryan/zarr-v2/test-era5-11\" store = zarr.storage.FSStore(target_url) In\u00a0[18]: Copied! <pre>%time dsl.to_zarr(store, consolidated=False, encoding=encoding, mode=\"w\")\n</pre> %time dsl.to_zarr(store, consolidated=False, encoding=encoding, mode=\"w\") <pre>CPU times: user 21.4 s, sys: 3.73 s, total: 25.1 s\nWall time: 31.8 s\n</pre> Out[18]: <pre>&lt;xarray.backends.zarr.ZarrStore at 0x7efac8869fc0&gt;</pre> In\u00a0[22]: Copied! <pre># with dask\ndslc = dsl.chunk({\"time\": 1, \"level\": 1})\nstore_d = zarr.storage.FSStore(target_url + '-dask')\nwith ProgressBar():\n    dslc.to_zarr(store_d, consolidated=False, encoding=encoding, mode=\"w\")\n</pre> # with dask dslc = dsl.chunk({\"time\": 1, \"level\": 1}) store_d = zarr.storage.FSStore(target_url + '-dask') with ProgressBar():     dslc.to_zarr(store_d, consolidated=False, encoding=encoding, mode=\"w\") <pre>[########################################] | 100% Completed | 12.30 s\n</pre> In\u00a0[12]: Copied! <pre>%time dss = xr.open_dataset(store, consolidated=False, engine=\"zarr\")\n</pre> %time dss = xr.open_dataset(store, consolidated=False, engine=\"zarr\") <pre>CPU times: user 50.4 ms, sys: 7.21 ms, total: 57.6 ms\nWall time: 487 ms\n</pre> In\u00a0[13]: Copied! <pre>%time dss.PV[0, 0, 0, 0].values\n</pre> %time dss.PV[0, 0, 0, 0].values <pre>CPU times: user 15.2 ms, sys: 671 \u03bcs, total: 15.9 ms\nWall time: 97.4 ms\n</pre> Out[13]: <pre>array(0.00710905, dtype=float32)</pre> In\u00a0[23]: Copied! <pre>%time _ = dss.compute()\n</pre> %time _ = dss.compute() <pre>CPU times: user 8.6 s, sys: 1.53 s, total: 10.1 s\nWall time: 22.6 s\n</pre> In\u00a0[15]: Copied! <pre>dssd = xr.open_dataset(store, consolidated=False, engine=\"zarr\").chunk({\"time\": 1, \"level\": 10})\n</pre> dssd = xr.open_dataset(store, consolidated=False, engine=\"zarr\").chunk({\"time\": 1, \"level\": 10}) In\u00a0[16]: Copied! <pre>with ProgressBar():\n    _ = dssd.compute()\n</pre> with ProgressBar():     _ = dssd.compute() <pre>[########################################] | 100% Completed | 4.55 sms\n</pre> In\u00a0[22]: Copied! <pre>1893510506 / 2 / 1e6\n</pre> 1893510506 / 2 / 1e6 Out[22]: <pre>946.755253</pre> In\u00a0[20]: Copied! <pre>group = zarr.open_group(store, mode=\"r\")\ngroup.info\n</pre> group = zarr.open_group(store, mode=\"r\") group.info Out[20]: Name/Typezarr.hierarchy.GroupRead-onlyTrueStore typezarr.storage.FSStoreNo. members6No. arrays6No. groups0ArraysPV, latitude, level, longitude, time, utc_date In\u00a0[21]: Copied! <pre>group.PV.info\n</pre> group.PV.info Out[21]: Name/PVTypezarr.core.ArrayData typefloat32Shape(24, 37, 721, 1440)Chunk shape(1, 1, 721, 1440)OrderCRead-onlyTrueCompressorZstd(level=1)Store typezarr.storage.FSStoreNo. bytes3687828480 (3.4G)No. bytes stored1893510506 (1.8G)Storage ratio1.9Chunks initialized888/888 In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr2/#icechunk-performance-zarr-v2","title":"Icechunk Performance - Zarr V2\u00b6","text":"<p>Using data from the NCAR ERA5 AWS Public Dataset.</p>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr2/#load-data-from-hdf5-file","title":"Load Data from HDF5 File\u00b6","text":"<p>This illustrates how loading directly from HDF5 files on S3 can be slow, even with Dask.</p>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr2/#write-zarr-store-no-dask","title":"Write Zarr Store - No Dask\u00b6","text":""},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr2/#read-data-back","title":"Read Data Back\u00b6","text":""},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr3/","title":"Icechunk Performance - Zarr V3","text":"In\u00a0[1]: Copied! <pre>import xarray as xr\nimport zarr\nimport dask\nimport fsspec\nfrom dask.diagnostics import ProgressBar\n\nprint('xarray:  ', xr.__version__)\nprint('dask:    ', dask.__version__)\nprint('zarr:    ', zarr.__version__)\n</pre> import xarray as xr import zarr import dask import fsspec from dask.diagnostics import ProgressBar  print('xarray:  ', xr.__version__) print('dask:    ', dask.__version__) print('zarr:    ', zarr.__version__) <pre>xarray:   0.9.7.dev3734+g26081d4f\ndask:     2024.9.1+8.g70f56e28\nzarr:     3.0.0b1.dev8+g9bbfd88\n</pre> In\u00a0[2]: Copied! <pre>zarr.config.set(\n    {\n        'threading.max_workers': 16,\n        'async.concurrency': 128\n    }\n)\n</pre> zarr.config.set(     {         'threading.max_workers': 16,         'async.concurrency': 128     } ) Out[2]: <pre>&lt;donfig.config_obj.ConfigSet at 0x7f5a7a52bf50&gt;</pre> In\u00a0[3]: Copied! <pre>url = \"https://nsf-ncar-era5.s3.amazonaws.com/e5.oper.an.pl/194106/e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.nc\"\n%time ds = xr.open_dataset(fsspec.open(url).open(), engine=\"h5netcdf\", chunks={\"time\": 1})\nds = ds.drop_encoding()\n</pre> url = \"https://nsf-ncar-era5.s3.amazonaws.com/e5.oper.an.pl/194106/e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.nc\" %time ds = xr.open_dataset(fsspec.open(url).open(), engine=\"h5netcdf\", chunks={\"time\": 1}) ds = ds.drop_encoding() <pre>CPU times: user 277 ms, sys: 37.5 ms, total: 315 ms\nWall time: 2.33 s\n</pre> <pre>/srv/conda/envs/icechunk/lib/python3.12/site-packages/xarray/backends/api.py:357: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 1. This could degrade performance. Instead, consider rechunking after loading.\n  var_chunks = _get_chunk(var, chunks, chunkmanager)\n</pre> In\u00a0[4]: Copied! <pre>print(ds)\n</pre> print(ds) <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:    (time: 24, level: 37, latitude: 721, longitude: 1440)\nCoordinates:\n  * latitude   (latitude) float64 6kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n  * level      (level) float64 296B 1.0 2.0 3.0 5.0 ... 925.0 950.0 975.0 1e+03\n  * longitude  (longitude) float64 12kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n  * time       (time) datetime64[ns] 192B 1941-06-01 ... 1941-06-01T23:00:00\nData variables:\n    PV         (time, level, latitude, longitude) float32 4GB dask.array&lt;chunksize=(1, 37, 721, 1440), meta=np.ndarray&gt;\n    utc_date   (time) int32 96B dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;\nAttributes:\n    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB 1 data to netC...\n    NETCDF_VERSION:       4.8.1\n    CONVERSION_PLATFORM:  Linux r1i4n4 4.12.14-95.51-default #1 SMP Fri Apr 1...\n    CONVERSION_DATE:      Wed May 10 06:33:49 MDT 2023\n    Conventions:          CF-1.6\n    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n    history:              Wed May 10 06:34:19 2023: ncks -4 --ppc default=7 e...\n    NCO:                  netCDF Operators version 5.0.3 (Homepage = http://n...\n</pre> In\u00a0[5]: Copied! <pre>with ProgressBar():\n    dsl = ds.load()\n</pre> with ProgressBar():     dsl = ds.load() <pre>[########################################] | 100% Completed | 62.20 ss\n</pre> In\u00a0[6]: Copied! <pre>encoding = {\n    \"PV\": {\n        \"codecs\": [zarr.codecs.BytesCodec(), zarr.codecs.ZstdCodec()],\n        \"chunks\": (1, 1, 721, 1440)\n    }\n}\n</pre> encoding = {     \"PV\": {         \"codecs\": [zarr.codecs.BytesCodec(), zarr.codecs.ZstdCodec()],         \"chunks\": (1, 1, 721, 1440)     } } In\u00a0[7]: Copied! <pre>import s3fs\ns3 = s3fs.S3FileSystem(use_listings_cache=False)\n</pre> import s3fs s3 = s3fs.S3FileSystem(use_listings_cache=False) In\u00a0[10]: Copied! <pre>target_path = \"icechunk-test/ryan/zarr-v3/test-era5-v3-919\"\nstore = zarr.storage.RemoteStore(s3, mode=\"w\", path=target_path)\n</pre> target_path = \"icechunk-test/ryan/zarr-v3/test-era5-v3-919\" store = zarr.storage.RemoteStore(s3, mode=\"w\", path=target_path) In\u00a0[11]: Copied! <pre>%time dsl.to_zarr(store, consolidated=False, zarr_format=3, encoding=encoding, mode=\"w\")\n</pre> %time dsl.to_zarr(store, consolidated=False, zarr_format=3, encoding=encoding, mode=\"w\") <pre>CPU times: user 36.2 s, sys: 2.53 s, total: 38.7 s\nWall time: 15.8 s\n</pre> Out[11]: <pre>&lt;xarray.backends.zarr.ZarrStore at 0x7f5a3839efc0&gt;</pre> In\u00a0[48]: Copied! <pre># with dask\ndslc = dsl.chunk({\"time\": 1, \"level\": 1})\nstore_d = zarr.storage.RemoteStore(s3, mode=\"w\", path=target_url + \"-dask\")\nwith ProgressBar():\n    dslc.to_zarr(store_d, consolidated=False, zarr_format=3, encoding=encoding, mode=\"w\")\n</pre> # with dask dslc = dsl.chunk({\"time\": 1, \"level\": 1}) store_d = zarr.storage.RemoteStore(s3, mode=\"w\", path=target_url + \"-dask\") with ProgressBar():     dslc.to_zarr(store_d, consolidated=False, zarr_format=3, encoding=encoding, mode=\"w\") <pre>[########################################] | 100% Completed | 12.60 s\n</pre> In\u00a0[12]: Copied! <pre>#store = zarr.storage.RemoteStore(s3, mode=\"r\", path=target_url)\n%time dss = xr.open_dataset(store, consolidated=False, zarr_format=3, engine=\"zarr\")\n</pre> #store = zarr.storage.RemoteStore(s3, mode=\"r\", path=target_url) %time dss = xr.open_dataset(store, consolidated=False, zarr_format=3, engine=\"zarr\") <pre>CPU times: user 35.6 ms, sys: 0 ns, total: 35.6 ms\nWall time: 343 ms\n</pre> In\u00a0[13]: Copied! <pre>dss\n</pre> dss Out[13]: <pre>&lt;xarray.Dataset&gt; Size: 4GB\nDimensions:    (time: 24, level: 37, latitude: 721, longitude: 1440)\nCoordinates:\n  * latitude   (latitude) float64 6kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n  * level      (level) float64 296B 1.0 2.0 3.0 5.0 ... 925.0 950.0 975.0 1e+03\n  * longitude  (longitude) float64 12kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n  * time       (time) datetime64[ns] 192B 1941-06-01 ... 1941-06-01T23:00:00\nData variables:\n    PV         (time, level, latitude, longitude) float32 4GB ...\n    utc_date   (time) int32 96B ...\nAttributes:\n    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB 1 data to netC...\n    NETCDF_VERSION:       4.8.1\n    CONVERSION_PLATFORM:  Linux r1i4n4 4.12.14-95.51-default #1 SMP Fri Apr 1...\n    CONVERSION_DATE:      Wed May 10 06:33:49 MDT 2023\n    Conventions:          CF-1.6\n    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n    history:              Wed May 10 06:34:19 2023: ncks -4 --ppc default=7 e...\n    NCO:                  netCDF Operators version 5.0.3 (Homepage = http://n...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 24</li><li>level: 37</li><li>latitude: 721</li><li>longitude: 1440</li></ul></li><li>Coordinates: (4)<ul><li>latitude(latitude)float6490.0 89.75 89.5 ... -89.75 -90.0long_name :latitudeshort_name :latunits :degrees_north<pre>array([ 90.  ,  89.75,  89.5 , ..., -89.5 , -89.75, -90.  ])</pre></li><li>level(level)float641.0 2.0 3.0 ... 950.0 975.0 1e+03long_name :pressure levelshort_name :plevunits :hPaalternate_units :millibar<pre>array([   1.,    2.,    3.,    5.,    7.,   10.,   20.,   30.,   50.,   70.,\n        100.,  125.,  150.,  175.,  200.,  225.,  250.,  300.,  350.,  400.,\n        450.,  500.,  550.,  600.,  650.,  700.,  750.,  775.,  800.,  825.,\n        850.,  875.,  900.,  925.,  950.,  975., 1000.])</pre></li><li>longitude(longitude)float640.0 0.25 0.5 ... 359.2 359.5 359.8long_name :longitudeshort_name :lonunits :degrees_east<pre>array([0.0000e+00, 2.5000e-01, 5.0000e-01, ..., 3.5925e+02, 3.5950e+02,\n       3.5975e+02])</pre></li><li>time(time)datetime64[ns]1941-06-01 ... 1941-06-01T23:00:00long_name :time<pre>array(['1941-06-01T00:00:00.000000000', '1941-06-01T01:00:00.000000000',\n       '1941-06-01T02:00:00.000000000', '1941-06-01T03:00:00.000000000',\n       '1941-06-01T04:00:00.000000000', '1941-06-01T05:00:00.000000000',\n       '1941-06-01T06:00:00.000000000', '1941-06-01T07:00:00.000000000',\n       '1941-06-01T08:00:00.000000000', '1941-06-01T09:00:00.000000000',\n       '1941-06-01T10:00:00.000000000', '1941-06-01T11:00:00.000000000',\n       '1941-06-01T12:00:00.000000000', '1941-06-01T13:00:00.000000000',\n       '1941-06-01T14:00:00.000000000', '1941-06-01T15:00:00.000000000',\n       '1941-06-01T16:00:00.000000000', '1941-06-01T17:00:00.000000000',\n       '1941-06-01T18:00:00.000000000', '1941-06-01T19:00:00.000000000',\n       '1941-06-01T20:00:00.000000000', '1941-06-01T21:00:00.000000000',\n       '1941-06-01T22:00:00.000000000', '1941-06-01T23:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>PV(time, level, latitude, longitude)float32...long_name :Potential vorticityshort_name :pvunits :K m**2 kg**-1 s**-1original_format :WMO GRIB 1 with ECMWF local tableecmwf_local_table :128ecmwf_parameter :60minimum_value :-0.03200835734605789maximum_value :0.023797351866960526grid_specification :0.25 degree x 0.25 degree from 90N to 90S and 0E to 359.75E (721 x 1440 Latitude/Longitude)rda_dataset :ds633.0rda_dataset_url :https:/rda.ucar.edu/datasets/ds633.0/rda_dataset_doi :DOI: 10.5065/BH6N-5N20rda_dataset_group :ERA5 atmospheric pressure level analysis [netCDF4]QuantizeGranularBitGroomNumberOfSignificantDigits :7<pre>[921957120 values with dtype=float32]</pre></li><li>utc_date(time)int32...long_name :UTC date yyyy-mm-dd hh:00:00 as yyyymmddhhunits :Gregorian_year month day hour<pre>[24 values with dtype=int32]</pre></li></ul></li><li>Indexes: (4)<ul><li>latitudePandasIndex<pre>PandasIndex(Index([  90.0,  89.75,   89.5,  89.25,   89.0,  88.75,   88.5,  88.25,   88.0,\n        87.75,\n       ...\n       -87.75,  -88.0, -88.25,  -88.5, -88.75,  -89.0, -89.25,  -89.5, -89.75,\n        -90.0],\n      dtype='float64', name='latitude', length=721))</pre></li><li>levelPandasIndex<pre>PandasIndex(Index([   1.0,    2.0,    3.0,    5.0,    7.0,   10.0,   20.0,   30.0,   50.0,\n         70.0,  100.0,  125.0,  150.0,  175.0,  200.0,  225.0,  250.0,  300.0,\n        350.0,  400.0,  450.0,  500.0,  550.0,  600.0,  650.0,  700.0,  750.0,\n        775.0,  800.0,  825.0,  850.0,  875.0,  900.0,  925.0,  950.0,  975.0,\n       1000.0],\n      dtype='float64', name='level'))</pre></li><li>longitudePandasIndex<pre>PandasIndex(Index([   0.0,   0.25,    0.5,   0.75,    1.0,   1.25,    1.5,   1.75,    2.0,\n         2.25,\n       ...\n        357.5, 357.75,  358.0, 358.25,  358.5, 358.75,  359.0, 359.25,  359.5,\n       359.75],\n      dtype='float64', name='longitude', length=1440))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['1941-06-01 00:00:00', '1941-06-01 01:00:00',\n               '1941-06-01 02:00:00', '1941-06-01 03:00:00',\n               '1941-06-01 04:00:00', '1941-06-01 05:00:00',\n               '1941-06-01 06:00:00', '1941-06-01 07:00:00',\n               '1941-06-01 08:00:00', '1941-06-01 09:00:00',\n               '1941-06-01 10:00:00', '1941-06-01 11:00:00',\n               '1941-06-01 12:00:00', '1941-06-01 13:00:00',\n               '1941-06-01 14:00:00', '1941-06-01 15:00:00',\n               '1941-06-01 16:00:00', '1941-06-01 17:00:00',\n               '1941-06-01 18:00:00', '1941-06-01 19:00:00',\n               '1941-06-01 20:00:00', '1941-06-01 21:00:00',\n               '1941-06-01 22:00:00', '1941-06-01 23:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (9)DATA_SOURCE :ECMWF: https://cds.climate.copernicus.eu, Copernicus Climate Data StoreNETCDF_CONVERSION :CISL RDA: Conversion from ECMWF GRIB 1 data to netCDF4.NETCDF_VERSION :4.8.1CONVERSION_PLATFORM :Linux r1i4n4 4.12.14-95.51-default #1 SMP Fri Apr 17 08:14:12 UTC 2020 (c6bab98) x86_64 x86_64 x86_64 GNU/LinuxCONVERSION_DATE :Wed May 10 06:33:49 MDT 2023Conventions :CF-1.6NETCDF_COMPRESSION :NCO: Precision-preserving compression to netCDF4/HDF5 (see \"history\" and \"NCO\" global attributes below for specifics).history :Wed May 10 06:34:19 2023: ncks -4 --ppc default=7 e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.unc.nc e5.oper.an.pl.128_060_pv.ll025sc.1941060100_1941060123.ncNCO :netCDF Operators version 5.0.3 (Homepage = http://nco.sf.net, Code = http://github.com/nco/nco)</li></ul> In\u00a0[14]: Copied! <pre>%time dss.PV[0, 0, 0, 0].values\n</pre> %time dss.PV[0, 0, 0, 0].values <pre>CPU times: user 15.7 ms, sys: 0 ns, total: 15.7 ms\nWall time: 101 ms\n</pre> Out[14]: <pre>array(0.00710905, dtype=float32)</pre> In\u00a0[16]: Copied! <pre>%time _ = dss.compute()\n</pre> %time _ = dss.compute() <pre>CPU times: user 8.41 s, sys: 1.19 s, total: 9.6 s\nWall time: 5.11 s\n</pre> In\u00a0[17]: Copied! <pre>dssd = xr.open_dataset(store, consolidated=False, engine=\"zarr\").chunk({\"time\": 1, \"level\": 10})\n</pre> dssd = xr.open_dataset(store, consolidated=False, engine=\"zarr\").chunk({\"time\": 1, \"level\": 10}) In\u00a0[18]: Copied! <pre>with ProgressBar():\n    _ = dssd.compute()\n</pre> with ProgressBar():     _ = dssd.compute() <pre>[########################################] | 100% Completed | 6.26 sms\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr3/#icechunk-performance-zarr-v3","title":"Icechunk Performance - Zarr V3\u00b6","text":"<p>Using data from the NCAR ERA5 AWS Public Dataset.</p>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr3/#load-data-from-hdf5-file","title":"Load Data from HDF5 File\u00b6","text":"<p>This illustrates how loading directly from HDF5 files on S3 can be slow, even with Dask.</p>"},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr3/#write-zarr-store-no-dask","title":"Write Zarr Store - No Dask\u00b6","text":""},{"location":"icechunk-python/notebooks/performance/era5_xarray-zarr3/#read-data-back","title":"Read Data Back\u00b6","text":""}]}